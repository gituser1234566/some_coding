Starting job 452435 on gpu-9 at Sat Mar 9 19:21:17 CET 2024

submission directory: /fp/homes01/u01/ec-eirikeg/mandatory_2
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [PAD] seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [SEP] seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))

Data preprocessing...
TESTING FOR MUTLIPLE PARAMETERS:




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.1 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9085
 * Micro Average: f1: 0.7689, precision: 0.7481, recall: 0.7908
 * Macro Average: f1: 0.5781, precision: 0.5627, recall: 0.5944

Epoch 2/10, accuracy: 0.9146
 * Micro Average: f1: 0.7924, precision: 0.7750, recall: 0.8105
 * Macro Average: f1: 0.7937, precision: 0.7760, recall: 0.8126

Epoch 3/10, accuracy: 0.9216
 * Micro Average: f1: 0.8134, precision: 0.8061, recall: 0.8209
 * Macro Average: f1: 0.8150, precision: 0.8077, recall: 0.8226

Epoch 4/10, accuracy: 0.9205
 * Micro Average: f1: 0.8054, precision: 0.7854, recall: 0.8264
 * Macro Average: f1: 0.8076, precision: 0.7883, recall: 0.8279

Epoch 5/10, accuracy: 0.9208
 * Micro Average: f1: 0.8128, precision: 0.7978, recall: 0.8284
 * Macro Average: f1: 0.8148, precision: 0.8006, recall: 0.8298

Epoch 6/10, accuracy: 0.9187
 * Micro Average: f1: 0.8062, precision: 0.7869, recall: 0.8264
 * Macro Average: f1: 0.6052, precision: 0.5902, recall: 0.6212

Epoch 7/10, accuracy: 0.9236
 * Micro Average: f1: 0.8182, precision: 0.8046, recall: 0.8322
 * Macro Average: f1: 0.8192, precision: 0.8051, recall: 0.8339

Epoch 8/10, accuracy: 0.9203
 * Micro Average: f1: 0.8162, precision: 0.8036, recall: 0.8291
 * Macro Average: f1: 0.8179, precision: 0.8057, recall: 0.8305

Epoch 9/10, accuracy: 0.9226
 * Micro Average: f1: 0.8227, precision: 0.8111, recall: 0.8346
 * Macro Average: f1: 0.6184, precision: 0.6101, recall: 0.6269

Epoch 10/10, accuracy: 0.9234
 * Micro Average: f1: 0.8260, precision: 0.8152, recall: 0.8370
 * Macro Average: f1: 0.6205, precision: 0.6125, recall: 0.6288

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7229
  * recall: 0.8232
  * f1-score: 0.7698
  * support: 526.0000
 ORG:
  * precision: 0.5241
  * recall: 0.7487
  * f1-score: 0.6166
  * support: 581.0000
 PER:
  * precision: 0.7723
  * recall: 0.9014
  * f1-score: 0.8319
  * support: 365.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6435
  * recall: 0.8132
  * f1-score: 0.7185
  * support: 1472.0000
 macro avg:
  * precision: 0.5048
  * recall: 0.6183
  * f1-score: 0.5546
  * support: 1472.0000
 weighted avg:
  * precision: 0.6567
  * recall: 0.8132
  * f1-score: 0.7247
  * support: 1472.0000
 accuracy:
  * 0.8779
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.1 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9233
 * Micro Average: f1: 0.8249, precision: 0.8136, recall: 0.8366
 * Macro Average: f1: 0.6198, precision: 0.6113, recall: 0.6285

Epoch 2/10, accuracy: 0.9233
 * Micro Average: f1: 0.8262, precision: 0.8155, recall: 0.8373
 * Macro Average: f1: 0.6209, precision: 0.6129, recall: 0.6290

Epoch 3/10, accuracy: 0.9233
 * Micro Average: f1: 0.8261, precision: 0.8154, recall: 0.8371
 * Macro Average: f1: 0.6208, precision: 0.6129, recall: 0.6289

Epoch 4/10, accuracy: 0.9233
 * Micro Average: f1: 0.8256, precision: 0.8148, recall: 0.8368
 * Macro Average: f1: 0.6203, precision: 0.6123, recall: 0.6286

Epoch 5/10, accuracy: 0.9233
 * Micro Average: f1: 0.8254, precision: 0.8143, recall: 0.8368
 * Macro Average: f1: 0.6202, precision: 0.6120, recall: 0.6286

Epoch 6/10, accuracy: 0.9233
 * Micro Average: f1: 0.8255, precision: 0.8145, recall: 0.8368
 * Macro Average: f1: 0.6202, precision: 0.6121, recall: 0.6286

Epoch 7/10, accuracy: 0.9232
 * Micro Average: f1: 0.8250, precision: 0.8140, recall: 0.8364
 * Macro Average: f1: 0.6199, precision: 0.6117, recall: 0.6283

Epoch 8/10, accuracy: 0.9233
 * Micro Average: f1: 0.8247, precision: 0.8135, recall: 0.8362
 * Macro Average: f1: 0.6197, precision: 0.6113, recall: 0.6282

Epoch 9/10, accuracy: 0.9233
 * Micro Average: f1: 0.8248, precision: 0.8136, recall: 0.8364
 * Macro Average: f1: 0.6197, precision: 0.6114, recall: 0.6283

Epoch 10/10, accuracy: 0.9234
 * Micro Average: f1: 0.8248, precision: 0.8136, recall: 0.8364
 * Macro Average: f1: 0.6197, precision: 0.6114, recall: 0.6283

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7236
  * recall: 0.8213
  * f1-score: 0.7694
  * support: 526.0000
 ORG:
  * precision: 0.5214
  * recall: 0.7556
  * f1-score: 0.6170
  * support: 581.0000
 PER:
  * precision: 0.7815
  * recall: 0.9014
  * f1-score: 0.8372
  * support: 365.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6431
  * recall: 0.8152
  * f1-score: 0.7190
  * support: 1472.0000
 macro avg:
  * precision: 0.5066
  * recall: 0.6196
  * f1-score: 0.5559
  * support: 1472.0000
 weighted avg:
  * precision: 0.6581
  * recall: 0.8152
  * f1-score: 0.7260
  * support: 1472.0000
 accuracy:
  * 0.8761
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.2 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9217
 * Micro Average: f1: 0.8200, precision: 0.8072, recall: 0.8331
 * Macro Average: f1: 0.6158, precision: 0.6059, recall: 0.6260

Epoch 2/10, accuracy: 0.9218
 * Micro Average: f1: 0.8195, precision: 0.8067, recall: 0.8328
 * Macro Average: f1: 0.6155, precision: 0.6056, recall: 0.6258

Epoch 3/10, accuracy: 0.9219
 * Micro Average: f1: 0.8199, precision: 0.8071, recall: 0.8331
 * Macro Average: f1: 0.6157, precision: 0.6059, recall: 0.6260

Epoch 4/10, accuracy: 0.9219
 * Micro Average: f1: 0.8200, precision: 0.8070, recall: 0.8335
 * Macro Average: f1: 0.6158, precision: 0.6058, recall: 0.6263

Epoch 5/10, accuracy: 0.9219
 * Micro Average: f1: 0.8192, precision: 0.8058, recall: 0.8331
 * Macro Average: f1: 0.6153, precision: 0.6049, recall: 0.6260

Epoch 6/10, accuracy: 0.9219
 * Micro Average: f1: 0.8201, precision: 0.8072, recall: 0.8333
 * Macro Average: f1: 0.6159, precision: 0.6060, recall: 0.6262

Epoch 7/10, accuracy: 0.9219
 * Micro Average: f1: 0.8199, precision: 0.8071, recall: 0.8331
 * Macro Average: f1: 0.6157, precision: 0.6058, recall: 0.6260

Epoch 8/10, accuracy: 0.9219
 * Micro Average: f1: 0.8193, precision: 0.8059, recall: 0.8331
 * Macro Average: f1: 0.6153, precision: 0.6050, recall: 0.6260

Epoch 9/10, accuracy: 0.9218
 * Micro Average: f1: 0.8195, precision: 0.8061, recall: 0.8333
 * Macro Average: f1: 0.6154, precision: 0.6052, recall: 0.6262

Epoch 10/10, accuracy: 0.9218
 * Micro Average: f1: 0.8189, precision: 0.8053, recall: 0.8329
 * Macro Average: f1: 0.6150, precision: 0.6046, recall: 0.6259

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7169
  * recall: 0.8327
  * f1-score: 0.7704
  * support: 526.0000
 ORG:
  * precision: 0.5212
  * recall: 0.7401
  * f1-score: 0.6117
  * support: 581.0000
 PER:
  * precision: 0.7631
  * recall: 0.9178
  * f1-score: 0.8333
  * support: 365.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6396
  * recall: 0.8173
  * f1-score: 0.7176
  * support: 1472.0000
 macro avg:
  * precision: 0.5003
  * recall: 0.6227
  * f1-score: 0.5539
  * support: 1472.0000
 weighted avg:
  * precision: 0.6511
  * recall: 0.8173
  * f1-score: 0.7234
  * support: 1472.0000
 accuracy:
  * 0.8720
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.2 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9219
 * Micro Average: f1: 0.8204, precision: 0.8076, recall: 0.8337
 * Macro Average: f1: 0.6162, precision: 0.6063, recall: 0.6264

Epoch 2/10, accuracy: 0.9218
 * Micro Average: f1: 0.8200, precision: 0.8067, recall: 0.8337
 * Macro Average: f1: 0.6158, precision: 0.6056, recall: 0.6264

Epoch 3/10, accuracy: 0.9219
 * Micro Average: f1: 0.8206, precision: 0.8079, recall: 0.8337
 * Macro Average: f1: 0.6162, precision: 0.6064, recall: 0.6264

Epoch 4/10, accuracy: 0.9220
 * Micro Average: f1: 0.8210, precision: 0.8085, recall: 0.8339
 * Macro Average: f1: 0.6165, precision: 0.6069, recall: 0.6266

Epoch 5/10, accuracy: 0.9220
 * Micro Average: f1: 0.8211, precision: 0.8084, recall: 0.8342
 * Macro Average: f1: 0.6166, precision: 0.6068, recall: 0.6269

Epoch 6/10, accuracy: 0.9219
 * Micro Average: f1: 0.8209, precision: 0.8082, recall: 0.8340
 * Macro Average: f1: 0.6165, precision: 0.6067, recall: 0.6267

Epoch 7/10, accuracy: 0.9219
 * Micro Average: f1: 0.8211, precision: 0.8085, recall: 0.8340
 * Macro Average: f1: 0.6166, precision: 0.6069, recall: 0.6267

Epoch 8/10, accuracy: 0.9219
 * Micro Average: f1: 0.8215, precision: 0.8091, recall: 0.8342
 * Macro Average: f1: 0.6169, precision: 0.6073, recall: 0.6269

Epoch 9/10, accuracy: 0.9219
 * Micro Average: f1: 0.8211, precision: 0.8085, recall: 0.8340
 * Macro Average: f1: 0.6166, precision: 0.6069, recall: 0.6267

Epoch 10/10, accuracy: 0.9219
 * Micro Average: f1: 0.8208, precision: 0.8081, recall: 0.8339
 * Macro Average: f1: 0.6164, precision: 0.6066, recall: 0.6266

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7162
  * recall: 0.8346
  * f1-score: 0.7709
  * support: 526.0000
 ORG:
  * precision: 0.5187
  * recall: 0.7384
  * f1-score: 0.6094
  * support: 581.0000
 PER:
  * precision: 0.7631
  * recall: 0.9178
  * f1-score: 0.8333
  * support: 365.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6382
  * recall: 0.8173
  * f1-score: 0.7167
  * support: 1472.0000
 macro avg:
  * precision: 0.4995
  * recall: 0.6227
  * f1-score: 0.5534
  * support: 1472.0000
 weighted avg:
  * precision: 0.6499
  * recall: 0.8173
  * f1-score: 0.7226
  * support: 1472.0000
 accuracy:
  * 0.8719
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.3 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9196
 * Micro Average: f1: 0.8119, precision: 0.7953, recall: 0.8291
 * Macro Average: f1: 0.6091, precision: 0.5962, recall: 0.6233

Epoch 2/10, accuracy: 0.9198
 * Micro Average: f1: 0.8120, precision: 0.7955, recall: 0.8293
 * Macro Average: f1: 0.6093, precision: 0.5963, recall: 0.6234

Epoch 3/10, accuracy: 0.9198
 * Micro Average: f1: 0.8111, precision: 0.7945, recall: 0.8284
 * Macro Average: f1: 0.6085, precision: 0.5956, recall: 0.6227

Epoch 4/10, accuracy: 0.9199
 * Micro Average: f1: 0.8114, precision: 0.7948, recall: 0.8287
 * Macro Average: f1: 0.6088, precision: 0.5958, recall: 0.6230

Epoch 5/10, accuracy: 0.9200
 * Micro Average: f1: 0.8108, precision: 0.7936, recall: 0.8287
 * Macro Average: f1: 0.6083, precision: 0.5949, recall: 0.6230

Epoch 6/10, accuracy: 0.9201
 * Micro Average: f1: 0.8119, precision: 0.7955, recall: 0.8291
 * Macro Average: f1: 0.6092, precision: 0.5963, recall: 0.6232

Epoch 7/10, accuracy: 0.9202
 * Micro Average: f1: 0.8126, precision: 0.7962, recall: 0.8298
 * Macro Average: f1: 0.6098, precision: 0.5969, recall: 0.6238

Epoch 8/10, accuracy: 0.9201
 * Micro Average: f1: 0.8126, precision: 0.7960, recall: 0.8298
 * Macro Average: f1: 0.6097, precision: 0.5968, recall: 0.6238

Epoch 9/10, accuracy: 0.9202
 * Micro Average: f1: 0.8125, precision: 0.7959, recall: 0.8298
 * Macro Average: f1: 0.6096, precision: 0.5966, recall: 0.6238

Epoch 10/10, accuracy: 0.9201
 * Micro Average: f1: 0.8123, precision: 0.7957, recall: 0.8297
 * Macro Average: f1: 0.6095, precision: 0.5965, recall: 0.6236

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6951
  * recall: 0.8365
  * f1-score: 0.7593
  * support: 526.0000
 ORG:
  * precision: 0.5309
  * recall: 0.7384
  * f1-score: 0.6177
  * support: 581.0000
 PER:
  * precision: 0.7045
  * recall: 0.9342
  * f1-score: 0.8033
  * support: 365.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6266
  * recall: 0.8220
  * f1-score: 0.7111
  * support: 1472.0000
 macro avg:
  * precision: 0.4826
  * recall: 0.6273
  * f1-score: 0.5451
  * support: 1472.0000
 weighted avg:
  * precision: 0.6326
  * recall: 0.8220
  * f1-score: 0.7143
  * support: 1472.0000
 accuracy:
  * 0.8642
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.3 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9200
 * Micro Average: f1: 0.8128, precision: 0.7965, recall: 0.8297
 * Macro Average: f1: 0.6098, precision: 0.5971, recall: 0.6237

Epoch 2/10, accuracy: 0.9200
 * Micro Average: f1: 0.8115, precision: 0.7947, recall: 0.8289
 * Macro Average: f1: 0.6088, precision: 0.5957, recall: 0.6231

Epoch 3/10, accuracy: 0.9201
 * Micro Average: f1: 0.8133, precision: 0.7972, recall: 0.8300
 * Macro Average: f1: 0.6102, precision: 0.5976, recall: 0.6239

Epoch 4/10, accuracy: 0.9201
 * Micro Average: f1: 0.8131, precision: 0.7970, recall: 0.8298
 * Macro Average: f1: 0.6100, precision: 0.5975, recall: 0.6238

Epoch 5/10, accuracy: 0.9202
 * Micro Average: f1: 0.8123, precision: 0.7957, recall: 0.8297
 * Macro Average: f1: 0.6095, precision: 0.5965, recall: 0.6236

Epoch 6/10, accuracy: 0.9203
 * Micro Average: f1: 0.8128, precision: 0.7962, recall: 0.8300
 * Macro Average: f1: 0.6098, precision: 0.5969, recall: 0.6239

Epoch 7/10, accuracy: 0.9203
 * Micro Average: f1: 0.8122, precision: 0.7954, recall: 0.8297
 * Macro Average: f1: 0.6094, precision: 0.5963, recall: 0.6236

Epoch 8/10, accuracy: 0.9203
 * Micro Average: f1: 0.8126, precision: 0.7960, recall: 0.8298
 * Macro Average: f1: 0.6097, precision: 0.5967, recall: 0.6238

Epoch 9/10, accuracy: 0.9202
 * Micro Average: f1: 0.8125, precision: 0.7959, recall: 0.8298
 * Macro Average: f1: 0.6096, precision: 0.5966, recall: 0.6238

Epoch 10/10, accuracy: 0.9203
 * Micro Average: f1: 0.8124, precision: 0.7956, recall: 0.8298
 * Macro Average: f1: 0.6095, precision: 0.5964, recall: 0.6238

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6956
  * recall: 0.8384
  * f1-score: 0.7603
  * support: 526.0000
 ORG:
  * precision: 0.5290
  * recall: 0.7384
  * f1-score: 0.6164
  * support: 581.0000
 PER:
  * precision: 0.7089
  * recall: 0.9342
  * f1-score: 0.8061
  * support: 365.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6265
  * recall: 0.8227
  * f1-score: 0.7113
  * support: 1472.0000
 macro avg:
  * precision: 0.4834
  * recall: 0.6278
  * f1-score: 0.5457
  * support: 1472.0000
 weighted avg:
  * precision: 0.6331
  * recall: 0.8227
  * f1-score: 0.7149
  * support: 1472.0000
 accuracy:
  * 0.8640
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.4 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9186
 * Micro Average: f1: 0.8059, precision: 0.7872, recall: 0.8256
 * Macro Average: f1: 0.4835, precision: 0.4719, recall: 0.4966

Epoch 2/10, accuracy: 0.9182
 * Micro Average: f1: 0.8046, precision: 0.7855, recall: 0.8247
 * Macro Average: f1: 0.4826, precision: 0.4709, recall: 0.4961

Epoch 3/10, accuracy: 0.9180
 * Micro Average: f1: 0.8024, precision: 0.7824, recall: 0.8235
 * Macro Average: f1: 0.4812, precision: 0.4690, recall: 0.4954

Epoch 4/10, accuracy: 0.9179
 * Micro Average: f1: 0.8017, precision: 0.7816, recall: 0.8229
 * Macro Average: f1: 0.4807, precision: 0.4685, recall: 0.4951

Epoch 5/10, accuracy: 0.9178
 * Micro Average: f1: 0.8009, precision: 0.7806, recall: 0.8222
 * Macro Average: f1: 0.4802, precision: 0.4679, recall: 0.4946

Epoch 6/10, accuracy: 0.9179
 * Micro Average: f1: 0.8004, precision: 0.7799, recall: 0.8220
 * Macro Average: f1: 0.4799, precision: 0.4675, recall: 0.4945

Epoch 7/10, accuracy: 0.9178
 * Micro Average: f1: 0.7998, precision: 0.7789, recall: 0.8218
 * Macro Average: f1: 0.4795, precision: 0.4669, recall: 0.4944

Epoch 8/10, accuracy: 0.9178
 * Micro Average: f1: 0.8002, precision: 0.7797, recall: 0.8218
 * Macro Average: f1: 0.4798, precision: 0.4674, recall: 0.4944

Epoch 9/10, accuracy: 0.9178
 * Micro Average: f1: 0.8002, precision: 0.7797, recall: 0.8218
 * Macro Average: f1: 0.4798, precision: 0.4674, recall: 0.4944

Epoch 10/10, accuracy: 0.9178
 * Micro Average: f1: 0.8001, precision: 0.7796, recall: 0.8218
 * Macro Average: f1: 0.4798, precision: 0.4673, recall: 0.4944

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6687
  * recall: 0.8365
  * f1-score: 0.7432
  * support: 526.0000
 ORG:
  * precision: 0.5404
  * recall: 0.7367
  * f1-score: 0.6235
  * support: 581.0000
 PER:
  * precision: 0.6348
  * recall: 0.9288
  * f1-score: 0.7542
  * support: 365.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6056
  * recall: 0.8200
  * f1-score: 0.6967
  * support: 1472.0000
 macro avg:
  * precision: 0.4610
  * recall: 0.6255
  * f1-score: 0.5302
  * support: 1472.0000
 weighted avg:
  * precision: 0.6097
  * recall: 0.8200
  * f1-score: 0.6987
  * support: 1472.0000
 accuracy:
  * 0.8572
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.4 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9178
 * Micro Average: f1: 0.7998, precision: 0.7791, recall: 0.8216
 * Macro Average: f1: 0.4795, precision: 0.4670, recall: 0.4943

Epoch 2/10, accuracy: 0.9178
 * Micro Average: f1: 0.7995, precision: 0.7787, recall: 0.8214
 * Macro Average: f1: 0.4794, precision: 0.4667, recall: 0.4942

Epoch 3/10, accuracy: 0.9177
 * Micro Average: f1: 0.7996, precision: 0.7788, recall: 0.8214
 * Macro Average: f1: 0.4794, precision: 0.4668, recall: 0.4942

Epoch 4/10, accuracy: 0.9176
 * Micro Average: f1: 0.7999, precision: 0.7793, recall: 0.8216
 * Macro Average: f1: 0.4795, precision: 0.4671, recall: 0.4943

Epoch 5/10, accuracy: 0.9177
 * Micro Average: f1: 0.8002, precision: 0.7795, recall: 0.8220
 * Macro Average: f1: 0.4797, precision: 0.4672, recall: 0.4946

Epoch 6/10, accuracy: 0.9176
 * Micro Average: f1: 0.7995, precision: 0.7786, recall: 0.8216
 * Macro Average: f1: 0.4793, precision: 0.4667, recall: 0.4943

Epoch 7/10, accuracy: 0.9176
 * Micro Average: f1: 0.7994, precision: 0.7786, recall: 0.8214
 * Macro Average: f1: 0.4793, precision: 0.4667, recall: 0.4942

Epoch 8/10, accuracy: 0.9176
 * Micro Average: f1: 0.7994, precision: 0.7784, recall: 0.8214
 * Macro Average: f1: 0.4792, precision: 0.4666, recall: 0.4942

Epoch 9/10, accuracy: 0.9175
 * Micro Average: f1: 0.7989, precision: 0.7780, recall: 0.8211
 * Macro Average: f1: 0.4790, precision: 0.4663, recall: 0.4940

Epoch 10/10, accuracy: 0.9175
 * Micro Average: f1: 0.7989, precision: 0.7778, recall: 0.8211
 * Macro Average: f1: 0.4789, precision: 0.4662, recall: 0.4940

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6728
  * recall: 0.8403
  * f1-score: 0.7473
  * support: 526.0000
 ORG:
  * precision: 0.5407
  * recall: 0.7315
  * f1-score: 0.6218
  * support: 581.0000
 PER:
  * precision: 0.6266
  * recall: 0.9288
  * f1-score: 0.7483
  * support: 365.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6051
  * recall: 0.8193
  * f1-score: 0.6961
  * support: 1472.0000
 macro avg:
  * precision: 0.4600
  * recall: 0.6251
  * f1-score: 0.5293
  * support: 1472.0000
 weighted avg:
  * precision: 0.6092
  * recall: 0.8193
  * f1-score: 0.6980
  * support: 1472.0000
 accuracy:
  * 0.8568
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.1 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9200
 * Micro Average: f1: 0.8097, precision: 0.7921, recall: 0.8282
 * Macro Average: f1: 0.4859, precision: 0.4751, recall: 0.4981

Epoch 2/10, accuracy: 0.9214
 * Micro Average: f1: 0.8158, precision: 0.7990, recall: 0.8333
 * Macro Average: f1: 0.4899, precision: 0.4795, recall: 0.5010

Epoch 3/10, accuracy: 0.9219
 * Micro Average: f1: 0.8160, precision: 0.7989, recall: 0.8339
 * Macro Average: f1: 0.4902, precision: 0.4797, recall: 0.5013

Epoch 4/10, accuracy: 0.9217
 * Micro Average: f1: 0.8156, precision: 0.7983, recall: 0.8337
 * Macro Average: f1: 0.4901, precision: 0.4797, recall: 0.5011

Epoch 5/10, accuracy: 0.9218
 * Micro Average: f1: 0.8173, precision: 0.8013, recall: 0.8339
 * Macro Average: f1: 0.4911, precision: 0.4815, recall: 0.5012

Epoch 6/10, accuracy: 0.9220
 * Micro Average: f1: 0.8179, precision: 0.8018, recall: 0.8346
 * Macro Average: f1: 0.6144, precision: 0.6023, recall: 0.6271

Epoch 7/10, accuracy: 0.9220
 * Micro Average: f1: 0.8184, precision: 0.8023, recall: 0.8352
 * Macro Average: f1: 0.6149, precision: 0.6028, recall: 0.6275

Epoch 8/10, accuracy: 0.9221
 * Micro Average: f1: 0.8195, precision: 0.8037, recall: 0.8359
 * Macro Average: f1: 0.6157, precision: 0.6039, recall: 0.6280

Epoch 9/10, accuracy: 0.9221
 * Micro Average: f1: 0.8204, precision: 0.8051, recall: 0.8363
 * Macro Average: f1: 0.6163, precision: 0.6049, recall: 0.6283

Epoch 10/10, accuracy: 0.9222
 * Micro Average: f1: 0.8212, precision: 0.8063, recall: 0.8366
 * Macro Average: f1: 0.6169, precision: 0.6058, recall: 0.6286

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7143
  * recall: 0.8268
  * f1-score: 0.7665
  * support: 514.0000
 ORG:
  * precision: 0.5222
  * recall: 0.7632
  * f1-score: 0.6201
  * support: 570.0000
 PER:
  * precision: 0.7303
  * recall: 0.9233
  * f1-score: 0.8156
  * support: 352.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6303
  * recall: 0.8252
  * f1-score: 0.7147
  * support: 1436.0000
 macro avg:
  * precision: 0.4917
  * recall: 0.6283
  * f1-score: 0.5505
  * support: 1436.0000
 weighted avg:
  * precision: 0.6420
  * recall: 0.8252
  * f1-score: 0.7204
  * support: 1436.0000
 accuracy:
  * 0.8667
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.1 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9224
 * Micro Average: f1: 0.8224, precision: 0.8082, recall: 0.8370
 * Macro Average: f1: 0.6179, precision: 0.6074, recall: 0.6288

Epoch 2/10, accuracy: 0.9227
 * Micro Average: f1: 0.8224, precision: 0.8083, recall: 0.8370
 * Macro Average: f1: 0.6180, precision: 0.6076, recall: 0.6288

Epoch 3/10, accuracy: 0.9227
 * Micro Average: f1: 0.8234, precision: 0.8098, recall: 0.8374
 * Macro Average: f1: 0.6187, precision: 0.6088, recall: 0.6291

Epoch 4/10, accuracy: 0.9228
 * Micro Average: f1: 0.8241, precision: 0.8113, recall: 0.8374
 * Macro Average: f1: 0.6193, precision: 0.6099, recall: 0.6291

Epoch 5/10, accuracy: 0.9229
 * Micro Average: f1: 0.8243, precision: 0.8115, recall: 0.8376
 * Macro Average: f1: 0.6195, precision: 0.6100, recall: 0.6292

Epoch 6/10, accuracy: 0.9230
 * Micro Average: f1: 0.8241, precision: 0.8111, recall: 0.8374
 * Macro Average: f1: 0.6193, precision: 0.6099, recall: 0.6291

Epoch 7/10, accuracy: 0.9230
 * Micro Average: f1: 0.8241, precision: 0.8111, recall: 0.8374
 * Macro Average: f1: 0.6193, precision: 0.6099, recall: 0.6291

Epoch 8/10, accuracy: 0.9231
 * Micro Average: f1: 0.8247, precision: 0.8122, recall: 0.8376
 * Macro Average: f1: 0.6197, precision: 0.6106, recall: 0.6292

Epoch 9/10, accuracy: 0.9229
 * Micro Average: f1: 0.8239, precision: 0.8111, recall: 0.8372
 * Macro Average: f1: 0.6192, precision: 0.6098, recall: 0.6289

Epoch 10/10, accuracy: 0.9230
 * Micro Average: f1: 0.8238, precision: 0.8109, recall: 0.8370
 * Macro Average: f1: 0.6191, precision: 0.6096, recall: 0.6288

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7211
  * recall: 0.8249
  * f1-score: 0.7695
  * support: 514.0000
 ORG:
  * precision: 0.5261
  * recall: 0.7614
  * f1-score: 0.6222
  * support: 570.0000
 PER:
  * precision: 0.7589
  * recall: 0.9119
  * f1-score: 0.8284
  * support: 352.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6397
  * recall: 0.8210
  * f1-score: 0.7191
  * support: 1436.0000
 macro avg:
  * precision: 0.5015
  * recall: 0.6246
  * f1-score: 0.5550
  * support: 1436.0000
 weighted avg:
  * precision: 0.6529
  * recall: 0.8210
  * f1-score: 0.7255
  * support: 1436.0000
 accuracy:
  * 0.8712
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.2 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9228
 * Micro Average: f1: 0.8231, precision: 0.8105, recall: 0.8361
 * Macro Average: f1: 0.6182, precision: 0.6086, recall: 0.6282

Epoch 2/10, accuracy: 0.9225
 * Micro Average: f1: 0.8225, precision: 0.8097, recall: 0.8357
 * Macro Average: f1: 0.6177, precision: 0.6079, recall: 0.6279

Epoch 3/10, accuracy: 0.9225
 * Micro Average: f1: 0.8228, precision: 0.8102, recall: 0.8359
 * Macro Average: f1: 0.6180, precision: 0.6083, recall: 0.6281

Epoch 4/10, accuracy: 0.9224
 * Micro Average: f1: 0.8227, precision: 0.8099, recall: 0.8359
 * Macro Average: f1: 0.6179, precision: 0.6080, recall: 0.6281

Epoch 5/10, accuracy: 0.9225
 * Micro Average: f1: 0.8229, precision: 0.8103, recall: 0.8359
 * Macro Average: f1: 0.6181, precision: 0.6084, recall: 0.6281

Epoch 6/10, accuracy: 0.9225
 * Micro Average: f1: 0.8231, precision: 0.8106, recall: 0.8359
 * Macro Average: f1: 0.6181, precision: 0.6086, recall: 0.6281

Epoch 7/10, accuracy: 0.9225
 * Micro Average: f1: 0.8230, precision: 0.8104, recall: 0.8359
 * Macro Average: f1: 0.6181, precision: 0.6085, recall: 0.6281

Epoch 8/10, accuracy: 0.9224
 * Micro Average: f1: 0.8228, precision: 0.8103, recall: 0.8357
 * Macro Average: f1: 0.6180, precision: 0.6083, recall: 0.6279

Epoch 9/10, accuracy: 0.9224
 * Micro Average: f1: 0.8225, precision: 0.8099, recall: 0.8355
 * Macro Average: f1: 0.6178, precision: 0.6081, recall: 0.6278

Epoch 10/10, accuracy: 0.9224
 * Micro Average: f1: 0.8226, precision: 0.8100, recall: 0.8357
 * Macro Average: f1: 0.6178, precision: 0.6081, recall: 0.6280

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7181
  * recall: 0.8327
  * f1-score: 0.7712
  * support: 514.0000
 ORG:
  * precision: 0.5291
  * recall: 0.7491
  * f1-score: 0.6202
  * support: 570.0000
 PER:
  * precision: 0.7617
  * recall: 0.9261
  * f1-score: 0.8359
  * support: 352.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6425
  * recall: 0.8224
  * f1-score: 0.7214
  * support: 1436.0000
 macro avg:
  * precision: 0.5022
  * recall: 0.6270
  * f1-score: 0.5568
  * support: 1436.0000
 weighted avg:
  * precision: 0.6538
  * recall: 0.8224
  * f1-score: 0.7271
  * support: 1436.0000
 accuracy:
  * 0.8711
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.2 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9225
 * Micro Average: f1: 0.8225, precision: 0.8098, recall: 0.8355
 * Macro Average: f1: 0.6177, precision: 0.6080, recall: 0.6278

Epoch 2/10, accuracy: 0.9223
 * Micro Average: f1: 0.8224, precision: 0.8098, recall: 0.8354
 * Macro Average: f1: 0.6176, precision: 0.6080, recall: 0.6277

Epoch 3/10, accuracy: 0.9223
 * Micro Average: f1: 0.8220, precision: 0.8090, recall: 0.8354
 * Macro Average: f1: 0.6174, precision: 0.6074, recall: 0.6277

Epoch 4/10, accuracy: 0.9224
 * Micro Average: f1: 0.8221, precision: 0.8092, recall: 0.8354
 * Macro Average: f1: 0.6174, precision: 0.6076, recall: 0.6277

Epoch 5/10, accuracy: 0.9223
 * Micro Average: f1: 0.8221, precision: 0.8093, recall: 0.8354
 * Macro Average: f1: 0.6175, precision: 0.6077, recall: 0.6277

Epoch 6/10, accuracy: 0.9224
 * Micro Average: f1: 0.8224, precision: 0.8098, recall: 0.8354
 * Macro Average: f1: 0.6176, precision: 0.6080, recall: 0.6277

Epoch 7/10, accuracy: 0.9224
 * Micro Average: f1: 0.8224, precision: 0.8097, recall: 0.8355
 * Macro Average: f1: 0.6177, precision: 0.6079, recall: 0.6278

Epoch 8/10, accuracy: 0.9223
 * Micro Average: f1: 0.8227, precision: 0.8103, recall: 0.8354
 * Macro Average: f1: 0.6179, precision: 0.6084, recall: 0.6277

Epoch 9/10, accuracy: 0.9223
 * Micro Average: f1: 0.8229, precision: 0.8107, recall: 0.8355
 * Macro Average: f1: 0.6181, precision: 0.6087, recall: 0.6278

Epoch 10/10, accuracy: 0.9223
 * Micro Average: f1: 0.8228, precision: 0.8104, recall: 0.8355
 * Macro Average: f1: 0.6180, precision: 0.6085, recall: 0.6278

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7133
  * recall: 0.8327
  * f1-score: 0.7684
  * support: 514.0000
 ORG:
  * precision: 0.5271
  * recall: 0.7509
  * f1-score: 0.6194
  * support: 570.0000
 PER:
  * precision: 0.7647
  * recall: 0.9233
  * f1-score: 0.8366
  * support: 352.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6405
  * recall: 0.8224
  * f1-score: 0.7201
  * support: 1436.0000
 macro avg:
  * precision: 0.5013
  * recall: 0.6267
  * f1-score: 0.5561
  * support: 1436.0000
 weighted avg:
  * precision: 0.6520
  * recall: 0.8224
  * f1-score: 0.7260
  * support: 1436.0000
 accuracy:
  * 0.8714
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.3 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9210
 * Micro Average: f1: 0.8136, precision: 0.7967, recall: 0.8311
 * Macro Average: f1: 0.6105, precision: 0.5974, recall: 0.6247

Epoch 2/10, accuracy: 0.9208
 * Micro Average: f1: 0.8143, precision: 0.7979, recall: 0.8313
 * Macro Average: f1: 0.6110, precision: 0.5982, recall: 0.6248

Epoch 3/10, accuracy: 0.9206
 * Micro Average: f1: 0.8135, precision: 0.7966, recall: 0.8311
 * Macro Average: f1: 0.6103, precision: 0.5972, recall: 0.6247

Epoch 4/10, accuracy: 0.9207
 * Micro Average: f1: 0.8138, precision: 0.7971, recall: 0.8311
 * Macro Average: f1: 0.6106, precision: 0.5976, recall: 0.6247

Epoch 5/10, accuracy: 0.9207
 * Micro Average: f1: 0.8133, precision: 0.7962, recall: 0.8311
 * Macro Average: f1: 0.6102, precision: 0.5969, recall: 0.6247

Epoch 6/10, accuracy: 0.9207
 * Micro Average: f1: 0.8136, precision: 0.7966, recall: 0.8313
 * Macro Average: f1: 0.6105, precision: 0.5972, recall: 0.6249

Epoch 7/10, accuracy: 0.9208
 * Micro Average: f1: 0.8140, precision: 0.7971, recall: 0.8317
 * Macro Average: f1: 0.6108, precision: 0.5976, recall: 0.6251

Epoch 8/10, accuracy: 0.9207
 * Micro Average: f1: 0.8142, precision: 0.7974, recall: 0.8317
 * Macro Average: f1: 0.6109, precision: 0.5978, recall: 0.6251

Epoch 9/10, accuracy: 0.9208
 * Micro Average: f1: 0.8146, precision: 0.7981, recall: 0.8319
 * Macro Average: f1: 0.6113, precision: 0.5984, recall: 0.6253

Epoch 10/10, accuracy: 0.9207
 * Micro Average: f1: 0.8143, precision: 0.7977, recall: 0.8317
 * Macro Average: f1: 0.6110, precision: 0.5981, recall: 0.6251

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6858
  * recall: 0.8366
  * f1-score: 0.7537
  * support: 514.0000
 ORG:
  * precision: 0.5280
  * recall: 0.7456
  * f1-score: 0.6182
  * support: 570.0000
 PER:
  * precision: 0.7137
  * recall: 0.9347
  * f1-score: 0.8093
  * support: 352.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6232
  * recall: 0.8245
  * f1-score: 0.7098
  * support: 1436.0000
 macro avg:
  * precision: 0.4819
  * recall: 0.6292
  * f1-score: 0.5453
  * support: 1436.0000
 weighted avg:
  * precision: 0.6300
  * recall: 0.8245
  * f1-score: 0.7136
  * support: 1436.0000
 accuracy:
  * 0.8638
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.3 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9209
 * Micro Average: f1: 0.8149, precision: 0.7981, recall: 0.8324
 * Macro Average: f1: 0.6115, precision: 0.5984, recall: 0.6257

Epoch 2/10, accuracy: 0.9208
 * Micro Average: f1: 0.8150, precision: 0.7985, recall: 0.8322
 * Macro Average: f1: 0.6115, precision: 0.5986, recall: 0.6255

Epoch 3/10, accuracy: 0.9209
 * Micro Average: f1: 0.8153, precision: 0.7988, recall: 0.8324
 * Macro Average: f1: 0.6117, precision: 0.5989, recall: 0.6257

Epoch 4/10, accuracy: 0.9207
 * Micro Average: f1: 0.8149, precision: 0.7982, recall: 0.8322
 * Macro Average: f1: 0.6114, precision: 0.5985, recall: 0.6255

Epoch 5/10, accuracy: 0.9209
 * Micro Average: f1: 0.8151, precision: 0.7983, recall: 0.8326
 * Macro Average: f1: 0.6116, precision: 0.5985, recall: 0.6258

Epoch 6/10, accuracy: 0.9208
 * Micro Average: f1: 0.8151, precision: 0.7985, recall: 0.8324
 * Macro Average: f1: 0.6116, precision: 0.5987, recall: 0.6257

Epoch 7/10, accuracy: 0.9207
 * Micro Average: f1: 0.8148, precision: 0.7981, recall: 0.8322
 * Macro Average: f1: 0.6114, precision: 0.5984, recall: 0.6255

Epoch 8/10, accuracy: 0.9207
 * Micro Average: f1: 0.8151, precision: 0.7985, recall: 0.8324
 * Macro Average: f1: 0.6116, precision: 0.5987, recall: 0.6257

Epoch 9/10, accuracy: 0.9206
 * Micro Average: f1: 0.8144, precision: 0.7976, recall: 0.8319
 * Macro Average: f1: 0.6111, precision: 0.5980, recall: 0.6253

Epoch 10/10, accuracy: 0.9207
 * Micro Average: f1: 0.8141, precision: 0.7971, recall: 0.8319
 * Macro Average: f1: 0.6109, precision: 0.5977, recall: 0.6253

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6896
  * recall: 0.8385
  * f1-score: 0.7568
  * support: 514.0000
 ORG:
  * precision: 0.5319
  * recall: 0.7456
  * f1-score: 0.6209
  * support: 570.0000
 PER:
  * precision: 0.7106
  * recall: 0.9347
  * f1-score: 0.8074
  * support: 352.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6257
  * recall: 0.8252
  * f1-score: 0.7117
  * support: 1436.0000
 macro avg:
  * precision: 0.4830
  * recall: 0.6297
  * f1-score: 0.5463
  * support: 1436.0000
 weighted avg:
  * precision: 0.6322
  * recall: 0.8252
  * f1-score: 0.7152
  * support: 1436.0000
 accuracy:
  * 0.8633
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.4 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9192
 * Micro Average: f1: 0.8067, precision: 0.7872, recall: 0.8273
 * Macro Average: f1: 0.4840, precision: 0.4720, recall: 0.4976

Epoch 2/10, accuracy: 0.9188
 * Micro Average: f1: 0.8051, precision: 0.7852, recall: 0.8260
 * Macro Average: f1: 0.4829, precision: 0.4707, recall: 0.4968

Epoch 3/10, accuracy: 0.9185
 * Micro Average: f1: 0.8049, precision: 0.7857, recall: 0.8251
 * Macro Average: f1: 0.4828, precision: 0.4710, recall: 0.4963

Epoch 4/10, accuracy: 0.9185
 * Micro Average: f1: 0.8039, precision: 0.7841, recall: 0.8247
 * Macro Average: f1: 0.4821, precision: 0.4700, recall: 0.4961

Epoch 5/10, accuracy: 0.9186
 * Micro Average: f1: 0.8042, precision: 0.7845, recall: 0.8249
 * Macro Average: f1: 0.4823, precision: 0.4703, recall: 0.4962

Epoch 6/10, accuracy: 0.9186
 * Micro Average: f1: 0.8047, precision: 0.7855, recall: 0.8249
 * Macro Average: f1: 0.4826, precision: 0.4709, recall: 0.4962

Epoch 7/10, accuracy: 0.9185
 * Micro Average: f1: 0.8037, precision: 0.7839, recall: 0.8245
 * Macro Average: f1: 0.4819, precision: 0.4700, recall: 0.4960

Epoch 8/10, accuracy: 0.9184
 * Micro Average: f1: 0.8034, precision: 0.7836, recall: 0.8243
 * Macro Average: f1: 0.4818, precision: 0.4698, recall: 0.4959

Epoch 9/10, accuracy: 0.9185
 * Micro Average: f1: 0.8034, precision: 0.7834, recall: 0.8243
 * Macro Average: f1: 0.4817, precision: 0.4697, recall: 0.4959

Epoch 10/10, accuracy: 0.9184
 * Micro Average: f1: 0.8030, precision: 0.7830, recall: 0.8241
 * Macro Average: f1: 0.4815, precision: 0.4694, recall: 0.4958

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6636
  * recall: 0.8366
  * f1-score: 0.7401
  * support: 514.0000
 ORG:
  * precision: 0.5444
  * recall: 0.7421
  * f1-score: 0.6281
  * support: 570.0000
 PER:
  * precision: 0.6342
  * recall: 0.9261
  * f1-score: 0.7529
  * support: 352.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6052
  * recall: 0.8210
  * f1-score: 0.6968
  * support: 1436.0000
 macro avg:
  * precision: 0.4606
  * recall: 0.6262
  * f1-score: 0.5303
  * support: 1436.0000
 weighted avg:
  * precision: 0.6091
  * recall: 0.8210
  * f1-score: 0.6988
  * support: 1436.0000
 accuracy:
  * 0.8571
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.4 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9183
 * Micro Average: f1: 0.8013, precision: 0.7805, recall: 0.8232
 * Macro Average: f1: 0.4805, precision: 0.4679, recall: 0.4953

Epoch 2/10, accuracy: 0.9182
 * Micro Average: f1: 0.8009, precision: 0.7802, recall: 0.8227
 * Macro Average: f1: 0.4802, precision: 0.4677, recall: 0.4950

Epoch 3/10, accuracy: 0.9182
 * Micro Average: f1: 0.8005, precision: 0.7794, recall: 0.8227
 * Macro Average: f1: 0.4799, precision: 0.4672, recall: 0.4950

Epoch 4/10, accuracy: 0.9181
 * Micro Average: f1: 0.8003, precision: 0.7795, recall: 0.8223
 * Macro Average: f1: 0.4799, precision: 0.4672, recall: 0.4947

Epoch 5/10, accuracy: 0.9181
 * Micro Average: f1: 0.7999, precision: 0.7790, recall: 0.8219
 * Macro Average: f1: 0.4796, precision: 0.4669, recall: 0.4945

Epoch 6/10, accuracy: 0.9180
 * Micro Average: f1: 0.7990, precision: 0.7778, recall: 0.8214
 * Macro Average: f1: 0.4790, precision: 0.4662, recall: 0.4942

Epoch 7/10, accuracy: 0.9181
 * Micro Average: f1: 0.7996, precision: 0.7786, recall: 0.8218
 * Macro Average: f1: 0.4794, precision: 0.4667, recall: 0.4944

Epoch 8/10, accuracy: 0.9181
 * Micro Average: f1: 0.7992, precision: 0.7781, recall: 0.8216
 * Macro Average: f1: 0.4792, precision: 0.4664, recall: 0.4943

Epoch 9/10, accuracy: 0.9181
 * Micro Average: f1: 0.7994, precision: 0.7783, recall: 0.8218
 * Macro Average: f1: 0.4793, precision: 0.4665, recall: 0.4944

Epoch 10/10, accuracy: 0.9181
 * Micro Average: f1: 0.7993, precision: 0.7782, recall: 0.8216
 * Macro Average: f1: 0.4792, precision: 0.4665, recall: 0.4943

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6672
  * recall: 0.8424
  * f1-score: 0.7446
  * support: 514.0000
 ORG:
  * precision: 0.5501
  * recall: 0.7421
  * f1-score: 0.6318
  * support: 570.0000
 PER:
  * precision: 0.6293
  * recall: 0.9261
  * f1-score: 0.7494
  * support: 352.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6077
  * recall: 0.8231
  * f1-score: 0.6992
  * support: 1436.0000
 macro avg:
  * precision: 0.4616
  * recall: 0.6277
  * f1-score: 0.5315
  * support: 1436.0000
 weighted avg:
  * precision: 0.6114
  * recall: 0.8231
  * f1-score: 0.7010
  * support: 1436.0000
 accuracy:
  * 0.8568
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 128
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.1 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9197
 * Micro Average: f1: 0.8060, precision: 0.7863, recall: 0.8267
 * Macro Average: f1: 0.4836, precision: 0.4714, recall: 0.4973

Epoch 2/10, accuracy: 0.9206
 * Micro Average: f1: 0.8120, precision: 0.7939, recall: 0.8309
 * Macro Average: f1: 0.4874, precision: 0.4762, recall: 0.4997

Epoch 3/10, accuracy: 0.9214
 * Micro Average: f1: 0.8148, precision: 0.7974, recall: 0.8330
 * Macro Average: f1: 0.4893, precision: 0.4786, recall: 0.5008

Epoch 4/10, accuracy: 0.9216
 * Micro Average: f1: 0.8152, precision: 0.7975, recall: 0.8337
 * Macro Average: f1: 0.4896, precision: 0.4788, recall: 0.5012

Epoch 5/10, accuracy: 0.9219
 * Micro Average: f1: 0.8159, precision: 0.7986, recall: 0.8341
 * Macro Average: f1: 0.4901, precision: 0.4795, recall: 0.5014

Epoch 6/10, accuracy: 0.9221
 * Micro Average: f1: 0.8165, precision: 0.7993, recall: 0.8344
 * Macro Average: f1: 0.4905, precision: 0.4801, recall: 0.5016

Epoch 7/10, accuracy: 0.9217
 * Micro Average: f1: 0.8155, precision: 0.7981, recall: 0.8337
 * Macro Average: f1: 0.4900, precision: 0.4795, recall: 0.5011

Epoch 8/10, accuracy: 0.9217
 * Micro Average: f1: 0.8160, precision: 0.7989, recall: 0.8339
 * Macro Average: f1: 0.4903, precision: 0.4800, recall: 0.5012

Epoch 9/10, accuracy: 0.9218
 * Micro Average: f1: 0.8169, precision: 0.8004, recall: 0.8341
 * Macro Average: f1: 0.4909, precision: 0.4809, recall: 0.5013

Epoch 10/10, accuracy: 0.9217
 * Micro Average: f1: 0.8170, precision: 0.8007, recall: 0.8341
 * Macro Average: f1: 0.4909, precision: 0.4811, recall: 0.5013

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7184
  * recall: 0.8593
  * f1-score: 0.7825
  * support: 469.0000
 ORG:
  * precision: 0.5431
  * recall: 0.7687
  * f1-score: 0.6365
  * support: 549.0000
 PER:
  * precision: 0.7335
  * recall: 0.9339
  * f1-score: 0.8217
  * support: 333.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6422
  * recall: 0.8409
  * f1-score: 0.7282
  * support: 1351.0000
 macro avg:
  * precision: 0.4987
  * recall: 0.6405
  * f1-score: 0.5602
  * support: 1351.0000
 weighted avg:
  * precision: 0.6509
  * recall: 0.8409
  * f1-score: 0.7328
  * support: 1351.0000
 accuracy:
  * 0.8680
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 128
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.1 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9217
 * Micro Average: f1: 0.8173, precision: 0.8010, recall: 0.8343
 * Macro Average: f1: 0.4912, precision: 0.4814, recall: 0.5014

Epoch 2/10, accuracy: 0.9221
 * Micro Average: f1: 0.8186, precision: 0.8024, recall: 0.8355
 * Macro Average: f1: 0.4920, precision: 0.4823, recall: 0.5022

Epoch 3/10, accuracy: 0.9220
 * Micro Average: f1: 0.8201, precision: 0.8047, recall: 0.8361
 * Macro Average: f1: 0.6162, precision: 0.6047, recall: 0.6281

Epoch 4/10, accuracy: 0.9221
 * Micro Average: f1: 0.8218, precision: 0.8074, recall: 0.8366
 * Macro Average: f1: 0.6174, precision: 0.6067, recall: 0.6285

Epoch 5/10, accuracy: 0.9223
 * Micro Average: f1: 0.8219, precision: 0.8076, recall: 0.8368
 * Macro Average: f1: 0.6176, precision: 0.6069, recall: 0.6287

Epoch 6/10, accuracy: 0.9224
 * Micro Average: f1: 0.8220, precision: 0.8075, recall: 0.8370
 * Macro Average: f1: 0.6176, precision: 0.6069, recall: 0.6288

Epoch 7/10, accuracy: 0.9224
 * Micro Average: f1: 0.8222, precision: 0.8079, recall: 0.8370
 * Macro Average: f1: 0.6178, precision: 0.6072, recall: 0.6288

Epoch 8/10, accuracy: 0.9225
 * Micro Average: f1: 0.8222, precision: 0.8079, recall: 0.8370
 * Macro Average: f1: 0.6178, precision: 0.6072, recall: 0.6288

Epoch 9/10, accuracy: 0.9225
 * Micro Average: f1: 0.8222, precision: 0.8079, recall: 0.8370
 * Macro Average: f1: 0.6178, precision: 0.6072, recall: 0.6288

Epoch 10/10, accuracy: 0.9225
 * Micro Average: f1: 0.8222, precision: 0.8079, recall: 0.8370
 * Macro Average: f1: 0.6178, precision: 0.6072, recall: 0.6288

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7246
  * recall: 0.8529
  * f1-score: 0.7835
  * support: 469.0000
 ORG:
  * precision: 0.5448
  * recall: 0.7760
  * f1-score: 0.6401
  * support: 549.0000
 PER:
  * precision: 0.7518
  * recall: 0.9189
  * f1-score: 0.8270
  * support: 333.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6480
  * recall: 0.8379
  * f1-score: 0.7308
  * support: 1351.0000
 macro avg:
  * precision: 0.5053
  * recall: 0.6369
  * f1-score: 0.5627
  * support: 1351.0000
 weighted avg:
  * precision: 0.6582
  * recall: 0.8379
  * f1-score: 0.7360
  * support: 1351.0000
 accuracy:
  * 0.8722
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 128
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.2 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9227
 * Micro Average: f1: 0.8223, precision: 0.8083, recall: 0.8368
 * Macro Average: f1: 0.6178, precision: 0.6072, recall: 0.6287

Epoch 2/10, accuracy: 0.9227
 * Micro Average: f1: 0.8213, precision: 0.8070, recall: 0.8361
 * Macro Average: f1: 0.6169, precision: 0.6061, recall: 0.6282

Epoch 3/10, accuracy: 0.9227
 * Micro Average: f1: 0.8212, precision: 0.8074, recall: 0.8355
 * Macro Average: f1: 0.6168, precision: 0.6063, recall: 0.6278

Epoch 4/10, accuracy: 0.9227
 * Micro Average: f1: 0.8218, precision: 0.8082, recall: 0.8357
 * Macro Average: f1: 0.6172, precision: 0.6069, recall: 0.6279

Epoch 5/10, accuracy: 0.9227
 * Micro Average: f1: 0.8215, precision: 0.8078, recall: 0.8357
 * Macro Average: f1: 0.6171, precision: 0.6066, recall: 0.6279

Epoch 6/10, accuracy: 0.9227
 * Micro Average: f1: 0.8214, precision: 0.8078, recall: 0.8355
 * Macro Average: f1: 0.6170, precision: 0.6066, recall: 0.6278

Epoch 7/10, accuracy: 0.9227
 * Micro Average: f1: 0.8216, precision: 0.8081, recall: 0.8355
 * Macro Average: f1: 0.6171, precision: 0.6068, recall: 0.6278

Epoch 8/10, accuracy: 0.9226
 * Micro Average: f1: 0.8220, precision: 0.8087, recall: 0.8357
 * Macro Average: f1: 0.6174, precision: 0.6072, recall: 0.6279

Epoch 9/10, accuracy: 0.9226
 * Micro Average: f1: 0.8223, precision: 0.8091, recall: 0.8359
 * Macro Average: f1: 0.6176, precision: 0.6076, recall: 0.6281

Epoch 10/10, accuracy: 0.9226
 * Micro Average: f1: 0.8221, precision: 0.8088, recall: 0.8357
 * Macro Average: f1: 0.6174, precision: 0.6073, recall: 0.6279

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7171
  * recall: 0.8593
  * f1-score: 0.7818
  * support: 469.0000
 ORG:
  * precision: 0.5438
  * recall: 0.7577
  * f1-score: 0.6332
  * support: 549.0000
 PER:
  * precision: 0.7624
  * recall: 0.9249
  * f1-score: 0.8358
  * support: 333.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6488
  * recall: 0.8342
  * f1-score: 0.7299
  * support: 1351.0000
 macro avg:
  * precision: 0.5058
  * recall: 0.6355
  * f1-score: 0.5627
  * support: 1351.0000
 weighted avg:
  * precision: 0.6578
  * recall: 0.8342
  * f1-score: 0.7347
  * support: 1351.0000
 accuracy:
  * 0.8741
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 128
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.2 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9227
 * Micro Average: f1: 0.8227, precision: 0.8098, recall: 0.8361
 * Macro Average: f1: 0.6179, precision: 0.6081, recall: 0.6282

Epoch 2/10, accuracy: 0.9227
 * Micro Average: f1: 0.8224, precision: 0.8093, recall: 0.8359
 * Macro Average: f1: 0.6177, precision: 0.6077, recall: 0.6281

Epoch 3/10, accuracy: 0.9227
 * Micro Average: f1: 0.8225, precision: 0.8094, recall: 0.8359
 * Macro Average: f1: 0.6177, precision: 0.6078, recall: 0.6281

Epoch 4/10, accuracy: 0.9226
 * Micro Average: f1: 0.8225, precision: 0.8096, recall: 0.8359
 * Macro Average: f1: 0.6178, precision: 0.6080, recall: 0.6281

Epoch 5/10, accuracy: 0.9227
 * Micro Average: f1: 0.8225, precision: 0.8094, recall: 0.8359
 * Macro Average: f1: 0.6178, precision: 0.6078, recall: 0.6281

Epoch 6/10, accuracy: 0.9227
 * Micro Average: f1: 0.8225, precision: 0.8096, recall: 0.8359
 * Macro Average: f1: 0.6178, precision: 0.6079, recall: 0.6281

Epoch 7/10, accuracy: 0.9227
 * Micro Average: f1: 0.8228, precision: 0.8100, recall: 0.8359
 * Macro Average: f1: 0.6180, precision: 0.6082, recall: 0.6281

Epoch 8/10, accuracy: 0.9227
 * Micro Average: f1: 0.8228, precision: 0.8102, recall: 0.8359
 * Macro Average: f1: 0.6180, precision: 0.6084, recall: 0.6281

Epoch 9/10, accuracy: 0.9227
 * Micro Average: f1: 0.8228, precision: 0.8102, recall: 0.8359
 * Macro Average: f1: 0.6180, precision: 0.6084, recall: 0.6281

Epoch 10/10, accuracy: 0.9228
 * Micro Average: f1: 0.8227, precision: 0.8099, recall: 0.8359
 * Macro Average: f1: 0.6179, precision: 0.6082, recall: 0.6281

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7217
  * recall: 0.8571
  * f1-score: 0.7836
  * support: 469.0000
 ORG:
  * precision: 0.5437
  * recall: 0.7596
  * f1-score: 0.6337
  * support: 549.0000
 PER:
  * precision: 0.7706
  * recall: 0.9279
  * f1-score: 0.8420
  * support: 333.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6516
  * recall: 0.8349
  * f1-score: 0.7320
  * support: 1351.0000
 macro avg:
  * precision: 0.5090
  * recall: 0.6362
  * f1-score: 0.5648
  * support: 1351.0000
 weighted avg:
  * precision: 0.6614
  * recall: 0.8349
  * f1-score: 0.7371
  * support: 1351.0000
 accuracy:
  * 0.8744
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 128
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.3 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9215
 * Micro Average: f1: 0.8158, precision: 0.7997, recall: 0.8326
 * Macro Average: f1: 0.6123, precision: 0.5998, recall: 0.6258

Epoch 2/10, accuracy: 0.9211
 * Micro Average: f1: 0.8150, precision: 0.7984, recall: 0.8324
 * Macro Average: f1: 0.6116, precision: 0.5986, recall: 0.6257

Epoch 3/10, accuracy: 0.9208
 * Micro Average: f1: 0.8136, precision: 0.7966, recall: 0.8313
 * Macro Average: f1: 0.6106, precision: 0.5973, recall: 0.6249

Epoch 4/10, accuracy: 0.9207
 * Micro Average: f1: 0.8129, precision: 0.7958, recall: 0.8308
 * Macro Average: f1: 0.6099, precision: 0.5966, recall: 0.6245

Epoch 5/10, accuracy: 0.9208
 * Micro Average: f1: 0.8125, precision: 0.7951, recall: 0.8308
 * Macro Average: f1: 0.6097, precision: 0.5961, recall: 0.6245

Epoch 6/10, accuracy: 0.9207
 * Micro Average: f1: 0.8127, precision: 0.7955, recall: 0.8306
 * Macro Average: f1: 0.6098, precision: 0.5964, recall: 0.6243

Epoch 7/10, accuracy: 0.9208
 * Micro Average: f1: 0.8128, precision: 0.7957, recall: 0.8308
 * Macro Average: f1: 0.6099, precision: 0.5965, recall: 0.6245

Epoch 8/10, accuracy: 0.9208
 * Micro Average: f1: 0.8132, precision: 0.7963, recall: 0.8309
 * Macro Average: f1: 0.6102, precision: 0.5970, recall: 0.6246

Epoch 9/10, accuracy: 0.9208
 * Micro Average: f1: 0.8130, precision: 0.7958, recall: 0.8309
 * Macro Average: f1: 0.6101, precision: 0.5967, recall: 0.6246

Epoch 10/10, accuracy: 0.9208
 * Micro Average: f1: 0.8128, precision: 0.7955, recall: 0.8308
 * Macro Average: f1: 0.6099, precision: 0.5964, recall: 0.6244

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6882
  * recall: 0.8614
  * f1-score: 0.7652
  * support: 469.0000
 ORG:
  * precision: 0.5498
  * recall: 0.7541
  * f1-score: 0.6359
  * support: 549.0000
 PER:
  * precision: 0.7172
  * recall: 0.9369
  * f1-score: 0.8125
  * support: 333.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6345
  * recall: 0.8364
  * f1-score: 0.7216
  * support: 1351.0000
 macro avg:
  * precision: 0.4888
  * recall: 0.6381
  * f1-score: 0.5534
  * support: 1351.0000
 weighted avg:
  * precision: 0.6391
  * recall: 0.8364
  * f1-score: 0.7243
  * support: 1351.0000
 accuracy:
  * 0.8663
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 128
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.3 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9209
 * Micro Average: f1: 0.8130, precision: 0.7956, recall: 0.8311
 * Macro Average: f1: 0.6100, precision: 0.5965, recall: 0.6247

Epoch 2/10, accuracy: 0.9207
 * Micro Average: f1: 0.8137, precision: 0.7970, recall: 0.8311
 * Macro Average: f1: 0.6106, precision: 0.5976, recall: 0.6247

Epoch 3/10, accuracy: 0.9207
 * Micro Average: f1: 0.8141, precision: 0.7975, recall: 0.8315
 * Macro Average: f1: 0.6109, precision: 0.5980, recall: 0.6250

Epoch 4/10, accuracy: 0.9209
 * Micro Average: f1: 0.8140, precision: 0.7970, recall: 0.8317
 * Macro Average: f1: 0.6108, precision: 0.5976, recall: 0.6251

Epoch 5/10, accuracy: 0.9209
 * Micro Average: f1: 0.8134, precision: 0.7963, recall: 0.8313
 * Macro Average: f1: 0.6104, precision: 0.5971, recall: 0.6249

Epoch 6/10, accuracy: 0.9208
 * Micro Average: f1: 0.8137, precision: 0.7968, recall: 0.8313
 * Macro Average: f1: 0.6106, precision: 0.5974, recall: 0.6249

Epoch 7/10, accuracy: 0.9206
 * Micro Average: f1: 0.8137, precision: 0.7969, recall: 0.8313
 * Macro Average: f1: 0.6106, precision: 0.5975, recall: 0.6249

Epoch 8/10, accuracy: 0.9206
 * Micro Average: f1: 0.8136, precision: 0.7966, recall: 0.8313
 * Macro Average: f1: 0.6105, precision: 0.5973, recall: 0.6249

Epoch 9/10, accuracy: 0.9206
 * Micro Average: f1: 0.8137, precision: 0.7968, recall: 0.8313
 * Macro Average: f1: 0.6106, precision: 0.5974, recall: 0.6249

Epoch 10/10, accuracy: 0.9206
 * Micro Average: f1: 0.8137, precision: 0.7968, recall: 0.8313
 * Macro Average: f1: 0.6106, precision: 0.5974, recall: 0.6249

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6911
  * recall: 0.8635
  * f1-score: 0.7678
  * support: 469.0000
 ORG:
  * precision: 0.5526
  * recall: 0.7559
  * f1-score: 0.6385
  * support: 549.0000
 PER:
  * precision: 0.7206
  * recall: 0.9369
  * f1-score: 0.8146
  * support: 333.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6374
  * recall: 0.8379
  * f1-score: 0.7240
  * support: 1351.0000
 macro avg:
  * precision: 0.4911
  * recall: 0.6391
  * f1-score: 0.5552
  * support: 1351.0000
 weighted avg:
  * precision: 0.6421
  * recall: 0.8379
  * f1-score: 0.7268
  * support: 1351.0000
 accuracy:
  * 0.8662
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 128
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.4 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9198
 * Micro Average: f1: 0.8072, precision: 0.7877, recall: 0.8276
 * Macro Average: f1: 0.4843, precision: 0.4723, recall: 0.4978

Epoch 2/10, accuracy: 0.9194
 * Micro Average: f1: 0.8072, precision: 0.7876, recall: 0.8278
 * Macro Average: f1: 0.4843, precision: 0.4722, recall: 0.4979

Epoch 3/10, accuracy: 0.9192
 * Micro Average: f1: 0.8059, precision: 0.7857, recall: 0.8273
 * Macro Average: f1: 0.4835, precision: 0.4711, recall: 0.4976

Epoch 4/10, accuracy: 0.9193
 * Micro Average: f1: 0.8057, precision: 0.7854, recall: 0.8271
 * Macro Average: f1: 0.4833, precision: 0.4709, recall: 0.4975

Epoch 5/10, accuracy: 0.9192
 * Micro Average: f1: 0.8057, precision: 0.7855, recall: 0.8269
 * Macro Average: f1: 0.4833, precision: 0.4709, recall: 0.4974

Epoch 6/10, accuracy: 0.9191
 * Micro Average: f1: 0.8057, precision: 0.7857, recall: 0.8267
 * Macro Average: f1: 0.4833, precision: 0.4711, recall: 0.4973

Epoch 7/10, accuracy: 0.9190
 * Micro Average: f1: 0.8059, precision: 0.7862, recall: 0.8265
 * Macro Average: f1: 0.4833, precision: 0.4714, recall: 0.4972

Epoch 8/10, accuracy: 0.9190
 * Micro Average: f1: 0.8054, precision: 0.7856, recall: 0.8262
 * Macro Average: f1: 0.4830, precision: 0.4710, recall: 0.4970

Epoch 9/10, accuracy: 0.9189
 * Micro Average: f1: 0.8051, precision: 0.7853, recall: 0.8260
 * Macro Average: f1: 0.4829, precision: 0.4708, recall: 0.4969

Epoch 10/10, accuracy: 0.9189
 * Micro Average: f1: 0.8051, precision: 0.7853, recall: 0.8260
 * Macro Average: f1: 0.4829, precision: 0.4708, recall: 0.4969

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6716
  * recall: 0.8635
  * f1-score: 0.7556
  * support: 469.0000
 ORG:
  * precision: 0.5636
  * recall: 0.7505
  * f1-score: 0.6438
  * support: 549.0000
 PER:
  * precision: 0.6540
  * recall: 0.9309
  * f1-score: 0.7683
  * support: 333.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6206
  * recall: 0.8342
  * f1-score: 0.7117
  * support: 1351.0000
 macro avg:
  * precision: 0.4723
  * recall: 0.6362
  * f1-score: 0.5419
  * support: 1351.0000
 weighted avg:
  * precision: 0.6234
  * recall: 0.8342
  * f1-score: 0.7133
  * support: 1351.0000
 accuracy:
  * 0.8614
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 128
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.4 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9188
 * Micro Average: f1: 0.8040, precision: 0.7836, recall: 0.8256
 * Macro Average: f1: 0.4822, precision: 0.4697, recall: 0.4967

Epoch 2/10, accuracy: 0.9187
 * Micro Average: f1: 0.8029, precision: 0.7822, recall: 0.8247
 * Macro Average: f1: 0.4815, precision: 0.4689, recall: 0.4961

Epoch 3/10, accuracy: 0.9187
 * Micro Average: f1: 0.8029, precision: 0.7822, recall: 0.8247
 * Macro Average: f1: 0.4815, precision: 0.4689, recall: 0.4961

Epoch 4/10, accuracy: 0.9185
 * Micro Average: f1: 0.8018, precision: 0.7808, recall: 0.8240
 * Macro Average: f1: 0.4808, precision: 0.4680, recall: 0.4957

Epoch 5/10, accuracy: 0.9184
 * Micro Average: f1: 0.8017, precision: 0.7807, recall: 0.8238
 * Macro Average: f1: 0.4807, precision: 0.4680, recall: 0.4956

Epoch 6/10, accuracy: 0.9185
 * Micro Average: f1: 0.8017, precision: 0.7807, recall: 0.8238
 * Macro Average: f1: 0.4807, precision: 0.4680, recall: 0.4956

Epoch 7/10, accuracy: 0.9184
 * Micro Average: f1: 0.8014, precision: 0.7803, recall: 0.8236
 * Macro Average: f1: 0.4805, precision: 0.4677, recall: 0.4955

Epoch 8/10, accuracy: 0.9183
 * Micro Average: f1: 0.8016, precision: 0.7807, recall: 0.8236
 * Macro Average: f1: 0.4807, precision: 0.4680, recall: 0.4955

Epoch 9/10, accuracy: 0.9184
 * Micro Average: f1: 0.8013, precision: 0.7803, recall: 0.8234
 * Macro Average: f1: 0.4805, precision: 0.4677, recall: 0.4954

Epoch 10/10, accuracy: 0.9184
 * Micro Average: f1: 0.8013, precision: 0.7803, recall: 0.8234
 * Macro Average: f1: 0.4805, precision: 0.4677, recall: 0.4954

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6722
  * recall: 0.8657
  * f1-score: 0.7568
  * support: 469.0000
 ORG:
  * precision: 0.5636
  * recall: 0.7505
  * f1-score: 0.6438
  * support: 549.0000
 PER:
  * precision: 0.6432
  * recall: 0.9309
  * f1-score: 0.7607
  * support: 333.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6181
  * recall: 0.8349
  * f1-score: 0.7103
  * support: 1351.0000
 macro avg:
  * precision: 0.4697
  * recall: 0.6368
  * f1-score: 0.5403
  * support: 1351.0000
 weighted avg:
  * precision: 0.6209
  * recall: 0.8349
  * f1-score: 0.7118
  * support: 1351.0000
 accuracy:
  * 0.8607
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 256
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.1 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9190
 * Micro Average: f1: 0.8026, precision: 0.7815, recall: 0.8248
 * Macro Average: f1: 0.4814, precision: 0.4685, recall: 0.4961

Epoch 2/10, accuracy: 0.9198
 * Micro Average: f1: 0.8073, precision: 0.7879, recall: 0.8277
 * Macro Average: f1: 0.4844, precision: 0.4724, recall: 0.4977

Epoch 3/10, accuracy: 0.9206
 * Micro Average: f1: 0.8116, precision: 0.7934, recall: 0.8307
 * Macro Average: f1: 0.4871, precision: 0.4759, recall: 0.4995

Epoch 4/10, accuracy: 0.9212
 * Micro Average: f1: 0.8137, precision: 0.7964, recall: 0.8317
 * Macro Average: f1: 0.4885, precision: 0.4779, recall: 0.5000

Epoch 5/10, accuracy: 0.9213
 * Micro Average: f1: 0.8139, precision: 0.7960, recall: 0.8326
 * Macro Average: f1: 0.4887, precision: 0.4777, recall: 0.5006

Epoch 6/10, accuracy: 0.9216
 * Micro Average: f1: 0.8139, precision: 0.7957, recall: 0.8330
 * Macro Average: f1: 0.4888, precision: 0.4776, recall: 0.5008

Epoch 7/10, accuracy: 0.9216
 * Micro Average: f1: 0.8144, precision: 0.7966, recall: 0.8330
 * Macro Average: f1: 0.4891, precision: 0.4782, recall: 0.5008

Epoch 8/10, accuracy: 0.9217
 * Micro Average: f1: 0.8141, precision: 0.7962, recall: 0.8328
 * Macro Average: f1: 0.4889, precision: 0.4780, recall: 0.5006

Epoch 9/10, accuracy: 0.9217
 * Micro Average: f1: 0.8148, precision: 0.7974, recall: 0.8330
 * Macro Average: f1: 0.4894, precision: 0.4787, recall: 0.5008

Epoch 10/10, accuracy: 0.9218
 * Micro Average: f1: 0.8144, precision: 0.7968, recall: 0.8328
 * Macro Average: f1: 0.4891, precision: 0.4784, recall: 0.5006

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7113
  * recall: 0.8582
  * f1-score: 0.7779
  * support: 402.0000
 ORG:
  * precision: 0.5332
  * recall: 0.7665
  * f1-score: 0.6289
  * support: 471.0000
 PER:
  * precision: 0.6992
  * recall: 0.9397
  * f1-score: 0.8018
  * support: 282.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6273
  * recall: 0.8407
  * f1-score: 0.7185
  * support: 1155.0000
 macro avg:
  * precision: 0.4859
  * recall: 0.6411
  * f1-score: 0.5522
  * support: 1155.0000
 weighted avg:
  * precision: 0.6357
  * recall: 0.8407
  * f1-score: 0.7230
  * support: 1155.0000
 accuracy:
  * 0.8655
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 256
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.1 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9219
 * Micro Average: f1: 0.8148, precision: 0.7975, recall: 0.8328
 * Macro Average: f1: 0.4894, precision: 0.4789, recall: 0.5006

Epoch 2/10, accuracy: 0.9215
 * Micro Average: f1: 0.8147, precision: 0.7976, recall: 0.8326
 * Macro Average: f1: 0.4895, precision: 0.4791, recall: 0.5005

Epoch 3/10, accuracy: 0.9216
 * Micro Average: f1: 0.8163, precision: 0.8002, recall: 0.8330
 * Macro Average: f1: 0.4905, precision: 0.4808, recall: 0.5007

Epoch 4/10, accuracy: 0.9217
 * Micro Average: f1: 0.8162, precision: 0.7999, recall: 0.8332
 * Macro Average: f1: 0.4905, precision: 0.4806, recall: 0.5008

Epoch 5/10, accuracy: 0.9217
 * Micro Average: f1: 0.8163, precision: 0.8001, recall: 0.8332
 * Macro Average: f1: 0.4905, precision: 0.4808, recall: 0.5008

Epoch 6/10, accuracy: 0.9218
 * Micro Average: f1: 0.8163, precision: 0.8000, recall: 0.8334
 * Macro Average: f1: 0.4906, precision: 0.4808, recall: 0.5009

Epoch 7/10, accuracy: 0.9218
 * Micro Average: f1: 0.8166, precision: 0.8003, recall: 0.8336
 * Macro Average: f1: 0.4908, precision: 0.4810, recall: 0.5010

Epoch 8/10, accuracy: 0.9219
 * Micro Average: f1: 0.8167, precision: 0.8004, recall: 0.8336
 * Macro Average: f1: 0.4908, precision: 0.4811, recall: 0.5010

Epoch 9/10, accuracy: 0.9219
 * Micro Average: f1: 0.8168, precision: 0.8005, recall: 0.8337
 * Macro Average: f1: 0.4909, precision: 0.4811, recall: 0.5011

Epoch 10/10, accuracy: 0.9219
 * Micro Average: f1: 0.8168, precision: 0.8005, recall: 0.8337
 * Macro Average: f1: 0.4909, precision: 0.4811, recall: 0.5011

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7206
  * recall: 0.8532
  * f1-score: 0.7813
  * support: 402.0000
 ORG:
  * precision: 0.5334
  * recall: 0.7792
  * f1-score: 0.6333
  * support: 471.0000
 PER:
  * precision: 0.7285
  * recall: 0.9326
  * f1-score: 0.8180
  * support: 282.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6351
  * recall: 0.8424
  * f1-score: 0.7242
  * support: 1155.0000
 macro avg:
  * precision: 0.4956
  * recall: 0.6413
  * f1-score: 0.5582
  * support: 1155.0000
 weighted avg:
  * precision: 0.6462
  * recall: 0.8424
  * f1-score: 0.7299
  * support: 1155.0000
 accuracy:
  * 0.8685
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 256
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.2 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9220
 * Micro Average: f1: 0.8175, precision: 0.8011, recall: 0.8347
 * Macro Average: f1: 0.6141, precision: 0.6017, recall: 0.6271

Epoch 2/10, accuracy: 0.9222
 * Micro Average: f1: 0.8185, precision: 0.8028, recall: 0.8347
 * Macro Average: f1: 0.6147, precision: 0.6029, recall: 0.6271

Epoch 3/10, accuracy: 0.9223
 * Micro Average: f1: 0.8185, precision: 0.8028, recall: 0.8347
 * Macro Average: f1: 0.6147, precision: 0.6028, recall: 0.6271

Epoch 4/10, accuracy: 0.9223
 * Micro Average: f1: 0.8187, precision: 0.8033, recall: 0.8347
 * Macro Average: f1: 0.6148, precision: 0.6031, recall: 0.6271

Epoch 5/10, accuracy: 0.9223
 * Micro Average: f1: 0.8189, precision: 0.8038, recall: 0.8345
 * Macro Average: f1: 0.6150, precision: 0.6035, recall: 0.6270

Epoch 6/10, accuracy: 0.9224
 * Micro Average: f1: 0.8196, precision: 0.8049, recall: 0.8349
 * Macro Average: f1: 0.6155, precision: 0.6043, recall: 0.6273

Epoch 7/10, accuracy: 0.9223
 * Micro Average: f1: 0.8194, precision: 0.8046, recall: 0.8347
 * Macro Average: f1: 0.6153, precision: 0.6041, recall: 0.6271

Epoch 8/10, accuracy: 0.9224
 * Micro Average: f1: 0.8196, precision: 0.8049, recall: 0.8349
 * Macro Average: f1: 0.6155, precision: 0.6043, recall: 0.6273

Epoch 9/10, accuracy: 0.9224
 * Micro Average: f1: 0.8197, precision: 0.8051, recall: 0.8349
 * Macro Average: f1: 0.6156, precision: 0.6045, recall: 0.6273

Epoch 10/10, accuracy: 0.9223
 * Micro Average: f1: 0.8198, precision: 0.8052, recall: 0.8349
 * Macro Average: f1: 0.6157, precision: 0.6046, recall: 0.6273

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7278
  * recall: 0.8582
  * f1-score: 0.7877
  * support: 402.0000
 ORG:
  * precision: 0.5459
  * recall: 0.7707
  * f1-score: 0.6391
  * support: 471.0000
 PER:
  * precision: 0.7472
  * recall: 0.9326
  * f1-score: 0.8297
  * support: 282.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6486
  * recall: 0.8407
  * f1-score: 0.7323
  * support: 1155.0000
 macro avg:
  * precision: 0.5052
  * recall: 0.6404
  * f1-score: 0.5641
  * support: 1155.0000
 weighted avg:
  * precision: 0.6584
  * recall: 0.8407
  * f1-score: 0.7373
  * support: 1155.0000
 accuracy:
  * 0.8725
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 256
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.2 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9224
 * Micro Average: f1: 0.8204, precision: 0.8063, recall: 0.8351
 * Macro Average: f1: 0.6162, precision: 0.6054, recall: 0.6274

Epoch 2/10, accuracy: 0.9223
 * Micro Average: f1: 0.8201, precision: 0.8059, recall: 0.8347
 * Macro Average: f1: 0.6159, precision: 0.6051, recall: 0.6271

Epoch 3/10, accuracy: 0.9224
 * Micro Average: f1: 0.8203, precision: 0.8064, recall: 0.8347
 * Macro Average: f1: 0.6160, precision: 0.6054, recall: 0.6271

Epoch 4/10, accuracy: 0.9225
 * Micro Average: f1: 0.8209, precision: 0.8073, recall: 0.8349
 * Macro Average: f1: 0.6165, precision: 0.6061, recall: 0.6273

Epoch 5/10, accuracy: 0.9224
 * Micro Average: f1: 0.8209, precision: 0.8075, recall: 0.8349
 * Macro Average: f1: 0.6165, precision: 0.6062, recall: 0.6273

Epoch 6/10, accuracy: 0.9225
 * Micro Average: f1: 0.8209, precision: 0.8075, recall: 0.8349
 * Macro Average: f1: 0.6165, precision: 0.6062, recall: 0.6273

Epoch 7/10, accuracy: 0.9224
 * Micro Average: f1: 0.8213, precision: 0.8082, recall: 0.8349
 * Macro Average: f1: 0.6168, precision: 0.6068, recall: 0.6273

Epoch 8/10, accuracy: 0.9225
 * Micro Average: f1: 0.8210, precision: 0.8077, recall: 0.8347
 * Macro Average: f1: 0.6166, precision: 0.6064, recall: 0.6271

Epoch 9/10, accuracy: 0.9224
 * Micro Average: f1: 0.8208, precision: 0.8074, recall: 0.8347
 * Macro Average: f1: 0.6165, precision: 0.6062, recall: 0.6271

Epoch 10/10, accuracy: 0.9224
 * Micro Average: f1: 0.8209, precision: 0.8076, recall: 0.8347
 * Macro Average: f1: 0.6165, precision: 0.6063, recall: 0.6271

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.7233
  * recall: 0.8582
  * f1-score: 0.7850
  * support: 402.0000
 ORG:
  * precision: 0.5419
  * recall: 0.7686
  * f1-score: 0.6356
  * support: 471.0000
 PER:
  * precision: 0.7623
  * recall: 0.9326
  * f1-score: 0.8389
  * support: 282.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6484
  * recall: 0.8398
  * f1-score: 0.7318
  * support: 1155.0000
 macro avg:
  * precision: 0.5069
  * recall: 0.6399
  * f1-score: 0.5649
  * support: 1155.0000
 weighted avg:
  * precision: 0.6588
  * recall: 0.8398
  * f1-score: 0.7373
  * support: 1155.0000
 accuracy:
  * 0.8745
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 256
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.3 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9223
 * Micro Average: f1: 0.8199, precision: 0.8054, recall: 0.8349
 * Macro Average: f1: 0.6155, precision: 0.6043, recall: 0.6273

Epoch 2/10, accuracy: 0.9219
 * Micro Average: f1: 0.8152, precision: 0.7984, recall: 0.8328
 * Macro Average: f1: 0.6119, precision: 0.5988, recall: 0.6258

Epoch 3/10, accuracy: 0.9217
 * Micro Average: f1: 0.8159, precision: 0.7998, recall: 0.8326
 * Macro Average: f1: 0.6123, precision: 0.5998, recall: 0.6257

Epoch 4/10, accuracy: 0.9216
 * Micro Average: f1: 0.8159, precision: 0.8001, recall: 0.8324
 * Macro Average: f1: 0.6123, precision: 0.6000, recall: 0.6256

Epoch 5/10, accuracy: 0.9215
 * Micro Average: f1: 0.8152, precision: 0.7989, recall: 0.8322
 * Macro Average: f1: 0.6118, precision: 0.5990, recall: 0.6255

Epoch 6/10, accuracy: 0.9214
 * Micro Average: f1: 0.8147, precision: 0.7981, recall: 0.8320
 * Macro Average: f1: 0.6114, precision: 0.5984, recall: 0.6253

Epoch 7/10, accuracy: 0.9213
 * Micro Average: f1: 0.8147, precision: 0.7981, recall: 0.8320
 * Macro Average: f1: 0.6114, precision: 0.5984, recall: 0.6253

Epoch 8/10, accuracy: 0.9213
 * Micro Average: f1: 0.8150, precision: 0.7984, recall: 0.8322
 * Macro Average: f1: 0.6116, precision: 0.5987, recall: 0.6255

Epoch 9/10, accuracy: 0.9213
 * Micro Average: f1: 0.8151, precision: 0.7987, recall: 0.8322
 * Macro Average: f1: 0.6117, precision: 0.5989, recall: 0.6255

Epoch 10/10, accuracy: 0.9213
 * Micro Average: f1: 0.8151, precision: 0.7987, recall: 0.8322
 * Macro Average: f1: 0.6117, precision: 0.5989, recall: 0.6255

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6934
  * recall: 0.8607
  * f1-score: 0.7680
  * support: 402.0000
 ORG:
  * precision: 0.5416
  * recall: 0.7601
  * f1-score: 0.6325
  * support: 471.0000
 PER:
  * precision: 0.7151
  * recall: 0.9433
  * f1-score: 0.8135
  * support: 282.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6307
  * recall: 0.8398
  * f1-score: 0.7204
  * support: 1155.0000
 macro avg:
  * precision: 0.4875
  * recall: 0.6410
  * f1-score: 0.5535
  * support: 1155.0000
 weighted avg:
  * precision: 0.6368
  * recall: 0.8398
  * f1-score: 0.7239
  * support: 1155.0000
 accuracy:
  * 0.8676
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 256
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.3 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9213
 * Micro Average: f1: 0.8138, precision: 0.7968, recall: 0.8315
 * Macro Average: f1: 0.6107, precision: 0.5974, recall: 0.6249

Epoch 2/10, accuracy: 0.9211
 * Micro Average: f1: 0.8141, precision: 0.7973, recall: 0.8317
 * Macro Average: f1: 0.6109, precision: 0.5978, recall: 0.6251

Epoch 3/10, accuracy: 0.9209
 * Micro Average: f1: 0.8121, precision: 0.7949, recall: 0.8299
 * Macro Average: f1: 0.6093, precision: 0.5960, recall: 0.6238

Epoch 4/10, accuracy: 0.9210
 * Micro Average: f1: 0.8134, precision: 0.7965, recall: 0.8311
 * Macro Average: f1: 0.6104, precision: 0.5972, recall: 0.6246

Epoch 5/10, accuracy: 0.9210
 * Micro Average: f1: 0.8133, precision: 0.7964, recall: 0.8309
 * Macro Average: f1: 0.6103, precision: 0.5971, recall: 0.6245

Epoch 6/10, accuracy: 0.9209
 * Micro Average: f1: 0.8125, precision: 0.7955, recall: 0.8303
 * Macro Average: f1: 0.6097, precision: 0.5964, recall: 0.6241

Epoch 7/10, accuracy: 0.9210
 * Micro Average: f1: 0.8128, precision: 0.7958, recall: 0.8305
 * Macro Average: f1: 0.6099, precision: 0.5966, recall: 0.6242

Epoch 8/10, accuracy: 0.9209
 * Micro Average: f1: 0.8125, precision: 0.7955, recall: 0.8303
 * Macro Average: f1: 0.6097, precision: 0.5964, recall: 0.6241

Epoch 9/10, accuracy: 0.9209
 * Micro Average: f1: 0.8123, precision: 0.7951, recall: 0.8301
 * Macro Average: f1: 0.6095, precision: 0.5961, recall: 0.6239

Epoch 10/10, accuracy: 0.9209
 * Micro Average: f1: 0.8123, precision: 0.7951, recall: 0.8301
 * Macro Average: f1: 0.6095, precision: 0.5961, recall: 0.6239

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6948
  * recall: 0.8607
  * f1-score: 0.7689
  * support: 402.0000
 ORG:
  * precision: 0.5431
  * recall: 0.7622
  * f1-score: 0.6343
  * support: 471.0000
 PER:
  * precision: 0.7112
  * recall: 0.9433
  * f1-score: 0.8110
  * support: 282.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6309
  * recall: 0.8407
  * f1-score: 0.7209
  * support: 1155.0000
 macro avg:
  * precision: 0.4873
  * recall: 0.6415
  * f1-score: 0.5535
  * support: 1155.0000
 weighted avg:
  * precision: 0.6369
  * recall: 0.8407
  * f1-score: 0.7243
  * support: 1155.0000
 accuracy:
  * 0.8668
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 256
 * frozen weights: False
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.4 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9202
 * Micro Average: f1: 0.8078, precision: 0.7883, recall: 0.8282
 * Macro Average: f1: 0.6059, precision: 0.5908, recall: 0.6226

Epoch 2/10, accuracy: 0.9195
 * Micro Average: f1: 0.8056, precision: 0.7853, recall: 0.8269
 * Macro Average: f1: 0.4833, precision: 0.4708, recall: 0.4973

Epoch 3/10, accuracy: 0.9193
 * Micro Average: f1: 0.8051, precision: 0.7846, recall: 0.8267
 * Macro Average: f1: 0.4830, precision: 0.4704, recall: 0.4972

Epoch 4/10, accuracy: 0.9194
 * Micro Average: f1: 0.8055, precision: 0.7849, recall: 0.8271
 * Macro Average: f1: 0.4832, precision: 0.4706, recall: 0.4974

Epoch 5/10, accuracy: 0.9193
 * Micro Average: f1: 0.8048, precision: 0.7843, recall: 0.8265
 * Macro Average: f1: 0.4827, precision: 0.4701, recall: 0.4971

Epoch 6/10, accuracy: 0.9192
 * Micro Average: f1: 0.8051, precision: 0.7849, recall: 0.8263
 * Macro Average: f1: 0.4829, precision: 0.4705, recall: 0.4970

Epoch 7/10, accuracy: 0.9192
 * Micro Average: f1: 0.8048, precision: 0.7844, recall: 0.8263
 * Macro Average: f1: 0.4827, precision: 0.4702, recall: 0.4970

Epoch 8/10, accuracy: 0.9191
 * Micro Average: f1: 0.8044, precision: 0.7841, recall: 0.8258
 * Macro Average: f1: 0.4824, precision: 0.4700, recall: 0.4967

Epoch 9/10, accuracy: 0.9190
 * Micro Average: f1: 0.8047, precision: 0.7847, recall: 0.8258
 * Macro Average: f1: 0.4826, precision: 0.4704, recall: 0.4967

Epoch 10/10, accuracy: 0.9191
 * Micro Average: f1: 0.8048, precision: 0.7850, recall: 0.8258
 * Macro Average: f1: 0.4827, precision: 0.4705, recall: 0.4967

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6725
  * recall: 0.8632
  * f1-score: 0.7560
  * support: 402.0000
 ORG:
  * precision: 0.5554
  * recall: 0.7558
  * f1-score: 0.6403
  * support: 471.0000
 PER:
  * precision: 0.6552
  * recall: 0.9433
  * f1-score: 0.7733
  * support: 282.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6168
  * recall: 0.8390
  * f1-score: 0.7109
  * support: 1155.0000
 macro avg:
  * precision: 0.4708
  * recall: 0.6406
  * f1-score: 0.5424
  * support: 1155.0000
 weighted avg:
  * precision: 0.6205
  * recall: 0.8390
  * f1-score: 0.7130
  * support: 1155.0000
 accuracy:
  * 0.8622
________________________________________




====================================================================================================
Training model: bert-base-multilingual-cased
 * 10 epochs
 * learning rate is 2e-05
 * batch size is 256
 * frozen weights: True
  * device is on cuda * warmup steps: 50
 * activation: GELU
 * dropout: 0.4 * train language: en
 * test language: af
____________________________________________________________________________________________________

Epoch 1/10, accuracy: 0.9190
 * Micro Average: f1: 0.8038, precision: 0.7836, recall: 0.8252
 * Macro Average: f1: 0.4821, precision: 0.4697, recall: 0.4963

Epoch 2/10, accuracy: 0.9191
 * Micro Average: f1: 0.8043, precision: 0.7843, recall: 0.8254
 * Macro Average: f1: 0.4824, precision: 0.4701, recall: 0.4965

Epoch 3/10, accuracy: 0.9187
 * Micro Average: f1: 0.8035, precision: 0.7832, recall: 0.8248
 * Macro Average: f1: 0.4818, precision: 0.4695, recall: 0.4961

Epoch 4/10, accuracy: 0.9187
 * Micro Average: f1: 0.8028, precision: 0.7822, recall: 0.8246
 * Macro Average: f1: 0.4814, precision: 0.4688, recall: 0.4960

Epoch 5/10, accuracy: 0.9187
 * Micro Average: f1: 0.8030, precision: 0.7825, recall: 0.8246
 * Macro Average: f1: 0.4815, precision: 0.4690, recall: 0.4960

Epoch 6/10, accuracy: 0.9187
 * Micro Average: f1: 0.8024, precision: 0.7816, recall: 0.8244
 * Macro Average: f1: 0.4812, precision: 0.4685, recall: 0.4959

Epoch 7/10, accuracy: 0.9188
 * Micro Average: f1: 0.8025, precision: 0.7817, recall: 0.8244
 * Macro Average: f1: 0.4812, precision: 0.4685, recall: 0.4959

Epoch 8/10, accuracy: 0.9187
 * Micro Average: f1: 0.8024, precision: 0.7814, recall: 0.8244
 * Macro Average: f1: 0.4811, precision: 0.4684, recall: 0.4959

Epoch 9/10, accuracy: 0.9187
 * Micro Average: f1: 0.8024, precision: 0.7814, recall: 0.8244
 * Macro Average: f1: 0.4811, precision: 0.4684, recall: 0.4959

Epoch 10/10, accuracy: 0.9187
 * Micro Average: f1: 0.8024, precision: 0.7814, recall: 0.8244
 * Macro Average: f1: 0.4811, precision: 0.4684, recall: 0.4959

Classification Report on test set:
________________________________________
 LOC:
  * precision: 0.6686
  * recall: 0.8632
  * f1-score: 0.7535
  * support: 402.0000
 ORG:
  * precision: 0.5571
  * recall: 0.7558
  * f1-score: 0.6414
  * support: 471.0000
 PER:
  * precision: 0.6488
  * recall: 0.9433
  * f1-score: 0.7688
  * support: 282.0000
 SEP]:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 0.0000
 micro avg:
  * precision: 0.6148
  * recall: 0.8390
  * f1-score: 0.7096
  * support: 1155.0000
 macro avg:
  * precision: 0.4686
  * recall: 0.6406
  * f1-score: 0.5409
  * support: 1155.0000
 weighted avg:
  * precision: 0.6183
  * recall: 0.8390
  * f1-score: 0.7115
  * support: 1155.0000
 accuracy:
  * 0.8623
________________________________________


Traceback (most recent call last):
  File "/fp/homes01/u01/ec-eirikeg/mandatory_2/hyperparameter_test_eirik.py", line 228, in <module>
    print(f"\n\n{'='*100}\nBEST MODEL:\n{best_model.best_model_info}\n")
  File "/fp/projects01/ec30/software/easybuild/software/nlpl-pytorch/2.1.2-foss-2022b-cuda-12.0.0-Python-3.10.8/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'BertForTokenClassification' object has no attribute 'best_model_info'

Task and CPU usage stats:
JobID           JobName  AllocCPUS   NTasks     MinCPU MinCPUTask     AveCPU    Elapsed ExitCode 
------------ ---------- ---------- -------- ---------- ---------- ---------- ---------- -------- 
452435           in5550          4                                             01:29:13      1:0 
452435.batch      batch          4        1   01:28:59          0   01:28:59   01:29:13      1:0 
452435.exte+     extern          4        1   00:00:00          0   00:00:00   01:29:13      0:0 

Memory usage stats:
JobID            MaxRSS MaxRSSTask     AveRSS MaxPages   MaxPagesTask   AvePages 
------------ ---------- ---------- ---------- -------- -------------- ---------- 
452435                                                                           
452435.batch   1262464K          0   1262464K        0              0          0 
452435.exte+          0          0          0        0              0          0 

Disk usage stats:
JobID         MaxDiskRead MaxDiskReadTask    AveDiskRead MaxDiskWrite MaxDiskWriteTask   AveDiskWrite 
------------ ------------ --------------- -------------- ------------ ---------------- -------------- 
452435                                                                                                
452435.batch      758.35M               0        758.35M        0.47M                0          0.47M 
452435.exte+        0.01M               0          0.01M        0.00M                0          0.00M 

GPU usage stats:

Job 452435 completed at Sat Mar 9 20:50:30 CET 2024
