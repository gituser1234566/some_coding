Starting job 463266 on gpu-5 at Thu Mar 14 04:36:06 CET 2024

/var/spool/slurmd/job463266/slurm_script: line 14: /fp/homes01/u01/ec-rasyed/.bashrc: No such file or directory
submission directory: /fp/homes01/u01/ec-rasyed/2024/labs/06/mand2/assignment2/IN5550-mandatory-2/code_python/colab
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Data preprocessing...
Map:   0%|          | 0/14546 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Map:   7%|▋         | 1000/14546 [00:00<00:02, 6142.44 examples/s]Map:  14%|█▎        | 2000/14546 [00:00<00:01, 6583.87 examples/s]Map:  21%|██        | 3000/14546 [00:00<00:01, 7002.53 examples/s]Map:  27%|██▋       | 4000/14546 [00:00<00:01, 7199.69 examples/s]Map:  34%|███▍      | 5000/14546 [00:00<00:01, 7441.75 examples/s]Map:  41%|████      | 6000/14546 [00:00<00:01, 7541.83 examples/s]Map:  48%|████▊     | 7000/14546 [00:00<00:00, 7601.49 examples/s]Map:  55%|█████▍    | 8000/14546 [00:01<00:00, 7424.74 examples/s]Map:  62%|██████▏   | 9000/14546 [00:01<00:00, 7238.14 examples/s]Map:  69%|██████▊   | 10000/14546 [00:01<00:00, 6995.57 examples/s]Map:  76%|███████▌  | 11000/14546 [00:01<00:00, 6697.15 examples/s]Map:  82%|████████▏ | 12000/14546 [00:01<00:00, 6699.48 examples/s]Map:  89%|████████▉ | 13000/14546 [00:02<00:00, 4945.68 examples/s]Map:  96%|█████████▌| 14000/14546 [00:02<00:00, 5328.92 examples/s]Map: 100%|██████████| 14546/14546 [00:02<00:00, 6405.60 examples/s]
Map:   0%|          | 0/11636 [00:00<?, ? examples/s]Map:   9%|▊         | 1000/11636 [00:00<00:01, 6922.41 examples/s]Map:  17%|█▋        | 2000/11636 [00:00<00:01, 6965.43 examples/s]Map:  26%|██▌       | 3000/11636 [00:00<00:01, 7172.03 examples/s]Map:  34%|███▍      | 4000/11636 [00:00<00:01, 6771.83 examples/s]Map:  43%|████▎     | 5000/11636 [00:00<00:00, 6922.30 examples/s]Map:  52%|█████▏    | 6000/11636 [00:00<00:00, 6950.15 examples/s]Map:  60%|██████    | 7000/11636 [00:00<00:00, 7089.77 examples/s]Map:  69%|██████▉   | 8000/11636 [00:01<00:00, 7096.77 examples/s]Map:  77%|███████▋  | 9000/11636 [00:01<00:00, 7149.10 examples/s]Map:  86%|████████▌ | 10000/11636 [00:01<00:00, 7040.94 examples/s]Map:  95%|█████████▍| 11000/11636 [00:01<00:00, 6834.22 examples/s]Map: 100%|██████████| 11636/11636 [00:01<00:00, 6936.74 examples/s]
Map:   0%|          | 0/2910 [00:00<?, ? examples/s]Map:  34%|███▍      | 1000/2910 [00:00<00:00, 6468.20 examples/s]Map:  69%|██████▊   | 2000/2910 [00:00<00:00, 6624.32 examples/s]Map: 100%|██████████| 2910/2910 [00:00<00:00, 6695.39 examples/s]Map: 100%|██████████| 2910/2910 [00:00<00:00, 6629.57 examples/s]
TESTING FOR MUTLIPLE PARAMETERS:


Map:   0%|          | 0/7311 [00:00<?, ? examples/s]Map:  14%|█▎        | 1000/7311 [00:00<00:00, 7458.95 examples/s]Map:  27%|██▋       | 2000/7311 [00:00<00:00, 7598.23 examples/s]Map:  41%|████      | 3000/7311 [00:00<00:00, 7534.60 examples/s]Map:  55%|█████▍    | 4000/7311 [00:00<00:00, 7373.09 examples/s]Map:  68%|██████▊   | 5000/7311 [00:00<00:00, 7581.08 examples/s]Map:  82%|████████▏ | 6000/7311 [00:00<00:00, 7640.34 examples/s]Map:  96%|█████████▌| 7000/7311 [00:00<00:00, 7745.47 examples/s]Map: 100%|██████████| 7311/7311 [00:00<00:00, 7611.16 examples/s]
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8739
 * Micro Average: f1: 0.7807, precision: 0.7840, recall: 0.7775
 * Macro Average: f1: 0.7823, precision: 0.7821, recall: 0.7833

Epoch 2/4, accuracy: 0.8816
 * Micro Average: f1: 0.7933, precision: 0.7961, recall: 0.7905
 * Macro Average: f1: 0.7942, precision: 0.7913, recall: 0.7993

Epoch 3/4, accuracy: 0.8898
 * Micro Average: f1: 0.8080, precision: 0.8078, recall: 0.8082
 * Macro Average: f1: 0.8098, precision: 0.8052, recall: 0.8154

Epoch 4/4, accuracy: 0.8923
 * Micro Average: f1: 0.8136, precision: 0.8103, recall: 0.8170
 * Macro Average: f1: 0.8159, precision: 0.8100, recall: 0.8223

 time for training and evaluating:214.07510018348694 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7972
  * recall: 0.8350
  * f1-score: 0.8157
  * support: 11455.0000
 ORG:
  * precision: 0.8135
  * recall: 0.8170
  * f1-score: 0.8153
  * support: 16343.0000
 PER:
  * precision: 0.8021
  * recall: 0.8000
  * f1-score: 0.8010
  * support: 22349.0000
 micro avg:
  * precision: 0.8046
  * recall: 0.8135
  * f1-score: 0.8091
  * support: 50147.0000
 macro avg:
  * precision: 0.8043
  * recall: 0.8173
  * f1-score: 0.8107
  * support: 50147.0000
 weighted avg:
  * precision: 0.8047
  * recall: 0.8135
  * f1-score: 0.8090
  * support: 50147.0000
 accuracy:
  * 0.8891
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4833
 * Micro Average: f1: 0.0032, precision: 0.1154, recall: 0.0016
 * Macro Average: f1: 0.0025, precision: 0.0738, recall: 0.0013

Epoch 2/4, accuracy: 0.4825
 * Micro Average: f1: 0.0001, precision: 1.0000, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.3333, recall: 0.0000

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.036478996276855 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11440.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16370.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22358.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50168.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50168.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50168.0000
 accuracy:
  * 0.4856
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8708
 * Micro Average: f1: 0.7796, precision: 0.7647, recall: 0.7951
 * Macro Average: f1: 0.7816, precision: 0.7713, recall: 0.7928

Epoch 2/4, accuracy: 0.8873
 * Micro Average: f1: 0.8054, precision: 0.8016, recall: 0.8093
 * Macro Average: f1: 0.8066, precision: 0.8019, recall: 0.8114

Epoch 3/4, accuracy: 0.8902
 * Micro Average: f1: 0.8114, precision: 0.7994, recall: 0.8236
 * Macro Average: f1: 0.8134, precision: 0.8024, recall: 0.8248

Epoch 4/4, accuracy: 0.8930
 * Micro Average: f1: 0.8141, precision: 0.8101, recall: 0.8181
 * Macro Average: f1: 0.8155, precision: 0.8092, recall: 0.8223

 time for training and evaluating:214.06628727912903 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.8038
  * recall: 0.8317
  * f1-score: 0.8176
  * support: 11459.0000
 ORG:
  * precision: 0.8020
  * recall: 0.8238
  * f1-score: 0.8127
  * support: 16378.0000
 PER:
  * precision: 0.7995
  * recall: 0.7982
  * f1-score: 0.7988
  * support: 22346.0000
 micro avg:
  * precision: 0.8013
  * recall: 0.8142
  * f1-score: 0.8077
  * support: 50183.0000
 macro avg:
  * precision: 0.8018
  * recall: 0.8179
  * f1-score: 0.8097
  * support: 50183.0000
 weighted avg:
  * precision: 0.8013
  * recall: 0.8142
  * f1-score: 0.8076
  * support: 50183.0000
 accuracy:
  * 0.8884
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4827
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4827
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:64.64650559425354 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11454.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16359.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22329.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50142.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50142.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50142.0000
 accuracy:
  * 0.4856
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8312
 * Micro Average: f1: 0.7029, precision: 0.7095, recall: 0.6964
 * Macro Average: f1: 0.7024, precision: 0.7049, recall: 0.7059

Epoch 2/4, accuracy: 0.8579
 * Micro Average: f1: 0.7548, precision: 0.7564, recall: 0.7533
 * Macro Average: f1: 0.7558, precision: 0.7521, recall: 0.7619

Epoch 3/4, accuracy: 0.8643
 * Micro Average: f1: 0.7669, precision: 0.7701, recall: 0.7638
 * Macro Average: f1: 0.7686, precision: 0.7661, recall: 0.7732

Epoch 4/4, accuracy: 0.8668
 * Micro Average: f1: 0.7716, precision: 0.7735, recall: 0.7697
 * Macro Average: f1: 0.7727, precision: 0.7701, recall: 0.7768

 time for training and evaluating:213.76192903518677 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7324
  * recall: 0.8180
  * f1-score: 0.7728
  * support: 11445.0000
 ORG:
  * precision: 0.7917
  * recall: 0.7619
  * f1-score: 0.7765
  * support: 16355.0000
 PER:
  * precision: 0.7771
  * recall: 0.7476
  * f1-score: 0.7621
  * support: 22322.0000
 micro avg:
  * precision: 0.7703
  * recall: 0.7684
  * f1-score: 0.7693
  * support: 50122.0000
 macro avg:
  * precision: 0.7671
  * recall: 0.7759
  * f1-score: 0.7705
  * support: 50122.0000
 weighted avg:
  * precision: 0.7717
  * recall: 0.7684
  * f1-score: 0.7693
  * support: 50122.0000
 accuracy:
  * 0.8668
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4831
 * Micro Average: f1: 0.0020, precision: 0.3125, recall: 0.0010
 * Macro Average: f1: 0.0015, precision: 0.1042, recall: 0.0007

Epoch 2/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:64.43632316589355 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11452.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16348.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22345.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50145.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50145.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50145.0000
 accuracy:
  * 0.4856
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8208
 * Micro Average: f1: 0.6856, precision: 0.6860, recall: 0.6852
 * Macro Average: f1: 0.6846, precision: 0.6830, recall: 0.6905

Epoch 2/4, accuracy: 0.8429
 * Micro Average: f1: 0.7273, precision: 0.7325, recall: 0.7223
 * Macro Average: f1: 0.7265, precision: 0.7274, recall: 0.7312

Epoch 3/4, accuracy: 0.8602
 * Micro Average: f1: 0.7576, precision: 0.7633, recall: 0.7520
 * Macro Average: f1: 0.7578, precision: 0.7582, recall: 0.7604

Epoch 4/4, accuracy: 0.8636
 * Micro Average: f1: 0.7662, precision: 0.7675, recall: 0.7650
 * Macro Average: f1: 0.7671, precision: 0.7642, recall: 0.7716

 time for training and evaluating:214.27346968650818 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7260
  * recall: 0.8102
  * f1-score: 0.7658
  * support: 11451.0000
 ORG:
  * precision: 0.7877
  * recall: 0.7500
  * f1-score: 0.7684
  * support: 16343.0000
 PER:
  * precision: 0.7642
  * recall: 0.7455
  * f1-score: 0.7547
  * support: 22372.0000
 micro avg:
  * precision: 0.7618
  * recall: 0.7617
  * f1-score: 0.7617
  * support: 50166.0000
 macro avg:
  * precision: 0.7593
  * recall: 0.7686
  * f1-score: 0.7630
  * support: 50166.0000
 weighted avg:
  * precision: 0.7631
  * recall: 0.7617
  * f1-score: 0.7617
  * support: 50166.0000
 accuracy:
  * 0.8621
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.105987548828125 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11438.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16363.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22351.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50152.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50152.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50152.0000
 accuracy:
  * 0.4856
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4814
 * Micro Average: f1: 0.0321, precision: 0.1581, recall: 0.0178
 * Macro Average: f1: 0.0215, precision: 0.1477, recall: 0.0134

Epoch 2/4, accuracy: 0.4827
 * Micro Average: f1: 0.0024, precision: 0.0874, recall: 0.0012
 * Macro Average: f1: 0.0018, precision: 0.0292, recall: 0.0009

Epoch 3/4, accuracy: 0.4827
 * Micro Average: f1: 0.0005, precision: 0.1087, recall: 0.0002
 * Macro Average: f1: 0.0004, precision: 0.0362, recall: 0.0002

Epoch 4/4, accuracy: 0.4830
 * Micro Average: f1: 0.0002, precision: 0.0690, recall: 0.0001
 * Macro Average: f1: 0.0001, precision: 0.0230, recall: 0.0001

 time for training and evaluating:213.59926295280457 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11445.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16364.0000
 PER:
  * precision: 0.1569
  * recall: 0.0004
  * f1-score: 0.0007
  * support: 22329.0000
 micro avg:
  * precision: 0.1569
  * recall: 0.0002
  * f1-score: 0.0003
  * support: 50138.0000
 macro avg:
  * precision: 0.0523
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 50138.0000
 weighted avg:
  * precision: 0.0699
  * recall: 0.0002
  * f1-score: 0.0003
  * support: 50138.0000
 accuracy:
  * 0.4859
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.2873
 * Micro Average: f1: 0.1923, precision: 0.1499, recall: 0.2678
 * Macro Average: f1: 0.0808, precision: 0.0946, recall: 0.2001

Epoch 2/4, accuracy: 0.4827
 * Micro Average: f1: 0.0030, precision: 0.1840, recall: 0.0015
 * Macro Average: f1: 0.0022, precision: 0.0613, recall: 0.0011

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4827
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:64.97846794128418 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11457.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16365.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22343.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50165.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50165.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50165.0000
 accuracy:
  * 0.4855
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4827
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:213.1051070690155 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11428.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16348.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22373.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50149.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50149.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50149.0000
 accuracy:
  * 0.4855
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0838
 * Micro Average: f1: 0.1497, precision: 0.1030, recall: 0.2740
 * Macro Average: f1: 0.0612, precision: 0.0343, recall: 0.2819

Epoch 2/4, accuracy: 0.2206
 * Micro Average: f1: 0.1004, precision: 0.0866, recall: 0.1196
 * Macro Average: f1: 0.0468, precision: 0.0289, recall: 0.1235

Epoch 3/4, accuracy: 0.4613
 * Micro Average: f1: 0.0087, precision: 0.0520, recall: 0.0047
 * Macro Average: f1: 0.0076, precision: 0.0173, recall: 0.0049

Epoch 4/4, accuracy: 0.4806
 * Micro Average: f1: 0.0014, precision: 0.0486, recall: 0.0007
 * Macro Average: f1: 0.0014, precision: 0.0162, recall: 0.0007

 time for training and evaluating:64.08095240592957 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11440.0000
 ORG:
  * precision: 0.0964
  * recall: 0.0040
  * f1-score: 0.0076
  * support: 16351.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22328.0000
 micro avg:
  * precision: 0.0964
  * recall: 0.0013
  * f1-score: 0.0026
  * support: 50119.0000
 macro avg:
  * precision: 0.0321
  * recall: 0.0013
  * f1-score: 0.0025
  * support: 50119.0000
 weighted avg:
  * precision: 0.0315
  * recall: 0.0013
  * f1-score: 0.0025
  * support: 50119.0000
 accuracy:
  * 0.4830
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8696
 * Micro Average: f1: 0.7741, precision: 0.7716, recall: 0.7766
 * Macro Average: f1: 0.7735, precision: 0.7700, recall: 0.7784

Epoch 2/4, accuracy: 0.8807
 * Micro Average: f1: 0.7950, precision: 0.7874, recall: 0.8028
 * Macro Average: f1: 0.7959, precision: 0.7903, recall: 0.8017

Epoch 3/4, accuracy: 0.8880
 * Micro Average: f1: 0.8043, precision: 0.8041, recall: 0.8044
 * Macro Average: f1: 0.8050, precision: 0.8027, recall: 0.8077

Epoch 4/4, accuracy: 0.8904
 * Micro Average: f1: 0.8106, precision: 0.8057, recall: 0.8156
 * Macro Average: f1: 0.8117, precision: 0.8051, recall: 0.8185

 time for training and evaluating:170.93974828720093 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7983
  * recall: 0.8335
  * f1-score: 0.8155
  * support: 11435.0000
 ORG:
  * precision: 0.8134
  * recall: 0.8128
  * f1-score: 0.8131
  * support: 16359.0000
 PER:
  * precision: 0.7929
  * recall: 0.8037
  * f1-score: 0.7983
  * support: 22365.0000
 micro avg:
  * precision: 0.8007
  * recall: 0.8135
  * f1-score: 0.8070
  * support: 50159.0000
 macro avg:
  * precision: 0.8015
  * recall: 0.8167
  * f1-score: 0.8089
  * support: 50159.0000
 weighted avg:
  * precision: 0.8008
  * recall: 0.8135
  * f1-score: 0.8070
  * support: 50159.0000
 accuracy:
  * 0.8882
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.2557
 * Micro Average: f1: 0.1033, precision: 0.0807, recall: 0.1435
 * Macro Average: f1: 0.0476, precision: 0.0269, recall: 0.2075

Epoch 2/4, accuracy: 0.4820
 * Micro Average: f1: 0.0039, precision: 0.0768, recall: 0.0020
 * Macro Average: f1: 0.0052, precision: 0.0256, recall: 0.0029

Epoch 3/4, accuracy: 0.4830
 * Micro Average: f1: 0.0002, precision: 0.2000, recall: 0.0001
 * Macro Average: f1: 0.0003, precision: 0.0667, recall: 0.0001

Epoch 4/4, accuracy: 0.4824
 * Micro Average: f1: 0.0001, precision: 0.2500, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0833, recall: 0.0001

 time for training and evaluating:60.347105503082275 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11452.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16339.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22340.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50131.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50131.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50131.0000
 accuracy:
  * 0.4855
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8714
 * Micro Average: f1: 0.7787, precision: 0.7682, recall: 0.7894
 * Macro Average: f1: 0.7800, precision: 0.7693, recall: 0.7914

Epoch 2/4, accuracy: 0.8813
 * Micro Average: f1: 0.7937, precision: 0.7953, recall: 0.7921
 * Macro Average: f1: 0.7955, precision: 0.7943, recall: 0.7971

Epoch 3/4, accuracy: 0.8878
 * Micro Average: f1: 0.8041, precision: 0.8035, recall: 0.8046
 * Macro Average: f1: 0.8056, precision: 0.8011, recall: 0.8110

Epoch 4/4, accuracy: 0.8896
 * Micro Average: f1: 0.8074, precision: 0.8042, recall: 0.8107
 * Macro Average: f1: 0.8093, precision: 0.8035, recall: 0.8155

 time for training and evaluating:170.81335639953613 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7954
  * recall: 0.8306
  * f1-score: 0.8126
  * support: 11456.0000
 ORG:
  * precision: 0.8089
  * recall: 0.8130
  * f1-score: 0.8109
  * support: 16355.0000
 PER:
  * precision: 0.7994
  * recall: 0.7957
  * f1-score: 0.7976
  * support: 22329.0000
 micro avg:
  * precision: 0.8015
  * recall: 0.8093
  * f1-score: 0.8054
  * support: 50140.0000
 macro avg:
  * precision: 0.8012
  * recall: 0.8131
  * f1-score: 0.8070
  * support: 50140.0000
 weighted avg:
  * precision: 0.8016
  * recall: 0.8093
  * f1-score: 0.8054
  * support: 50140.0000
 accuracy:
  * 0.8876
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.2835
 * Micro Average: f1: 0.2028, precision: 0.1559, recall: 0.2899
 * Macro Average: f1: 0.0839, precision: 0.0520, recall: 0.2170

Epoch 2/4, accuracy: 0.4833
 * Micro Average: f1: 0.0200, precision: 0.3141, recall: 0.0104
 * Macro Average: f1: 0.0144, precision: 0.1047, recall: 0.0077

Epoch 3/4, accuracy: 0.4835
 * Micro Average: f1: 0.0011, precision: 0.5500, recall: 0.0006
 * Macro Average: f1: 0.0008, precision: 0.1833, recall: 0.0004

Epoch 4/4, accuracy: 0.4826
 * Micro Average: f1: 0.0001, precision: 0.1667, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0556, recall: 0.0000

 time for training and evaluating:59.80237555503845 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11445.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16354.0000
 PER:
  * precision: 0.5200
  * recall: 0.0006
  * f1-score: 0.0012
  * support: 22350.0000
 micro avg:
  * precision: 0.5200
  * recall: 0.0003
  * f1-score: 0.0005
  * support: 50149.0000
 macro avg:
  * precision: 0.1733
  * recall: 0.0002
  * f1-score: 0.0004
  * support: 50149.0000
 weighted avg:
  * precision: 0.2317
  * recall: 0.0003
  * f1-score: 0.0005
  * support: 50149.0000
 accuracy:
  * 0.4856
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8020
 * Micro Average: f1: 0.6506, precision: 0.6412, recall: 0.6602
 * Macro Average: f1: 0.6465, precision: 0.6349, recall: 0.6625

Epoch 2/4, accuracy: 0.8424
 * Micro Average: f1: 0.7247, precision: 0.7233, recall: 0.7262
 * Macro Average: f1: 0.7242, precision: 0.7185, recall: 0.7345

Epoch 3/4, accuracy: 0.8533
 * Micro Average: f1: 0.7448, precision: 0.7397, recall: 0.7500
 * Macro Average: f1: 0.7446, precision: 0.7357, recall: 0.7564

Epoch 4/4, accuracy: 0.8549
 * Micro Average: f1: 0.7487, precision: 0.7462, recall: 0.7511
 * Macro Average: f1: 0.7487, precision: 0.7433, recall: 0.7568

 time for training and evaluating:170.68666887283325 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6979
  * recall: 0.8081
  * f1-score: 0.7489
  * support: 11464.0000
 ORG:
  * precision: 0.7842
  * recall: 0.7160
  * f1-score: 0.7485
  * support: 16356.0000
 PER:
  * precision: 0.7472
  * recall: 0.7450
  * f1-score: 0.7461
  * support: 22334.0000
 micro avg:
  * precision: 0.7452
  * recall: 0.7500
  * f1-score: 0.7476
  * support: 50154.0000
 macro avg:
  * precision: 0.7431
  * recall: 0.7564
  * f1-score: 0.7479
  * support: 50154.0000
 weighted avg:
  * precision: 0.7480
  * recall: 0.7500
  * f1-score: 0.7475
  * support: 50154.0000
 accuracy:
  * 0.8547
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0712
 * Micro Average: f1: 0.0225, precision: 0.0487, recall: 0.0146
 * Macro Average: f1: 0.0233, precision: 0.0660, recall: 0.0152

Epoch 2/4, accuracy: 0.3981
 * Micro Average: f1: 0.0549, precision: 0.0831, recall: 0.0410
 * Macro Average: f1: 0.0406, precision: 0.0972, recall: 0.0409

Epoch 3/4, accuracy: 0.4684
 * Micro Average: f1: 0.0261, precision: 0.1068, recall: 0.0148
 * Macro Average: f1: 0.0223, precision: 0.1341, recall: 0.0149

Epoch 4/4, accuracy: 0.4771
 * Micro Average: f1: 0.0165, precision: 0.1180, recall: 0.0089
 * Macro Average: f1: 0.0150, precision: 0.1565, recall: 0.0089

 time for training and evaluating:60.28712296485901 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.2727
  * recall: 0.0005
  * f1-score: 0.0010
  * support: 11444.0000
 ORG:
  * precision: 0.1276
  * recall: 0.0262
  * f1-score: 0.0435
  * support: 16360.0000
 PER:
  * precision: 0.1887
  * recall: 0.0022
  * f1-score: 0.0044
  * support: 22341.0000
 micro avg:
  * precision: 0.1329
  * recall: 0.0097
  * f1-score: 0.0180
  * support: 50145.0000
 macro avg:
  * precision: 0.1963
  * recall: 0.0097
  * f1-score: 0.0163
  * support: 50145.0000
 weighted avg:
  * precision: 0.1879
  * recall: 0.0097
  * f1-score: 0.0164
  * support: 50145.0000
 accuracy:
  * 0.4804
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8050
 * Micro Average: f1: 0.6590, precision: 0.6606, recall: 0.6573
 * Macro Average: f1: 0.6591, precision: 0.6554, recall: 0.6674

Epoch 2/4, accuracy: 0.8456
 * Micro Average: f1: 0.7312, precision: 0.7257, recall: 0.7367
 * Macro Average: f1: 0.7310, precision: 0.7238, recall: 0.7398

Epoch 3/4, accuracy: 0.8526
 * Micro Average: f1: 0.7436, precision: 0.7440, recall: 0.7433
 * Macro Average: f1: 0.7432, precision: 0.7402, recall: 0.7480

Epoch 4/4, accuracy: 0.8566
 * Micro Average: f1: 0.7523, precision: 0.7517, recall: 0.7528
 * Macro Average: f1: 0.7530, precision: 0.7487, recall: 0.7586

 time for training and evaluating:171.0526978969574 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7142
  * recall: 0.7982
  * f1-score: 0.7539
  * support: 11454.0000
 ORG:
  * precision: 0.7765
  * recall: 0.7366
  * f1-score: 0.7560
  * support: 16345.0000
 PER:
  * precision: 0.7535
  * recall: 0.7380
  * f1-score: 0.7457
  * support: 22377.0000
 micro avg:
  * precision: 0.7506
  * recall: 0.7513
  * f1-score: 0.7509
  * support: 50176.0000
 macro avg:
  * precision: 0.7481
  * recall: 0.7576
  * f1-score: 0.7519
  * support: 50176.0000
 weighted avg:
  * precision: 0.7520
  * recall: 0.7513
  * f1-score: 0.7509
  * support: 50176.0000
 accuracy:
  * 0.8565
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0805
 * Micro Average: f1: 0.0946, precision: 0.0664, recall: 0.1643
 * Macro Average: f1: 0.0406, precision: 0.1888, recall: 0.2373

Epoch 2/4, accuracy: 0.4334
 * Micro Average: f1: 0.0200, precision: 0.0492, recall: 0.0125
 * Macro Average: f1: 0.0172, precision: 0.0164, recall: 0.0181

Epoch 3/4, accuracy: 0.4792
 * Micro Average: f1: 0.0024, precision: 0.0527, recall: 0.0012
 * Macro Average: f1: 0.0033, precision: 0.0176, recall: 0.0018

Epoch 4/4, accuracy: 0.4817
 * Micro Average: f1: 0.0007, precision: 0.0365, recall: 0.0003
 * Macro Average: f1: 0.0010, precision: 0.0122, recall: 0.0005

 time for training and evaluating:59.91496753692627 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0613
  * recall: 0.0020
  * f1-score: 0.0039
  * support: 11425.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16361.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22354.0000
 micro avg:
  * precision: 0.0613
  * recall: 0.0005
  * f1-score: 0.0009
  * support: 50140.0000
 macro avg:
  * precision: 0.0204
  * recall: 0.0007
  * f1-score: 0.0013
  * support: 50140.0000
 weighted avg:
  * precision: 0.0140
  * recall: 0.0005
  * f1-score: 0.0009
  * support: 50140.0000
 accuracy:
  * 0.4849
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4837
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:170.32522296905518 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11459.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16366.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22351.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50176.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50176.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50176.0000
 accuracy:
  * 0.4856
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0673
 * Micro Average: f1: 0.0124, precision: 0.0458, recall: 0.0072
 * Macro Average: f1: 0.0154, precision: 0.0371, recall: 0.0102

Epoch 2/4, accuracy: 0.0681
 * Micro Average: f1: 0.0190, precision: 0.0443, recall: 0.0121
 * Macro Average: f1: 0.0212, precision: 0.0624, recall: 0.0146

Epoch 3/4, accuracy: 0.0708
 * Micro Average: f1: 0.0343, precision: 0.0560, recall: 0.0247
 * Macro Average: f1: 0.0357, precision: 0.0738, recall: 0.0258

Epoch 4/4, accuracy: 0.0752
 * Micro Average: f1: 0.0406, precision: 0.0590, recall: 0.0309
 * Macro Average: f1: 0.0420, precision: 0.0768, recall: 0.0314

 time for training and evaluating:60.50784969329834 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0723
  * recall: 0.0457
  * f1-score: 0.0560
  * support: 11447.0000
 ORG:
  * precision: 0.0215
  * recall: 0.0179
  * f1-score: 0.0196
  * support: 16344.0000
 PER:
  * precision: 0.1408
  * recall: 0.0335
  * f1-score: 0.0542
  * support: 22365.0000
 micro avg:
  * precision: 0.0599
  * recall: 0.0312
  * f1-score: 0.0410
  * support: 50156.0000
 macro avg:
  * precision: 0.0782
  * recall: 0.0324
  * f1-score: 0.0432
  * support: 50156.0000
 weighted avg:
  * precision: 0.0863
  * recall: 0.0312
  * f1-score: 0.0433
  * support: 50156.0000
 accuracy:
  * 0.0738
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:170.0429654121399 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11446.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16335.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22360.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50141.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50141.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50141.0000
 accuracy:
  * 0.4856
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1775
 * Micro Average: f1: 0.1876, precision: 0.1365, recall: 0.3000
 * Macro Average: f1: 0.0756, precision: 0.0455, recall: 0.2239

Epoch 2/4, accuracy: 0.4327
 * Micro Average: f1: 0.0770, precision: 0.1597, recall: 0.0508
 * Macro Average: f1: 0.0443, precision: 0.0532, recall: 0.0379

Epoch 3/4, accuracy: 0.4794
 * Micro Average: f1: 0.0078, precision: 0.1762, recall: 0.0040
 * Macro Average: f1: 0.0057, precision: 0.0589, recall: 0.0030

Epoch 4/4, accuracy: 0.4819
 * Micro Average: f1: 0.0031, precision: 0.2000, recall: 0.0015
 * Macro Average: f1: 0.0023, precision: 0.0667, recall: 0.0012

 time for training and evaluating:60.49850845336914 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11449.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16348.0000
 PER:
  * precision: 0.2042
  * recall: 0.0026
  * f1-score: 0.0051
  * support: 22359.0000
 micro avg:
  * precision: 0.2042
  * recall: 0.0012
  * f1-score: 0.0023
  * support: 50156.0000
 macro avg:
  * precision: 0.0681
  * recall: 0.0009
  * f1-score: 0.0017
  * support: 50156.0000
 weighted avg:
  * precision: 0.0910
  * recall: 0.0012
  * f1-score: 0.0023
  * support: 50156.0000
 accuracy:
  * 0.4848
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8593
 * Micro Average: f1: 0.7560, precision: 0.7528, recall: 0.7593
 * Macro Average: f1: 0.7561, precision: 0.7491, recall: 0.7644

Epoch 2/4, accuracy: 0.8772
 * Micro Average: f1: 0.7854, precision: 0.7843, recall: 0.7865
 * Macro Average: f1: 0.7860, precision: 0.7824, recall: 0.7902

Epoch 3/4, accuracy: 0.8824
 * Micro Average: f1: 0.7958, precision: 0.7921, recall: 0.7995
 * Macro Average: f1: 0.7975, precision: 0.7933, recall: 0.8019

Epoch 4/4, accuracy: 0.8854
 * Micro Average: f1: 0.8010, precision: 0.7976, recall: 0.8043
 * Macro Average: f1: 0.8021, precision: 0.7967, recall: 0.8077

 time for training and evaluating:144.40821719169617 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7913
  * recall: 0.8222
  * f1-score: 0.8064
  * support: 11454.0000
 ORG:
  * precision: 0.8009
  * recall: 0.8030
  * f1-score: 0.8019
  * support: 16368.0000
 PER:
  * precision: 0.7868
  * recall: 0.7894
  * f1-score: 0.7881
  * support: 22343.0000
 micro avg:
  * precision: 0.7924
  * recall: 0.8013
  * f1-score: 0.7968
  * support: 50165.0000
 macro avg:
  * precision: 0.7930
  * recall: 0.8048
  * f1-score: 0.7988
  * support: 50165.0000
 weighted avg:
  * precision: 0.7924
  * recall: 0.8013
  * f1-score: 0.7968
  * support: 50165.0000
 accuracy:
  * 0.8826
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1328
 * Micro Average: f1: 0.1964, precision: 0.1355, recall: 0.3567
 * Macro Average: f1: 0.0774, precision: 0.0730, recall: 0.2660

Epoch 2/4, accuracy: 0.1335
 * Micro Average: f1: 0.1963, precision: 0.1355, recall: 0.3563
 * Macro Average: f1: 0.0774, precision: 0.0868, recall: 0.2661

Epoch 3/4, accuracy: 0.1370
 * Micro Average: f1: 0.1973, precision: 0.1363, recall: 0.3567
 * Macro Average: f1: 0.0778, precision: 0.1288, recall: 0.2664

Epoch 4/4, accuracy: 0.1449
 * Micro Average: f1: 0.1983, precision: 0.1374, recall: 0.3561
 * Macro Average: f1: 0.0781, precision: 0.0458, recall: 0.2658

 time for training and evaluating:58.50376319885254 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.2500
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 11441.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16331.0000
 PER:
  * precision: 0.1363
  * recall: 0.7953
  * f1-score: 0.2327
  * support: 22329.0000
 micro avg:
  * precision: 0.1363
  * recall: 0.3545
  * f1-score: 0.1969
  * support: 50101.0000
 macro avg:
  * precision: 0.1288
  * recall: 0.2651
  * f1-score: 0.0776
  * support: 50101.0000
 weighted avg:
  * precision: 0.1178
  * recall: 0.3545
  * f1-score: 0.1037
  * support: 50101.0000
 accuracy:
  * 0.1459
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8594
 * Micro Average: f1: 0.7559, precision: 0.7531, recall: 0.7586
 * Macro Average: f1: 0.7563, precision: 0.7522, recall: 0.7610

Epoch 2/4, accuracy: 0.8757
 * Micro Average: f1: 0.7848, precision: 0.7797, recall: 0.7900
 * Macro Average: f1: 0.7864, precision: 0.7782, recall: 0.7955

Epoch 3/4, accuracy: 0.8825
 * Micro Average: f1: 0.7956, precision: 0.7965, recall: 0.7947
 * Macro Average: f1: 0.7964, precision: 0.7942, recall: 0.7991

Epoch 4/4, accuracy: 0.8848
 * Micro Average: f1: 0.7992, precision: 0.7981, recall: 0.8003
 * Macro Average: f1: 0.8009, precision: 0.7974, recall: 0.8047

 time for training and evaluating:144.5948920249939 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7842
  * recall: 0.8228
  * f1-score: 0.8030
  * support: 11441.0000
 ORG:
  * precision: 0.8005
  * recall: 0.7991
  * f1-score: 0.7998
  * support: 16353.0000
 PER:
  * precision: 0.7885
  * recall: 0.7873
  * f1-score: 0.7879
  * support: 22351.0000
 micro avg:
  * precision: 0.7913
  * recall: 0.7993
  * f1-score: 0.7953
  * support: 50145.0000
 macro avg:
  * precision: 0.7911
  * recall: 0.8031
  * f1-score: 0.7969
  * support: 50145.0000
 weighted avg:
  * precision: 0.7914
  * recall: 0.7993
  * f1-score: 0.7952
  * support: 50145.0000
 accuracy:
  * 0.8818
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1056
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.1060
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.1056
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.1058
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:57.36889672279358 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11443.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16348.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22317.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50108.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50108.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50108.0000
 accuracy:
  * 0.1076
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7498
 * Micro Average: f1: 0.5703, precision: 0.5500, recall: 0.5921
 * Macro Average: f1: 0.5694, precision: 0.5507, recall: 0.5904

Epoch 2/4, accuracy: 0.8221
 * Micro Average: f1: 0.6912, precision: 0.6862, recall: 0.6963
 * Macro Average: f1: 0.6918, precision: 0.6818, recall: 0.7041

Epoch 3/4, accuracy: 0.8378
 * Micro Average: f1: 0.7177, precision: 0.7162, recall: 0.7193
 * Macro Average: f1: 0.7184, precision: 0.7120, recall: 0.7275

Epoch 4/4, accuracy: 0.8431
 * Micro Average: f1: 0.7286, precision: 0.7271, recall: 0.7302
 * Macro Average: f1: 0.7303, precision: 0.7239, recall: 0.7390

 time for training and evaluating:144.5526294708252 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6842
  * recall: 0.7868
  * f1-score: 0.7319
  * support: 11433.0000
 ORG:
  * precision: 0.7505
  * recall: 0.7083
  * f1-score: 0.7288
  * support: 16370.0000
 PER:
  * precision: 0.7345
  * recall: 0.7083
  * f1-score: 0.7212
  * support: 22342.0000
 micro avg:
  * precision: 0.7263
  * recall: 0.7262
  * f1-score: 0.7262
  * support: 50145.0000
 macro avg:
  * precision: 0.7231
  * recall: 0.7345
  * f1-score: 0.7273
  * support: 50145.0000
 weighted avg:
  * precision: 0.7283
  * recall: 0.7262
  * f1-score: 0.7261
  * support: 50145.0000
 accuracy:
  * 0.8430
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0845
 * Micro Average: f1: 0.0845, precision: 0.0827, recall: 0.0863
 * Macro Average: f1: 0.0849, precision: 0.0938, recall: 0.0847

Epoch 2/4, accuracy: 0.3506
 * Micro Average: f1: 0.1193, precision: 0.1308, recall: 0.1096
 * Macro Average: f1: 0.1061, precision: 0.1235, recall: 0.0969

Epoch 3/4, accuracy: 0.4542
 * Micro Average: f1: 0.0838, precision: 0.1942, recall: 0.0534
 * Macro Average: f1: 0.0642, precision: 0.1349, recall: 0.0428

Epoch 4/4, accuracy: 0.4672
 * Micro Average: f1: 0.0684, precision: 0.2269, recall: 0.0403
 * Macro Average: f1: 0.0510, precision: 0.1461, recall: 0.0316

 time for training and evaluating:57.71497416496277 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0449
  * recall: 0.0030
  * f1-score: 0.0056
  * support: 11436.0000
 ORG:
  * precision: 0.0931
  * recall: 0.0133
  * f1-score: 0.0232
  * support: 16365.0000
 PER:
  * precision: 0.2989
  * recall: 0.0802
  * f1-score: 0.1265
  * support: 22332.0000
 micro avg:
  * precision: 0.2249
  * recall: 0.0408
  * f1-score: 0.0690
  * support: 50133.0000
 macro avg:
  * precision: 0.1456
  * recall: 0.0322
  * f1-score: 0.0518
  * support: 50133.0000
 weighted avg:
  * precision: 0.1738
  * recall: 0.0408
  * f1-score: 0.0652
  * support: 50133.0000
 accuracy:
  * 0.4702
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7639
 * Micro Average: f1: 0.5838, precision: 0.5607, recall: 0.6089
 * Macro Average: f1: 0.5805, precision: 0.5595, recall: 0.6042

Epoch 2/4, accuracy: 0.8274
 * Micro Average: f1: 0.6977, precision: 0.6942, recall: 0.7013
 * Macro Average: f1: 0.6975, precision: 0.6893, recall: 0.7075

Epoch 3/4, accuracy: 0.8400
 * Micro Average: f1: 0.7215, precision: 0.7189, recall: 0.7241
 * Macro Average: f1: 0.7221, precision: 0.7162, recall: 0.7305

Epoch 4/4, accuracy: 0.8446
 * Micro Average: f1: 0.7302, precision: 0.7276, recall: 0.7329
 * Macro Average: f1: 0.7306, precision: 0.7238, recall: 0.7400

 time for training and evaluating:144.3776364326477 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6813
  * recall: 0.7948
  * f1-score: 0.7337
  * support: 11450.0000
 ORG:
  * precision: 0.7574
  * recall: 0.7080
  * f1-score: 0.7319
  * support: 16352.0000
 PER:
  * precision: 0.7360
  * recall: 0.7128
  * f1-score: 0.7242
  * support: 22342.0000
 micro avg:
  * precision: 0.7280
  * recall: 0.7300
  * f1-score: 0.7290
  * support: 50144.0000
 macro avg:
  * precision: 0.7249
  * recall: 0.7385
  * f1-score: 0.7299
  * support: 50144.0000
 weighted avg:
  * precision: 0.7305
  * recall: 0.7300
  * f1-score: 0.7289
  * support: 50144.0000
 accuracy:
  * 0.8450
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0609
 * Micro Average: f1: 0.0998, precision: 0.0688, recall: 0.1814
 * Macro Average: f1: 0.0422, precision: 0.0229, recall: 0.2624

Epoch 2/4, accuracy: 0.1408
 * Micro Average: f1: 0.0735, precision: 0.0558, recall: 0.1074
 * Macro Average: f1: 0.0332, precision: 0.0186, recall: 0.1555

Epoch 3/4, accuracy: 0.2529
 * Micro Average: f1: 0.0465, precision: 0.0435, recall: 0.0500
 * Macro Average: f1: 0.0241, precision: 0.0145, recall: 0.0723

Epoch 4/4, accuracy: 0.3008
 * Micro Average: f1: 0.0405, precision: 0.0426, recall: 0.0387
 * Macro Average: f1: 0.0227, precision: 0.0142, recall: 0.0558

 time for training and evaluating:58.05572438240051 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0420
  * recall: 0.1675
  * f1-score: 0.0672
  * support: 11430.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16374.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22346.0000
 micro avg:
  * precision: 0.0420
  * recall: 0.0382
  * f1-score: 0.0400
  * support: 50150.0000
 macro avg:
  * precision: 0.0140
  * recall: 0.0558
  * f1-score: 0.0224
  * support: 50150.0000
 weighted avg:
  * precision: 0.0096
  * recall: 0.0382
  * f1-score: 0.0153
  * support: 50150.0000
 accuracy:
  * 0.3026
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4811
 * Micro Average: f1: 0.0985, precision: 0.2250, recall: 0.0630
 * Macro Average: f1: 0.0579, precision: 0.0750, recall: 0.0471

Epoch 2/4, accuracy: 0.4835
 * Micro Average: f1: 0.0018, precision: 0.4000, recall: 0.0009
 * Macro Average: f1: 0.0013, precision: 0.1333, recall: 0.0007

Epoch 3/4, accuracy: 0.4832
 * Micro Average: f1: 0.0001, precision: 0.3333, recall: 0.0001
 * Macro Average: f1: 0.0001, precision: 0.1111, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:144.20857310295105 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11430.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16352.0000
 PER:
  * precision: 0.7500
  * recall: 0.0001
  * f1-score: 0.0003
  * support: 22339.0000
 micro avg:
  * precision: 0.7500
  * recall: 0.0001
  * f1-score: 0.0001
  * support: 50121.0000
 macro avg:
  * precision: 0.2500
  * recall: 0.0000
  * f1-score: 0.0001
  * support: 50121.0000
 weighted avg:
  * precision: 0.3343
  * recall: 0.0001
  * f1-score: 0.0001
  * support: 50121.0000
 accuracy:
  * 0.4857
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0800
 * Micro Average: f1: 0.0730, precision: 0.0701, recall: 0.0762
 * Macro Average: f1: 0.0365, precision: 0.0460, recall: 0.0785

Epoch 2/4, accuracy: 0.0831
 * Micro Average: f1: 0.0848, precision: 0.0761, recall: 0.0957
 * Macro Average: f1: 0.0409, precision: 0.0550, recall: 0.0988

Epoch 3/4, accuracy: 0.1105
 * Micro Average: f1: 0.0889, precision: 0.0787, recall: 0.1022
 * Macro Average: f1: 0.0424, precision: 0.0910, recall: 0.1056

Epoch 4/4, accuracy: 0.1347
 * Micro Average: f1: 0.0915, precision: 0.0812, recall: 0.1048
 * Macro Average: f1: 0.0436, precision: 0.1144, recall: 0.1082

 time for training and evaluating:58.269378900527954 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0455
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 11456.0000
 ORG:
  * precision: 0.0831
  * recall: 0.3274
  * f1-score: 0.1326
  * support: 16338.0000
 PER:
  * precision: 0.1304
  * recall: 0.0001
  * f1-score: 0.0003
  * support: 22369.0000
 micro avg:
  * precision: 0.0831
  * recall: 0.1067
  * f1-score: 0.0934
  * support: 50163.0000
 macro avg:
  * precision: 0.0863
  * recall: 0.1092
  * f1-score: 0.0443
  * support: 50163.0000
 weighted avg:
  * precision: 0.0956
  * recall: 0.1067
  * f1-score: 0.0433
  * support: 50163.0000
 accuracy:
  * 0.1374
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4831
 * Micro Average: f1: 0.0003, precision: 0.0968, recall: 0.0001
 * Macro Average: f1: 0.0004, precision: 0.1037, recall: 0.0002

Epoch 2/4, accuracy: 0.4837
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4838
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4840
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:144.16670393943787 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11453.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16351.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 22348.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50152.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50152.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 50152.0000
 accuracy:
  * 0.4856
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-en.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1060
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.1084
 * Micro Average: f1: 0.0004, precision: 0.0046, recall: 0.0002
 * Macro Average: f1: 0.0003, precision: 0.0015, recall: 0.0001

Epoch 3/4, accuracy: 0.1223
 * Micro Average: f1: 0.0081, precision: 0.0221, recall: 0.0049
 * Macro Average: f1: 0.0049, precision: 0.0074, recall: 0.0037

Epoch 4/4, accuracy: 0.1394
 * Micro Average: f1: 0.0160, precision: 0.0322, recall: 0.0107
 * Macro Average: f1: 0.0091, precision: 0.0107, recall: 0.0080

 time for training and evaluating:57.99493050575256 for train language combination:train-en.tsv.gz and test language: dev-en.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 11443.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 16363.0000
 PER:
  * precision: 0.0349
  * recall: 0.0259
  * f1-score: 0.0297
  * support: 22321.0000
 micro avg:
  * precision: 0.0349
  * recall: 0.0115
  * f1-score: 0.0173
  * support: 50127.0000
 macro avg:
  * precision: 0.0116
  * recall: 0.0086
  * f1-score: 0.0099
  * support: 50127.0000
 weighted avg:
  * precision: 0.0155
  * recall: 0.0115
  * f1-score: 0.0132
  * support: 50127.0000
 accuracy:
  * 0.1412
________________________________________


Map:   0%|          | 0/8931 [00:00<?, ? examples/s]Map:  11%|█         | 1000/8931 [00:00<00:01, 5617.47 examples/s]Map:  22%|██▏       | 2000/8931 [00:00<00:01, 5868.09 examples/s]Map:  34%|███▎      | 3000/8931 [00:00<00:01, 5886.53 examples/s]Map:  45%|████▍     | 4000/8931 [00:00<00:00, 5889.81 examples/s]Map:  56%|█████▌    | 5000/8931 [00:00<00:00, 5876.13 examples/s]Map:  67%|██████▋   | 6000/8931 [00:01<00:00, 4301.86 examples/s]Map:  78%|███████▊  | 7000/8931 [00:01<00:00, 4724.64 examples/s]Map:  90%|████████▉ | 8000/8931 [00:01<00:00, 4979.04 examples/s]Map: 100%|██████████| 8931/8931 [00:01<00:00, 5217.07 examples/s]Map: 100%|██████████| 8931/8931 [00:01<00:00, 5213.08 examples/s]
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8706
 * Micro Average: f1: 0.7752, precision: 0.7883, recall: 0.7625
 * Macro Average: f1: 0.7778, precision: 0.7840, recall: 0.7757

Epoch 2/4, accuracy: 0.8872
 * Micro Average: f1: 0.8040, precision: 0.7968, recall: 0.8114
 * Macro Average: f1: 0.8060, precision: 0.7959, recall: 0.8169

Epoch 3/4, accuracy: 0.8903
 * Micro Average: f1: 0.8099, precision: 0.8030, recall: 0.8170
 * Macro Average: f1: 0.8123, precision: 0.8025, recall: 0.8229

Epoch 4/4, accuracy: 0.8923
 * Micro Average: f1: 0.8146, precision: 0.8127, recall: 0.8165
 * Macro Average: f1: 0.8169, precision: 0.8124, recall: 0.8216

 time for training and evaluating:213.1485002040863 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7763
  * recall: 0.7623
  * f1-score: 0.7692
  * support: 9913.0000
 ORG:
  * precision: 0.6570
  * recall: 0.7372
  * f1-score: 0.6948
  * support: 17473.0000
 PER:
  * precision: 0.6571
  * recall: 0.8115
  * f1-score: 0.7262
  * support: 15269.0000
 micro avg:
  * precision: 0.6811
  * recall: 0.7696
  * f1-score: 0.7227
  * support: 42655.0000
 macro avg:
  * precision: 0.6968
  * recall: 0.7703
  * f1-score: 0.7301
  * support: 42655.0000
 weighted avg:
  * precision: 0.6848
  * recall: 0.7696
  * f1-score: 0.7233
  * support: 42655.0000
 accuracy:
  * 0.8644
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4833
 * Micro Average: f1: 0.0001, precision: 1.0000, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.3333, recall: 0.0001

Epoch 2/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:61.942970752716064 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9904.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17484.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15254.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42642.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42642.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42642.0000
 accuracy:
  * 0.6543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8755
 * Micro Average: f1: 0.7851, precision: 0.7797, recall: 0.7907
 * Macro Average: f1: 0.7863, precision: 0.7814, recall: 0.7915

Epoch 2/4, accuracy: 0.8855
 * Micro Average: f1: 0.8035, precision: 0.7979, recall: 0.8092
 * Macro Average: f1: 0.8046, precision: 0.8024, recall: 0.8072

Epoch 3/4, accuracy: 0.8909
 * Micro Average: f1: 0.8115, precision: 0.7999, recall: 0.8234
 * Macro Average: f1: 0.8126, precision: 0.7997, recall: 0.8264

Epoch 4/4, accuracy: 0.8927
 * Micro Average: f1: 0.8150, precision: 0.8124, recall: 0.8177
 * Macro Average: f1: 0.8167, precision: 0.8122, recall: 0.8214

 time for training and evaluating:211.07067465782166 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7892
  * recall: 0.7566
  * f1-score: 0.7726
  * support: 9903.0000
 ORG:
  * precision: 0.6590
  * recall: 0.7486
  * f1-score: 0.7010
  * support: 17488.0000
 PER:
  * precision: 0.6633
  * recall: 0.8134
  * f1-score: 0.7307
  * support: 15255.0000
 micro avg:
  * precision: 0.6864
  * recall: 0.7737
  * f1-score: 0.7274
  * support: 42646.0000
 macro avg:
  * precision: 0.7038
  * recall: 0.7729
  * f1-score: 0.7348
  * support: 42646.0000
 weighted avg:
  * precision: 0.6908
  * recall: 0.7737
  * f1-score: 0.7282
  * support: 42646.0000
 accuracy:
  * 0.8712
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4061
 * Micro Average: f1: 0.1284, precision: 0.1385, recall: 0.1198
 * Macro Average: f1: 0.1087, precision: 0.2065, recall: 0.1162

Epoch 2/4, accuracy: 0.4832
 * Micro Average: f1: 0.0010, precision: 0.4000, recall: 0.0005
 * Macro Average: f1: 0.0008, precision: 0.4583, recall: 0.0004

Epoch 3/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.30983877182007 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9909.0000
 ORG:
  * precision: 1.0000
  * recall: 0.0001
  * f1-score: 0.0001
  * support: 17500.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15251.0000
 micro avg:
  * precision: 0.2500
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42660.0000
 macro avg:
  * precision: 0.3333
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42660.0000
 weighted avg:
  * precision: 0.4102
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42660.0000
 accuracy:
  * 0.6542
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8281
 * Micro Average: f1: 0.6996, precision: 0.7004, recall: 0.6987
 * Macro Average: f1: 0.6981, precision: 0.6954, recall: 0.7055

Epoch 2/4, accuracy: 0.8580
 * Micro Average: f1: 0.7553, precision: 0.7500, recall: 0.7607
 * Macro Average: f1: 0.7563, precision: 0.7461, recall: 0.7683

Epoch 3/4, accuracy: 0.8647
 * Micro Average: f1: 0.7684, precision: 0.7703, recall: 0.7665
 * Macro Average: f1: 0.7698, precision: 0.7670, recall: 0.7740

Epoch 4/4, accuracy: 0.8666
 * Micro Average: f1: 0.7704, precision: 0.7700, recall: 0.7708
 * Macro Average: f1: 0.7710, precision: 0.7669, recall: 0.7769

 time for training and evaluating:213.0684790611267 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7311
  * recall: 0.7557
  * f1-score: 0.7432
  * support: 9903.0000
 ORG:
  * precision: 0.6146
  * recall: 0.6974
  * f1-score: 0.6534
  * support: 17497.0000
 PER:
  * precision: 0.5863
  * recall: 0.7897
  * f1-score: 0.6730
  * support: 15248.0000
 micro avg:
  * precision: 0.6267
  * recall: 0.7440
  * f1-score: 0.6803
  * support: 42648.0000
 macro avg:
  * precision: 0.6440
  * recall: 0.7476
  * f1-score: 0.6899
  * support: 42648.0000
 weighted avg:
  * precision: 0.6316
  * recall: 0.7440
  * f1-score: 0.6813
  * support: 42648.0000
 accuracy:
  * 0.8443
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.45620059967041 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9908.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17495.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15253.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42656.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42656.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42656.0000
 accuracy:
  * 0.6542
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8280
 * Micro Average: f1: 0.6974, precision: 0.7017, recall: 0.6932
 * Macro Average: f1: 0.6968, precision: 0.6961, recall: 0.6998

Epoch 2/4, accuracy: 0.8502
 * Micro Average: f1: 0.7405, precision: 0.7388, recall: 0.7422
 * Macro Average: f1: 0.7405, precision: 0.7347, recall: 0.7483

Epoch 3/4, accuracy: 0.8652
 * Micro Average: f1: 0.7681, precision: 0.7637, recall: 0.7725
 * Macro Average: f1: 0.7689, precision: 0.7628, recall: 0.7757

Epoch 4/4, accuracy: 0.8666
 * Micro Average: f1: 0.7705, precision: 0.7659, recall: 0.7752
 * Macro Average: f1: 0.7717, precision: 0.7637, recall: 0.7808

 time for training and evaluating:213.49707794189453 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7402
  * recall: 0.7550
  * f1-score: 0.7476
  * support: 9904.0000
 ORG:
  * precision: 0.5956
  * recall: 0.7177
  * f1-score: 0.6510
  * support: 17482.0000
 PER:
  * precision: 0.5899
  * recall: 0.7897
  * f1-score: 0.6753
  * support: 15242.0000
 micro avg:
  * precision: 0.6217
  * recall: 0.7521
  * f1-score: 0.6807
  * support: 42628.0000
 macro avg:
  * precision: 0.6419
  * recall: 0.7541
  * f1-score: 0.6913
  * support: 42628.0000
 weighted avg:
  * precision: 0.6272
  * recall: 0.7521
  * f1-score: 0.6821
  * support: 42628.0000
 accuracy:
  * 0.8390
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4830
 * Micro Average: f1: 0.0006, precision: 0.1714, recall: 0.0003
 * Macro Average: f1: 0.0005, precision: 0.1002, recall: 0.0003

Epoch 2/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:64.01769042015076 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9898.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17491.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15262.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42651.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42651.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42651.0000
 accuracy:
  * 0.6543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4831
 * Micro Average: f1: 0.0105, precision: 0.1922, recall: 0.0054
 * Macro Average: f1: 0.0104, precision: 0.2554, recall: 0.0056

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:211.97096920013428 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9907.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17492.0000
 PER:
  * precision: 0.3333
  * recall: 0.0001
  * f1-score: 0.0001
  * support: 15244.0000
 micro avg:
  * precision: 0.3333
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42643.0000
 macro avg:
  * precision: 0.1111
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42643.0000
 weighted avg:
  * precision: 0.1192
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42643.0000
 accuracy:
  * 0.6543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4827
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:62.67258977890015 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9907.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17498.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15257.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42662.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42662.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42662.0000
 accuracy:
  * 0.6543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:212.76750946044922 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9902.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17476.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15258.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42636.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42636.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42636.0000
 accuracy:
  * 0.6543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4808
 * Micro Average: f1: 0.0012, precision: 0.0500, recall: 0.0006
 * Macro Average: f1: 0.0016, precision: 0.1266, recall: 0.0008

Epoch 2/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.896477699279785 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9906.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17490.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15252.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42648.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42648.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42648.0000
 accuracy:
  * 0.6543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8711
 * Micro Average: f1: 0.7747, precision: 0.7791, recall: 0.7703
 * Macro Average: f1: 0.7758, precision: 0.7757, recall: 0.7770

Epoch 2/4, accuracy: 0.8859
 * Micro Average: f1: 0.8030, precision: 0.7951, recall: 0.8111
 * Macro Average: f1: 0.8047, precision: 0.7950, recall: 0.8148

Epoch 3/4, accuracy: 0.8882
 * Micro Average: f1: 0.8061, precision: 0.8009, recall: 0.8113
 * Macro Average: f1: 0.8072, precision: 0.7993, recall: 0.8161

Epoch 4/4, accuracy: 0.8911
 * Micro Average: f1: 0.8112, precision: 0.8080, recall: 0.8145
 * Macro Average: f1: 0.8131, precision: 0.8073, recall: 0.8193

 time for training and evaluating:170.18936109542847 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7890
  * recall: 0.7562
  * f1-score: 0.7722
  * support: 9902.0000
 ORG:
  * precision: 0.6491
  * recall: 0.7488
  * f1-score: 0.6954
  * support: 17499.0000
 PER:
  * precision: 0.6469
  * recall: 0.8083
  * f1-score: 0.7187
  * support: 15241.0000
 micro avg:
  * precision: 0.6755
  * recall: 0.7718
  * f1-score: 0.7204
  * support: 42642.0000
 macro avg:
  * precision: 0.6950
  * recall: 0.7711
  * f1-score: 0.7288
  * support: 42642.0000
 weighted avg:
  * precision: 0.6808
  * recall: 0.7718
  * f1-score: 0.7215
  * support: 42642.0000
 accuracy:
  * 0.8659
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0840
 * Micro Average: f1: 0.1492, precision: 0.1027, recall: 0.2732
 * Macro Average: f1: 0.0610, precision: 0.0342, recall: 0.2815

Epoch 2/4, accuracy: 0.3427
 * Micro Average: f1: 0.1585, precision: 0.1337, recall: 0.1948
 * Macro Average: f1: 0.0729, precision: 0.0446, recall: 0.2006

Epoch 3/4, accuracy: 0.4755
 * Micro Average: f1: 0.0475, precision: 0.1710, recall: 0.0276
 * Macro Average: f1: 0.0380, precision: 0.0570, recall: 0.0285

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0196, precision: 0.1956, recall: 0.0103
 * Macro Average: f1: 0.0183, precision: 0.0652, recall: 0.0107

 time for training and evaluating:60.03508806228638 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9895.0000
 ORG:
  * precision: 0.1177
  * recall: 0.0349
  * f1-score: 0.0538
  * support: 17481.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15263.0000
 micro avg:
  * precision: 0.1177
  * recall: 0.0143
  * f1-score: 0.0255
  * support: 42639.0000
 macro avg:
  * precision: 0.0392
  * recall: 0.0116
  * f1-score: 0.0179
  * support: 42639.0000
 weighted avg:
  * precision: 0.0483
  * recall: 0.0143
  * f1-score: 0.0221
  * support: 42639.0000
 accuracy:
  * 0.6393
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8679
 * Micro Average: f1: 0.7693, precision: 0.7756, recall: 0.7630
 * Macro Average: f1: 0.7710, precision: 0.7707, recall: 0.7751

Epoch 2/4, accuracy: 0.8818
 * Micro Average: f1: 0.7969, precision: 0.7928, recall: 0.8010
 * Macro Average: f1: 0.7981, precision: 0.7920, recall: 0.8049

Epoch 3/4, accuracy: 0.8891
 * Micro Average: f1: 0.8092, precision: 0.8038, recall: 0.8147
 * Macro Average: f1: 0.8102, precision: 0.8040, recall: 0.8166

Epoch 4/4, accuracy: 0.8893
 * Micro Average: f1: 0.8090, precision: 0.8054, recall: 0.8126
 * Macro Average: f1: 0.8107, precision: 0.8046, recall: 0.8173

 time for training and evaluating:169.77357029914856 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7838
  * recall: 0.7584
  * f1-score: 0.7709
  * support: 9912.0000
 ORG:
  * precision: 0.6477
  * recall: 0.7475
  * f1-score: 0.6940
  * support: 17506.0000
 PER:
  * precision: 0.6735
  * recall: 0.8065
  * f1-score: 0.7340
  * support: 15257.0000
 micro avg:
  * precision: 0.6846
  * recall: 0.7711
  * f1-score: 0.7253
  * support: 42675.0000
 macro avg:
  * precision: 0.7016
  * recall: 0.7708
  * f1-score: 0.7330
  * support: 42675.0000
 weighted avg:
  * precision: 0.6885
  * recall: 0.7711
  * f1-score: 0.7262
  * support: 42675.0000
 accuracy:
  * 0.8664
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0853
 * Micro Average: f1: 0.1497, precision: 0.1031, recall: 0.2734
 * Macro Average: f1: 0.0613, precision: 0.2010, recall: 0.2818

Epoch 2/4, accuracy: 0.4408
 * Micro Average: f1: 0.1067, precision: 0.1514, recall: 0.0823
 * Macro Average: f1: 0.0633, precision: 0.0505, recall: 0.0849

Epoch 3/4, accuracy: 0.4831
 * Micro Average: f1: 0.0095, precision: 0.1825, recall: 0.0049
 * Macro Average: f1: 0.0093, precision: 0.2271, recall: 0.0050

Epoch 4/4, accuracy: 0.4829
 * Micro Average: f1: 0.0037, precision: 0.2216, recall: 0.0018
 * Macro Average: f1: 0.0037, precision: 0.0743, recall: 0.0019

 time for training and evaluating:59.97118258476257 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9911.0000
 ORG:
  * precision: 0.0713
  * recall: 0.0222
  * f1-score: 0.0338
  * support: 17490.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15248.0000
 micro avg:
  * precision: 0.0712
  * recall: 0.0091
  * f1-score: 0.0161
  * support: 42649.0000
 macro avg:
  * precision: 0.0238
  * recall: 0.0074
  * f1-score: 0.0113
  * support: 42649.0000
 weighted avg:
  * precision: 0.0292
  * recall: 0.0091
  * f1-score: 0.0139
  * support: 42649.0000
 accuracy:
  * 0.6319
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8063
 * Micro Average: f1: 0.6613, precision: 0.6565, recall: 0.6662
 * Macro Average: f1: 0.6599, precision: 0.6503, recall: 0.6726

Epoch 2/4, accuracy: 0.8425
 * Micro Average: f1: 0.7299, precision: 0.7242, recall: 0.7357
 * Macro Average: f1: 0.7305, precision: 0.7209, recall: 0.7426

Epoch 3/4, accuracy: 0.8524
 * Micro Average: f1: 0.7465, precision: 0.7479, recall: 0.7451
 * Macro Average: f1: 0.7471, precision: 0.7440, recall: 0.7529

Epoch 4/4, accuracy: 0.8582
 * Micro Average: f1: 0.7561, precision: 0.7542, recall: 0.7580
 * Macro Average: f1: 0.7568, precision: 0.7508, recall: 0.7645

 time for training and evaluating:169.99079489707947 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7136
  * recall: 0.7610
  * f1-score: 0.7365
  * support: 9908.0000
 ORG:
  * precision: 0.5832
  * recall: 0.6990
  * f1-score: 0.6359
  * support: 17487.0000
 PER:
  * precision: 0.5935
  * recall: 0.7822
  * f1-score: 0.6749
  * support: 15259.0000
 micro avg:
  * precision: 0.6139
  * recall: 0.7432
  * f1-score: 0.6724
  * support: 42654.0000
 macro avg:
  * precision: 0.6301
  * recall: 0.7474
  * f1-score: 0.6824
  * support: 42654.0000
 weighted avg:
  * precision: 0.6172
  * recall: 0.7432
  * f1-score: 0.6732
  * support: 42654.0000
 accuracy:
  * 0.8373
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4837
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4840
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4826
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:59.446322202682495 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9912.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17481.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15250.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42643.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42643.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42643.0000
 accuracy:
  * 0.6542
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8122
 * Micro Average: f1: 0.6694, precision: 0.6600, recall: 0.6791
 * Macro Average: f1: 0.6677, precision: 0.6536, recall: 0.6853

Epoch 2/4, accuracy: 0.8427
 * Micro Average: f1: 0.7240, precision: 0.7282, recall: 0.7198
 * Macro Average: f1: 0.7227, precision: 0.7223, recall: 0.7301

Epoch 3/4, accuracy: 0.8564
 * Micro Average: f1: 0.7520, precision: 0.7530, recall: 0.7510
 * Macro Average: f1: 0.7526, precision: 0.7486, recall: 0.7590

Epoch 4/4, accuracy: 0.8590
 * Micro Average: f1: 0.7556, precision: 0.7556, recall: 0.7556
 * Macro Average: f1: 0.7558, precision: 0.7518, recall: 0.7620

 time for training and evaluating:169.93453669548035 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7094
  * recall: 0.7566
  * f1-score: 0.7322
  * support: 9897.0000
 ORG:
  * precision: 0.5926
  * recall: 0.6967
  * f1-score: 0.6404
  * support: 17500.0000
 PER:
  * precision: 0.5670
  * recall: 0.7814
  * f1-score: 0.6571
  * support: 15247.0000
 micro avg:
  * precision: 0.6059
  * recall: 0.7409
  * f1-score: 0.6666
  * support: 42644.0000
 macro avg:
  * precision: 0.6230
  * recall: 0.7449
  * f1-score: 0.6766
  * support: 42644.0000
 weighted avg:
  * precision: 0.6105
  * recall: 0.7409
  * f1-score: 0.6677
  * support: 42644.0000
 accuracy:
  * 0.8358
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4764
 * Micro Average: f1: 0.0041, precision: 0.0501, recall: 0.0022
 * Macro Average: f1: 0.0046, precision: 0.0357, recall: 0.0025

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:59.805832862854004 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9897.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17482.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15256.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42635.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42635.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42635.0000
 accuracy:
  * 0.6543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4826
 * Micro Average: f1: 0.0012, precision: 0.2182, recall: 0.0006
 * Macro Average: f1: 0.0011, precision: 0.1364, recall: 0.0006

Epoch 2/4, accuracy: 0.4825
 * Micro Average: f1: 0.0002, precision: 0.2000, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.1389, recall: 0.0001

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:169.35773539543152 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9906.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17484.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15260.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42650.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42650.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42650.0000
 accuracy:
  * 0.6543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1292
 * Micro Average: f1: 0.0135, precision: 0.0247, recall: 0.0093
 * Macro Average: f1: 0.0102, precision: 0.0082, recall: 0.0134

Epoch 2/4, accuracy: 0.4599
 * Micro Average: f1: 0.0065, precision: 0.0368, recall: 0.0035
 * Macro Average: f1: 0.0072, precision: 0.0123, recall: 0.0051

Epoch 3/4, accuracy: 0.4816
 * Micro Average: f1: 0.0011, precision: 0.0991, recall: 0.0005
 * Macro Average: f1: 0.0015, precision: 0.0330, recall: 0.0008

Epoch 4/4, accuracy: 0.4826
 * Micro Average: f1: 0.0005, precision: 0.1429, recall: 0.0002
 * Macro Average: f1: 0.0007, precision: 0.0476, recall: 0.0004

 time for training and evaluating:59.5982506275177 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0086
  * recall: 0.0008
  * f1-score: 0.0015
  * support: 9909.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17492.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15254.0000
 micro avg:
  * precision: 0.0086
  * recall: 0.0002
  * f1-score: 0.0004
  * support: 42655.0000
 macro avg:
  * precision: 0.0029
  * recall: 0.0003
  * f1-score: 0.0005
  * support: 42655.0000
 weighted avg:
  * precision: 0.0020
  * recall: 0.0002
  * f1-score: 0.0003
  * support: 42655.0000
 accuracy:
  * 0.6490
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4834
 * Micro Average: f1: 0.0048, precision: 0.1109, recall: 0.0025
 * Macro Average: f1: 0.0042, precision: 0.0912, recall: 0.0022

Epoch 2/4, accuracy: 0.4840
 * Micro Average: f1: 0.0004, precision: 0.0784, recall: 0.0002
 * Macro Average: f1: 0.0004, precision: 0.0630, recall: 0.0002

Epoch 3/4, accuracy: 0.4828
 * Micro Average: f1: 0.0002, precision: 0.0769, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.0602, recall: 0.0001

Epoch 4/4, accuracy: 0.4835
 * Micro Average: f1: 0.0002, precision: 0.1429, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.1037, recall: 0.0001

 time for training and evaluating:169.32863521575928 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9909.0000
 ORG:
  * precision: 0.5000
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 17491.0000
 PER:
  * precision: 0.4000
  * recall: 0.0001
  * f1-score: 0.0003
  * support: 15253.0000
 micro avg:
  * precision: 0.4444
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 42653.0000
 macro avg:
  * precision: 0.3000
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 42653.0000
 weighted avg:
  * precision: 0.3481
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 42653.0000
 accuracy:
  * 0.6542
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0608
 * Micro Average: f1: 0.1000, precision: 0.0691, recall: 0.1807
 * Macro Average: f1: 0.0518, precision: 0.0449, recall: 0.2560

Epoch 2/4, accuracy: 0.1384
 * Micro Average: f1: 0.0754, precision: 0.0574, recall: 0.1096
 * Macro Average: f1: 0.0465, precision: 0.0387, recall: 0.1497

Epoch 3/4, accuracy: 0.2745
 * Micro Average: f1: 0.0394, precision: 0.0396, recall: 0.0393
 * Macro Average: f1: 0.0284, precision: 0.0339, recall: 0.0512

Epoch 4/4, accuracy: 0.3270
 * Micro Average: f1: 0.0285, precision: 0.0342, recall: 0.0244
 * Macro Average: f1: 0.0218, precision: 0.0346, recall: 0.0309

 time for training and evaluating:60.379329681396484 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0206
  * recall: 0.1197
  * f1-score: 0.0352
  * support: 9901.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17467.0000
 PER:
  * precision: 0.0366
  * recall: 0.0118
  * f1-score: 0.0178
  * support: 15259.0000
 micro avg:
  * precision: 0.0219
  * recall: 0.0320
  * f1-score: 0.0260
  * support: 42627.0000
 macro avg:
  * precision: 0.0191
  * recall: 0.0438
  * f1-score: 0.0177
  * support: 42627.0000
 weighted avg:
  * precision: 0.0179
  * recall: 0.0320
  * f1-score: 0.0146
  * support: 42627.0000
 accuracy:
  * 0.3814
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8538
 * Micro Average: f1: 0.7443, precision: 0.7513, recall: 0.7375
 * Macro Average: f1: 0.7453, precision: 0.7464, recall: 0.7467

Epoch 2/4, accuracy: 0.8772
 * Micro Average: f1: 0.7871, precision: 0.7841, recall: 0.7902
 * Macro Average: f1: 0.7881, precision: 0.7830, recall: 0.7934

Epoch 3/4, accuracy: 0.8834
 * Micro Average: f1: 0.7987, precision: 0.7951, recall: 0.8024
 * Macro Average: f1: 0.8003, precision: 0.7939, recall: 0.8076

Epoch 4/4, accuracy: 0.8851
 * Micro Average: f1: 0.8005, precision: 0.7979, recall: 0.8030
 * Macro Average: f1: 0.8019, precision: 0.7968, recall: 0.8074

 time for training and evaluating:144.41614699363708 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7766
  * recall: 0.7565
  * f1-score: 0.7664
  * support: 9882.0000
 ORG:
  * precision: 0.6430
  * recall: 0.7302
  * f1-score: 0.6838
  * support: 17404.0000
 PER:
  * precision: 0.6496
  * recall: 0.8064
  * f1-score: 0.7196
  * support: 15200.0000
 micro avg:
  * precision: 0.6722
  * recall: 0.7636
  * f1-score: 0.7150
  * support: 42486.0000
 macro avg:
  * precision: 0.6897
  * recall: 0.7644
  * f1-score: 0.7233
  * support: 42486.0000
 weighted avg:
  * precision: 0.6764
  * recall: 0.7636
  * f1-score: 0.7158
  * support: 42486.0000
 accuracy:
  * 0.8626
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1797
 * Micro Average: f1: 0.2043, precision: 0.1429, recall: 0.3583
 * Macro Average: f1: 0.0847, precision: 0.0681, recall: 0.2676

Epoch 2/4, accuracy: 0.4180
 * Micro Average: f1: 0.1983, precision: 0.1745, recall: 0.2294
 * Macro Average: f1: 0.0876, precision: 0.0903, recall: 0.1716

Epoch 3/4, accuracy: 0.4735
 * Micro Average: f1: 0.1203, precision: 0.1791, recall: 0.0906
 * Macro Average: f1: 0.0636, precision: 0.0806, recall: 0.0678

Epoch 4/4, accuracy: 0.4809
 * Micro Average: f1: 0.0886, precision: 0.1812, recall: 0.0586
 * Macro Average: f1: 0.0508, precision: 0.0605, recall: 0.0438

 time for training and evaluating:57.91957068443298 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0007
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 9887.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17420.0000
 PER:
  * precision: 0.0713
  * recall: 0.1658
  * f1-score: 0.0997
  * support: 15204.0000
 micro avg:
  * precision: 0.0685
  * recall: 0.0593
  * f1-score: 0.0636
  * support: 42511.0000
 macro avg:
  * precision: 0.0240
  * recall: 0.0553
  * f1-score: 0.0333
  * support: 42511.0000
 weighted avg:
  * precision: 0.0257
  * recall: 0.0593
  * f1-score: 0.0357
  * support: 42511.0000
 accuracy:
  * 0.5467
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8604
 * Micro Average: f1: 0.7567, precision: 0.7541, recall: 0.7592
 * Macro Average: f1: 0.7562, precision: 0.7514, recall: 0.7614

Epoch 2/4, accuracy: 0.8762
 * Micro Average: f1: 0.7836, precision: 0.7850, recall: 0.7822
 * Macro Average: f1: 0.7855, precision: 0.7818, recall: 0.7908

Epoch 3/4, accuracy: 0.8829
 * Micro Average: f1: 0.7970, precision: 0.7922, recall: 0.8018
 * Macro Average: f1: 0.7985, precision: 0.7917, recall: 0.8055

Epoch 4/4, accuracy: 0.8849
 * Micro Average: f1: 0.8005, precision: 0.7955, recall: 0.8056
 * Macro Average: f1: 0.8024, precision: 0.7959, recall: 0.8091

 time for training and evaluating:144.26877808570862 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7909
  * recall: 0.7448
  * f1-score: 0.7671
  * support: 9875.0000
 ORG:
  * precision: 0.6147
  * recall: 0.7419
  * f1-score: 0.6724
  * support: 17425.0000
 PER:
  * precision: 0.6388
  * recall: 0.8121
  * f1-score: 0.7151
  * support: 15200.0000
 micro avg:
  * precision: 0.6571
  * recall: 0.7677
  * f1-score: 0.7081
  * support: 42500.0000
 macro avg:
  * precision: 0.6815
  * recall: 0.7663
  * f1-score: 0.7182
  * support: 42500.0000
 weighted avg:
  * precision: 0.6643
  * recall: 0.7677
  * f1-score: 0.7097
  * support: 42500.0000
 accuracy:
  * 0.8577
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1478
 * Micro Average: f1: 0.0033, precision: 0.0079, recall: 0.0021
 * Macro Average: f1: 0.0028, precision: 0.0026, recall: 0.0030

Epoch 2/4, accuracy: 0.4742
 * Micro Average: f1: 0.0291, precision: 0.1028, recall: 0.0170
 * Macro Average: f1: 0.0287, precision: 0.0343, recall: 0.0246

Epoch 3/4, accuracy: 0.4835
 * Micro Average: f1: 0.0034, precision: 0.1122, recall: 0.0017
 * Macro Average: f1: 0.0047, precision: 0.0374, recall: 0.0025

Epoch 4/4, accuracy: 0.4836
 * Micro Average: f1: 0.0021, precision: 0.1419, recall: 0.0011
 * Macro Average: f1: 0.0029, precision: 0.0473, recall: 0.0015

 time for training and evaluating:57.74527597427368 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0955
  * recall: 0.0058
  * f1-score: 0.0109
  * support: 9857.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17402.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15197.0000
 micro avg:
  * precision: 0.0955
  * recall: 0.0013
  * f1-score: 0.0026
  * support: 42456.0000
 macro avg:
  * precision: 0.0318
  * recall: 0.0019
  * f1-score: 0.0036
  * support: 42456.0000
 weighted avg:
  * precision: 0.0222
  * recall: 0.0013
  * f1-score: 0.0025
  * support: 42456.0000
 accuracy:
  * 0.6532
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7732
 * Micro Average: f1: 0.6035, precision: 0.5775, recall: 0.6319
 * Macro Average: f1: 0.6013, precision: 0.5734, recall: 0.6325

Epoch 2/4, accuracy: 0.8286
 * Micro Average: f1: 0.6990, precision: 0.7030, recall: 0.6950
 * Macro Average: f1: 0.6982, precision: 0.6978, recall: 0.7014

Epoch 3/4, accuracy: 0.8417
 * Micro Average: f1: 0.7259, precision: 0.7233, recall: 0.7286
 * Macro Average: f1: 0.7261, precision: 0.7185, recall: 0.7362

Epoch 4/4, accuracy: 0.8446
 * Micro Average: f1: 0.7310, precision: 0.7299, recall: 0.7320
 * Macro Average: f1: 0.7311, precision: 0.7259, recall: 0.7388

 time for training and evaluating:143.8142569065094 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6848
  * recall: 0.7407
  * f1-score: 0.7117
  * support: 9873.0000
 ORG:
  * precision: 0.6080
  * recall: 0.6766
  * f1-score: 0.6405
  * support: 17441.0000
 PER:
  * precision: 0.5653
  * recall: 0.7622
  * f1-score: 0.6492
  * support: 15209.0000
 micro avg:
  * precision: 0.6069
  * recall: 0.7221
  * f1-score: 0.6595
  * support: 42523.0000
 macro avg:
  * precision: 0.6194
  * recall: 0.7265
  * f1-score: 0.6671
  * support: 42523.0000
 weighted avg:
  * precision: 0.6106
  * recall: 0.7221
  * f1-score: 0.6601
  * support: 42523.0000
 accuracy:
  * 0.8430
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1060
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.1054
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.1059
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.1056
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:57.17368745803833 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9884.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17431.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15213.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42528.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42528.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42528.0000
 accuracy:
  * 0.0812
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7663
 * Micro Average: f1: 0.5988, precision: 0.5684, recall: 0.6327
 * Macro Average: f1: 0.5968, precision: 0.5674, recall: 0.6298

Epoch 2/4, accuracy: 0.8292
 * Micro Average: f1: 0.7030, precision: 0.6992, recall: 0.7067
 * Macro Average: f1: 0.7038, precision: 0.6946, recall: 0.7160

Epoch 3/4, accuracy: 0.8434
 * Micro Average: f1: 0.7251, precision: 0.7275, recall: 0.7228
 * Macro Average: f1: 0.7256, precision: 0.7228, recall: 0.7315

Epoch 4/4, accuracy: 0.8461
 * Micro Average: f1: 0.7320, precision: 0.7321, recall: 0.7318
 * Macro Average: f1: 0.7324, precision: 0.7277, recall: 0.7399

 time for training and evaluating:143.53141474723816 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6950
  * recall: 0.7501
  * f1-score: 0.7215
  * support: 9874.0000
 ORG:
  * precision: 0.6044
  * recall: 0.6835
  * f1-score: 0.6415
  * support: 17417.0000
 PER:
  * precision: 0.5761
  * recall: 0.7512
  * f1-score: 0.6521
  * support: 15180.0000
 micro avg:
  * precision: 0.6125
  * recall: 0.7232
  * f1-score: 0.6633
  * support: 42471.0000
 macro avg:
  * precision: 0.6252
  * recall: 0.7283
  * f1-score: 0.6717
  * support: 42471.0000
 weighted avg:
  * precision: 0.6154
  * recall: 0.7232
  * f1-score: 0.6639
  * support: 42471.0000
 accuracy:
  * 0.8428
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0585
 * Micro Average: f1: 0.1000, precision: 0.0688, recall: 0.1834
 * Macro Average: f1: 0.0422, precision: 0.0229, recall: 0.2643

Epoch 2/4, accuracy: 0.0582
 * Micro Average: f1: 0.0996, precision: 0.0685, recall: 0.1822
 * Macro Average: f1: 0.0420, precision: 0.0228, recall: 0.2638

Epoch 3/4, accuracy: 0.0630
 * Micro Average: f1: 0.0995, precision: 0.0686, recall: 0.1811
 * Macro Average: f1: 0.0420, precision: 0.0229, recall: 0.2619

Epoch 4/4, accuracy: 0.0701
 * Micro Average: f1: 0.0987, precision: 0.0682, recall: 0.1780
 * Macro Average: f1: 0.0418, precision: 0.0227, recall: 0.2567

 time for training and evaluating:58.32730174064636 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0503
  * recall: 0.8741
  * f1-score: 0.0951
  * support: 9869.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17454.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15179.0000
 micro avg:
  * precision: 0.0503
  * recall: 0.2030
  * f1-score: 0.0806
  * support: 42502.0000
 macro avg:
  * precision: 0.0168
  * recall: 0.2914
  * f1-score: 0.0317
  * support: 42502.0000
 weighted avg:
  * precision: 0.0117
  * recall: 0.2030
  * f1-score: 0.0221
  * support: 42502.0000
 accuracy:
  * 0.0561
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4832
 * Micro Average: f1: 0.0073, precision: 0.1337, recall: 0.0037
 * Macro Average: f1: 0.0057, precision: 0.2468, recall: 0.0030

Epoch 2/4, accuracy: 0.4829
 * Micro Average: f1: 0.0008, precision: 0.1067, recall: 0.0004
 * Macro Average: f1: 0.0007, precision: 0.2525, recall: 0.0003

Epoch 3/4, accuracy: 0.4828
 * Micro Average: f1: 0.0005, precision: 0.1471, recall: 0.0002
 * Macro Average: f1: 0.0004, precision: 0.3678, recall: 0.0002

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0004, precision: 0.1818, recall: 0.0002
 * Macro Average: f1: 0.0003, precision: 0.3833, recall: 0.0002

 time for training and evaluating:143.8719940185547 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9877.0000
 ORG:
  * precision: 0.5000
  * recall: 0.0001
  * f1-score: 0.0001
  * support: 17406.0000
 PER:
  * precision: 0.0484
  * recall: 0.0004
  * f1-score: 0.0008
  * support: 15184.0000
 micro avg:
  * precision: 0.0538
  * recall: 0.0002
  * f1-score: 0.0003
  * support: 42467.0000
 macro avg:
  * precision: 0.1828
  * recall: 0.0002
  * f1-score: 0.0003
  * support: 42467.0000
 weighted avg:
  * precision: 0.2222
  * recall: 0.0002
  * f1-score: 0.0003
  * support: 42467.0000
 accuracy:
  * 0.6543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4710
 * Micro Average: f1: 0.0066, precision: 0.0590, recall: 0.0035
 * Macro Average: f1: 0.0068, precision: 0.0824, recall: 0.0036

Epoch 2/4, accuracy: 0.4824
 * Micro Average: f1: 0.0003, precision: 0.0476, recall: 0.0002
 * Macro Average: f1: 0.0003, precision: 0.0423, recall: 0.0001

Epoch 3/4, accuracy: 0.4832
 * Micro Average: f1: 0.0002, precision: 0.0952, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.0513, recall: 0.0001

Epoch 4/4, accuracy: 0.4834
 * Micro Average: f1: 0.0002, precision: 0.1053, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.0606, recall: 0.0001

 time for training and evaluating:57.511213302612305 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9867.0000
 ORG:
  * precision: 0.2857
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 17410.0000
 PER:
  * precision: 0.0260
  * recall: 0.0001
  * f1-score: 0.0003
  * support: 15212.0000
 micro avg:
  * precision: 0.0440
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 42489.0000
 macro avg:
  * precision: 0.1039
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 42489.0000
 weighted avg:
  * precision: 0.1264
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 42489.0000
 accuracy:
  * 0.6539
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4840
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4837
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:143.69630455970764 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9863.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17436.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15189.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42488.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42488.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42488.0000
 accuracy:
  * 0.6544
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-de.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1057
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.1059
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.1061
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.1058
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:57.726637840270996 for train language combination:train-en.tsv.gz and test language: dev-de.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 9858.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 17437.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 15226.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42521.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42521.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 42521.0000
 accuracy:
  * 0.0813
________________________________________


Map:   0%|          | 0/7270 [00:00<?, ? examples/s]Map:  14%|█▍        | 1000/7270 [00:00<00:00, 7007.78 examples/s]Map:  28%|██▊       | 2000/7270 [00:00<00:00, 6958.59 examples/s]Map:  41%|████▏     | 3000/7270 [00:00<00:00, 7125.73 examples/s]Map:  55%|█████▌    | 4000/7270 [00:00<00:00, 7012.61 examples/s]Map:  69%|██████▉   | 5000/7270 [00:00<00:00, 7235.32 examples/s]Map:  83%|████████▎ | 6000/7270 [00:00<00:00, 7327.32 examples/s]Map:  96%|█████████▋| 7000/7270 [00:00<00:00, 7424.80 examples/s]Map: 100%|██████████| 7270/7270 [00:01<00:00, 7247.84 examples/s]
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8742
 * Micro Average: f1: 0.7802, precision: 0.7809, recall: 0.7795
 * Macro Average: f1: 0.7806, precision: 0.7770, recall: 0.7856

Epoch 2/4, accuracy: 0.8854
 * Micro Average: f1: 0.7994, precision: 0.7994, recall: 0.7994
 * Macro Average: f1: 0.8009, precision: 0.7987, recall: 0.8034

Epoch 3/4, accuracy: 0.8931
 * Micro Average: f1: 0.8157, precision: 0.8128, recall: 0.8185
 * Macro Average: f1: 0.8168, precision: 0.8128, recall: 0.8208

Epoch 4/4, accuracy: 0.8935
 * Micro Average: f1: 0.8147, precision: 0.8114, recall: 0.8179
 * Macro Average: f1: 0.8157, precision: 0.8100, recall: 0.8218

 time for training and evaluating:210.78778338432312 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7739
  * recall: 0.8341
  * f1-score: 0.8029
  * support: 10140.0000
 ORG:
  * precision: 0.7324
  * recall: 0.7380
  * f1-score: 0.7352
  * support: 14476.0000
 PER:
  * precision: 0.7651
  * recall: 0.8125
  * f1-score: 0.7880
  * support: 18955.0000
 micro avg:
  * precision: 0.7567
  * recall: 0.7928
  * f1-score: 0.7743
  * support: 43571.0000
 macro avg:
  * precision: 0.7571
  * recall: 0.7949
  * f1-score: 0.7754
  * support: 43571.0000
 weighted avg:
  * precision: 0.7563
  * recall: 0.7928
  * f1-score: 0.7739
  * support: 43571.0000
 accuracy:
  * 0.8686
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.3386
 * Micro Average: f1: 0.1013, precision: 0.0882, recall: 0.1189
 * Macro Average: f1: 0.0521, precision: 0.1579, recall: 0.1705

Epoch 2/4, accuracy: 0.4829
 * Micro Average: f1: 0.0001, precision: 0.3333, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.1111, recall: 0.0001

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4837
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.91893124580383 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10127.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14474.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18936.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43537.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43537.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43537.0000
 accuracy:
  * 0.5435
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8761
 * Micro Average: f1: 0.7863, precision: 0.7895, recall: 0.7832
 * Macro Average: f1: 0.7879, precision: 0.7883, recall: 0.7879

Epoch 2/4, accuracy: 0.8886
 * Micro Average: f1: 0.8076, precision: 0.8062, recall: 0.8091
 * Macro Average: f1: 0.8090, precision: 0.8080, recall: 0.8100

Epoch 3/4, accuracy: 0.8934
 * Micro Average: f1: 0.8158, precision: 0.8125, recall: 0.8192
 * Macro Average: f1: 0.8176, precision: 0.8133, recall: 0.8223

Epoch 4/4, accuracy: 0.8955
 * Micro Average: f1: 0.8189, precision: 0.8152, recall: 0.8226
 * Macro Average: f1: 0.8204, precision: 0.8144, recall: 0.8268

 time for training and evaluating:212.85673570632935 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7768
  * recall: 0.8277
  * f1-score: 0.8014
  * support: 10128.0000
 ORG:
  * precision: 0.7289
  * recall: 0.7257
  * f1-score: 0.7273
  * support: 14462.0000
 PER:
  * precision: 0.7509
  * recall: 0.8091
  * f1-score: 0.7789
  * support: 18943.0000
 micro avg:
  * precision: 0.7501
  * recall: 0.7857
  * f1-score: 0.7675
  * support: 43533.0000
 macro avg:
  * precision: 0.7522
  * recall: 0.7875
  * f1-score: 0.7692
  * support: 43533.0000
 weighted avg:
  * precision: 0.7496
  * recall: 0.7857
  * f1-score: 0.7670
  * support: 43533.0000
 accuracy:
  * 0.8626
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4827
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.31280040740967 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10127.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14461.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18933.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43521.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43521.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43521.0000
 accuracy:
  * 0.5434
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8247
 * Micro Average: f1: 0.6941, precision: 0.6789, recall: 0.7100
 * Macro Average: f1: 0.6935, precision: 0.6764, recall: 0.7136

Epoch 2/4, accuracy: 0.8477
 * Micro Average: f1: 0.7336, precision: 0.7373, recall: 0.7300
 * Macro Average: f1: 0.7336, precision: 0.7313, recall: 0.7404

Epoch 3/4, accuracy: 0.8614
 * Micro Average: f1: 0.7604, precision: 0.7603, recall: 0.7606
 * Macro Average: f1: 0.7612, precision: 0.7563, recall: 0.7682

Epoch 4/4, accuracy: 0.8633
 * Micro Average: f1: 0.7656, precision: 0.7641, recall: 0.7670
 * Macro Average: f1: 0.7667, precision: 0.7609, recall: 0.7740

 time for training and evaluating:213.35364723205566 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6957
  * recall: 0.8294
  * f1-score: 0.7567
  * support: 10145.0000
 ORG:
  * precision: 0.7037
  * recall: 0.6836
  * f1-score: 0.6935
  * support: 14471.0000
 PER:
  * precision: 0.7620
  * recall: 0.7571
  * f1-score: 0.7596
  * support: 18943.0000
 micro avg:
  * precision: 0.7260
  * recall: 0.7495
  * f1-score: 0.7376
  * support: 43559.0000
 macro avg:
  * precision: 0.7205
  * recall: 0.7567
  * f1-score: 0.7366
  * support: 43559.0000
 weighted avg:
  * precision: 0.7272
  * recall: 0.7495
  * f1-score: 0.7369
  * support: 43559.0000
 accuracy:
  * 0.8469
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4822
 * Micro Average: f1: 0.0020, precision: 0.1170, recall: 0.0010
 * Macro Average: f1: 0.0019, precision: 0.1318, recall: 0.0010

Epoch 2/4, accuracy: 0.4834
 * Micro Average: f1: 0.0001, precision: 1.0000, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.3333, recall: 0.0000

Epoch 3/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:64.12422156333923 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10134.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14471.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18951.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43556.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43556.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43556.0000
 accuracy:
  * 0.5433
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8189
 * Micro Average: f1: 0.6800, precision: 0.6894, recall: 0.6707
 * Macro Average: f1: 0.6778, precision: 0.6837, recall: 0.6777

Epoch 2/4, accuracy: 0.8522
 * Micro Average: f1: 0.7442, precision: 0.7440, recall: 0.7445
 * Macro Average: f1: 0.7453, precision: 0.7424, recall: 0.7490

Epoch 3/4, accuracy: 0.8588
 * Micro Average: f1: 0.7575, precision: 0.7568, recall: 0.7582
 * Macro Average: f1: 0.7585, precision: 0.7546, recall: 0.7637

Epoch 4/4, accuracy: 0.8637
 * Micro Average: f1: 0.7643, precision: 0.7623, recall: 0.7663
 * Macro Average: f1: 0.7648, precision: 0.7585, recall: 0.7726

 time for training and evaluating:212.70875763893127 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6893
  * recall: 0.8292
  * f1-score: 0.7528
  * support: 10132.0000
 ORG:
  * precision: 0.7161
  * recall: 0.6865
  * f1-score: 0.7010
  * support: 14468.0000
 PER:
  * precision: 0.7608
  * recall: 0.7608
  * f1-score: 0.7608
  * support: 18931.0000
 micro avg:
  * precision: 0.7276
  * recall: 0.7520
  * f1-score: 0.7396
  * support: 43531.0000
 macro avg:
  * precision: 0.7221
  * recall: 0.7588
  * f1-score: 0.7382
  * support: 43531.0000
 weighted avg:
  * precision: 0.7293
  * recall: 0.7520
  * f1-score: 0.7391
  * support: 43531.0000
 accuracy:
  * 0.8479
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0804
 * Micro Average: f1: 0.0021, precision: 0.0152, recall: 0.0011
 * Macro Average: f1: 0.0019, precision: 0.0999, recall: 0.0012

Epoch 2/4, accuracy: 0.4600
 * Micro Average: f1: 0.0240, precision: 0.0931, recall: 0.0138
 * Macro Average: f1: 0.0195, precision: 0.0311, recall: 0.0142

Epoch 3/4, accuracy: 0.4835
 * Micro Average: f1: 0.0028, precision: 0.2523, recall: 0.0014
 * Macro Average: f1: 0.0028, precision: 0.0841, recall: 0.0014

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0013, precision: 0.3171, recall: 0.0006
 * Macro Average: f1: 0.0013, precision: 0.1057, recall: 0.0007

 time for training and evaluating:63.30834746360779 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10139.0000
 ORG:
  * precision: 0.1250
  * recall: 0.0013
  * f1-score: 0.0026
  * support: 14467.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18930.0000
 micro avg:
  * precision: 0.1226
  * recall: 0.0004
  * f1-score: 0.0009
  * support: 43536.0000
 macro avg:
  * precision: 0.0417
  * recall: 0.0004
  * f1-score: 0.0009
  * support: 43536.0000
 weighted avg:
  * precision: 0.0415
  * recall: 0.0004
  * f1-score: 0.0009
  * support: 43536.0000
 accuracy:
  * 0.5430
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:212.5236213207245 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10133.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14453.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18937.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43523.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43523.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43523.0000
 accuracy:
  * 0.5434
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4825
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.03486156463623 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10139.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14460.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18941.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43540.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43540.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43540.0000
 accuracy:
  * 0.5434
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:212.0788905620575 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10127.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14466.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18954.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43547.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43547.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43547.0000
 accuracy:
  * 0.5434
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1299
 * Micro Average: f1: 0.1983, precision: 0.1366, recall: 0.3617
 * Macro Average: f1: 0.0780, precision: 0.3789, recall: 0.2702

Epoch 2/4, accuracy: 0.2242
 * Micro Average: f1: 0.1407, precision: 0.1150, recall: 0.1811
 * Macro Average: f1: 0.0597, precision: 0.0383, recall: 0.1353

Epoch 3/4, accuracy: 0.4205
 * Micro Average: f1: 0.0377, precision: 0.0847, recall: 0.0242
 * Macro Average: f1: 0.0221, precision: 0.0282, recall: 0.0181

Epoch 4/4, accuracy: 0.4537
 * Micro Average: f1: 0.0099, precision: 0.0506, recall: 0.0055
 * Macro Average: f1: 0.0066, precision: 0.0169, recall: 0.0041

 time for training and evaluating:64.39613676071167 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10140.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14464.0000
 PER:
  * precision: 0.1148
  * recall: 0.0334
  * f1-score: 0.0517
  * support: 18946.0000
 micro avg:
  * precision: 0.1148
  * recall: 0.0145
  * f1-score: 0.0258
  * support: 43550.0000
 macro avg:
  * precision: 0.0383
  * recall: 0.0111
  * f1-score: 0.0172
  * support: 43550.0000
 weighted avg:
  * precision: 0.0499
  * recall: 0.0145
  * f1-score: 0.0225
  * support: 43550.0000
 accuracy:
  * 0.5177
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8694
 * Micro Average: f1: 0.7717, precision: 0.7725, recall: 0.7709
 * Macro Average: f1: 0.7726, precision: 0.7689, recall: 0.7776

Epoch 2/4, accuracy: 0.8830
 * Micro Average: f1: 0.7984, precision: 0.7909, recall: 0.8060
 * Macro Average: f1: 0.7995, precision: 0.7922, recall: 0.8075

Epoch 3/4, accuracy: 0.8893
 * Micro Average: f1: 0.8094, precision: 0.8032, recall: 0.8157
 * Macro Average: f1: 0.8118, precision: 0.8038, recall: 0.8202

Epoch 4/4, accuracy: 0.8897
 * Micro Average: f1: 0.8108, precision: 0.8062, recall: 0.8154
 * Macro Average: f1: 0.8127, precision: 0.8071, recall: 0.8185

 time for training and evaluating:170.2447738647461 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7731
  * recall: 0.8243
  * f1-score: 0.7979
  * support: 10145.0000
 ORG:
  * precision: 0.7313
  * recall: 0.7253
  * f1-score: 0.7283
  * support: 14461.0000
 PER:
  * precision: 0.7576
  * recall: 0.8127
  * f1-score: 0.7842
  * support: 18935.0000
 micro avg:
  * precision: 0.7530
  * recall: 0.7864
  * f1-score: 0.7693
  * support: 43541.0000
 macro avg:
  * precision: 0.7540
  * recall: 0.7874
  * f1-score: 0.7701
  * support: 43541.0000
 weighted avg:
  * precision: 0.7525
  * recall: 0.7864
  * f1-score: 0.7688
  * support: 43541.0000
 accuracy:
  * 0.8647
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4695
 * Micro Average: f1: 0.0091, precision: 0.0523, recall: 0.0050
 * Macro Average: f1: 0.0102, precision: 0.0174, recall: 0.0072

Epoch 2/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4824
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4837
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:59.849207639694214 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10130.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14450.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18940.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43520.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43520.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43520.0000
 accuracy:
  * 0.5434
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8700
 * Micro Average: f1: 0.7742, precision: 0.7672, recall: 0.7813
 * Macro Average: f1: 0.7751, precision: 0.7696, recall: 0.7807

Epoch 2/4, accuracy: 0.8831
 * Micro Average: f1: 0.7979, precision: 0.7909, recall: 0.8050
 * Macro Average: f1: 0.7992, precision: 0.7915, recall: 0.8071

Epoch 3/4, accuracy: 0.8880
 * Micro Average: f1: 0.8046, precision: 0.8035, recall: 0.8056
 * Macro Average: f1: 0.8054, precision: 0.8012, recall: 0.8102

Epoch 4/4, accuracy: 0.8920
 * Micro Average: f1: 0.8119, precision: 0.8085, recall: 0.8153
 * Macro Average: f1: 0.8131, precision: 0.8077, recall: 0.8188

 time for training and evaluating:170.00946950912476 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7618
  * recall: 0.8262
  * f1-score: 0.7927
  * support: 10121.0000
 ORG:
  * precision: 0.7203
  * recall: 0.7300
  * f1-score: 0.7251
  * support: 14461.0000
 PER:
  * precision: 0.7506
  * recall: 0.8089
  * f1-score: 0.7787
  * support: 18920.0000
 micro avg:
  * precision: 0.7437
  * recall: 0.7867
  * f1-score: 0.7646
  * support: 43502.0000
 macro avg:
  * precision: 0.7443
  * recall: 0.7883
  * f1-score: 0.7655
  * support: 43502.0000
 weighted avg:
  * precision: 0.7432
  * recall: 0.7867
  * f1-score: 0.7641
  * support: 43502.0000
 accuracy:
  * 0.8608
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1133
 * Micro Average: f1: 0.1548, precision: 0.1073, recall: 0.2776
 * Macro Average: f1: 0.1192, precision: 0.1642, recall: 0.2755

Epoch 2/4, accuracy: 0.1599
 * Micro Average: f1: 0.1713, precision: 0.1220, recall: 0.2878
 * Macro Average: f1: 0.1141, precision: 0.0741, recall: 0.2514

Epoch 3/4, accuracy: 0.3207
 * Micro Average: f1: 0.1948, precision: 0.1497, recall: 0.2788
 * Macro Average: f1: 0.1186, precision: 0.0808, recall: 0.2291

Epoch 4/4, accuracy: 0.3624
 * Micro Average: f1: 0.2019, precision: 0.1598, recall: 0.2740
 * Macro Average: f1: 0.1185, precision: 0.0832, recall: 0.2205

 time for training and evaluating:59.635504722595215 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0757
  * recall: 0.1289
  * f1-score: 0.0954
  * support: 10137.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14466.0000
 PER:
  * precision: 0.1447
  * recall: 0.5321
  * f1-score: 0.2276
  * support: 18936.0000
 micro avg:
  * precision: 0.1310
  * recall: 0.2614
  * f1-score: 0.1745
  * support: 43539.0000
 macro avg:
  * precision: 0.0735
  * recall: 0.2203
  * f1-score: 0.1076
  * support: 43539.0000
 weighted avg:
  * precision: 0.0806
  * recall: 0.2614
  * f1-score: 0.1212
  * support: 43539.0000
 accuracy:
  * 0.3325
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8006
 * Micro Average: f1: 0.6569, precision: 0.6356, recall: 0.6796
 * Macro Average: f1: 0.6539, precision: 0.6317, recall: 0.6802

Epoch 2/4, accuracy: 0.8411
 * Micro Average: f1: 0.7204, precision: 0.7225, recall: 0.7183
 * Macro Average: f1: 0.7192, precision: 0.7176, recall: 0.7251

Epoch 3/4, accuracy: 0.8519
 * Micro Average: f1: 0.7442, precision: 0.7433, recall: 0.7452
 * Macro Average: f1: 0.7449, precision: 0.7399, recall: 0.7526

Epoch 4/4, accuracy: 0.8559
 * Micro Average: f1: 0.7525, precision: 0.7514, recall: 0.7536
 * Macro Average: f1: 0.7532, precision: 0.7479, recall: 0.7609

 time for training and evaluating:169.02186155319214 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6837
  * recall: 0.8314
  * f1-score: 0.7504
  * support: 10121.0000
 ORG:
  * precision: 0.7225
  * recall: 0.6669
  * f1-score: 0.6935
  * support: 14462.0000
 PER:
  * precision: 0.7581
  * recall: 0.7615
  * f1-score: 0.7598
  * support: 18944.0000
 micro avg:
  * precision: 0.7270
  * recall: 0.7463
  * f1-score: 0.7365
  * support: 43527.0000
 macro avg:
  * precision: 0.7214
  * recall: 0.7533
  * f1-score: 0.7346
  * support: 43527.0000
 weighted avg:
  * precision: 0.7290
  * recall: 0.7463
  * f1-score: 0.7356
  * support: 43527.0000
 accuracy:
  * 0.8464
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4688
 * Micro Average: f1: 0.0134, precision: 0.0645, recall: 0.0074
 * Macro Average: f1: 0.0144, precision: 0.1047, recall: 0.0107

Epoch 2/4, accuracy: 0.4831
 * Micro Average: f1: 0.0001, precision: 0.5000, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.1667, recall: 0.0001

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:59.0671648979187 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.1000
  * recall: 0.0001
  * f1-score: 0.0002
  * support: 10141.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14459.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18942.0000
 micro avg:
  * precision: 0.0769
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43542.0000
 macro avg:
  * precision: 0.0333
  * recall: 0.0000
  * f1-score: 0.0001
  * support: 43542.0000
 weighted avg:
  * precision: 0.0233
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43542.0000
 accuracy:
  * 0.5434
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8119
 * Micro Average: f1: 0.6775, precision: 0.6581, recall: 0.6980
 * Macro Average: f1: 0.6762, precision: 0.6548, recall: 0.7005

Epoch 2/4, accuracy: 0.8457
 * Micro Average: f1: 0.7318, precision: 0.7277, recall: 0.7359
 * Macro Average: f1: 0.7321, precision: 0.7246, recall: 0.7412

Epoch 3/4, accuracy: 0.8520
 * Micro Average: f1: 0.7446, precision: 0.7430, recall: 0.7462
 * Macro Average: f1: 0.7447, precision: 0.7402, recall: 0.7507

Epoch 4/4, accuracy: 0.8555
 * Micro Average: f1: 0.7515, precision: 0.7506, recall: 0.7525
 * Macro Average: f1: 0.7529, precision: 0.7478, recall: 0.7596

 time for training and evaluating:170.0569453239441 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6833
  * recall: 0.8275
  * f1-score: 0.7485
  * support: 10136.0000
 ORG:
  * precision: 0.7117
  * recall: 0.6739
  * f1-score: 0.6923
  * support: 14464.0000
 PER:
  * precision: 0.7532
  * recall: 0.7448
  * f1-score: 0.7490
  * support: 18939.0000
 micro avg:
  * precision: 0.7213
  * recall: 0.7405
  * f1-score: 0.7308
  * support: 43539.0000
 macro avg:
  * precision: 0.7160
  * recall: 0.7488
  * f1-score: 0.7299
  * support: 43539.0000
 weighted avg:
  * precision: 0.7231
  * recall: 0.7405
  * f1-score: 0.7300
  * support: 43539.0000
 accuracy:
  * 0.8402
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:59.59762954711914 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10136.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14462.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18946.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43544.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43544.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43544.0000
 accuracy:
  * 0.5435
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4826
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:169.94883847236633 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10144.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14429.0000
 PER:
  * precision: 1.0000
  * recall: 0.0001
  * f1-score: 0.0001
  * support: 18955.0000
 micro avg:
  * precision: 1.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43528.0000
 macro avg:
  * precision: 0.3333
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43528.0000
 weighted avg:
  * precision: 0.4355
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43528.0000
 accuracy:
  * 0.5434
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.2446
 * Micro Average: f1: 0.1053, precision: 0.0906, recall: 0.1259
 * Macro Average: f1: 0.0490, precision: 0.0302, recall: 0.1301

Epoch 2/4, accuracy: 0.4794
 * Micro Average: f1: 0.0042, precision: 0.1014, recall: 0.0021
 * Macro Average: f1: 0.0042, precision: 0.0338, recall: 0.0022

Epoch 3/4, accuracy: 0.4835
 * Micro Average: f1: 0.0002, precision: 0.1667, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.0556, recall: 0.0001

Epoch 4/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:60.21332931518555 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10133.0000
 ORG:
  * precision: 0.0357
  * recall: 0.0001
  * f1-score: 0.0001
  * support: 14465.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18954.0000
 micro avg:
  * precision: 0.0357
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43552.0000
 macro avg:
  * precision: 0.0119
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43552.0000
 weighted avg:
  * precision: 0.0119
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43552.0000
 accuracy:
  * 0.5433
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.3958
 * Micro Average: f1: 0.0741, precision: 0.0974, recall: 0.0598
 * Macro Average: f1: 0.0440, precision: 0.0677, recall: 0.0613

Epoch 2/4, accuracy: 0.4842
 * Micro Average: f1: 0.0172, precision: 0.2257, recall: 0.0090
 * Macro Average: f1: 0.0165, precision: 0.2417, recall: 0.0093

Epoch 3/4, accuracy: 0.4836
 * Micro Average: f1: 0.0039, precision: 0.2108, recall: 0.0020
 * Macro Average: f1: 0.0039, precision: 0.0707, recall: 0.0020

Epoch 4/4, accuracy: 0.4834
 * Micro Average: f1: 0.0022, precision: 0.2391, recall: 0.0011
 * Macro Average: f1: 0.0022, precision: 0.0797, recall: 0.0011

 time for training and evaluating:169.79505896568298 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10131.0000
 ORG:
  * precision: 0.1106
  * recall: 0.0015
  * f1-score: 0.0030
  * support: 14470.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18940.0000
 micro avg:
  * precision: 0.1100
  * recall: 0.0005
  * f1-score: 0.0010
  * support: 43541.0000
 macro avg:
  * precision: 0.0369
  * recall: 0.0005
  * f1-score: 0.0010
  * support: 43541.0000
 weighted avg:
  * precision: 0.0367
  * recall: 0.0005
  * f1-score: 0.0010
  * support: 43541.0000
 accuracy:
  * 0.5431
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1292
 * Micro Average: f1: 0.1977, precision: 0.1360, recall: 0.3624
 * Macro Average: f1: 0.0777, precision: 0.0453, recall: 0.2712

Epoch 2/4, accuracy: 0.1295
 * Micro Average: f1: 0.1967, precision: 0.1357, recall: 0.3572
 * Macro Average: f1: 0.0774, precision: 0.0452, recall: 0.2669

Epoch 3/4, accuracy: 0.1366
 * Micro Average: f1: 0.1875, precision: 0.1326, recall: 0.3198
 * Macro Average: f1: 0.0746, precision: 0.0442, recall: 0.2389

Epoch 4/4, accuracy: 0.1460
 * Micro Average: f1: 0.1780, precision: 0.1289, recall: 0.2874
 * Macro Average: f1: 0.0716, precision: 0.0430, recall: 0.2154

 time for training and evaluating:61.174094915390015 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10138.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14448.0000
 PER:
  * precision: 0.1104
  * recall: 0.6724
  * f1-score: 0.1897
  * support: 18940.0000
 micro avg:
  * precision: 0.1104
  * recall: 0.2926
  * f1-score: 0.1604
  * support: 43526.0000
 macro avg:
  * precision: 0.0368
  * recall: 0.2241
  * f1-score: 0.0632
  * support: 43526.0000
 weighted avg:
  * precision: 0.0481
  * recall: 0.2926
  * f1-score: 0.0826
  * support: 43526.0000
 accuracy:
  * 0.1240
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8603
 * Micro Average: f1: 0.7555, precision: 0.7534, recall: 0.7577
 * Macro Average: f1: 0.7549, precision: 0.7485, recall: 0.7627

Epoch 2/4, accuracy: 0.8764
 * Micro Average: f1: 0.7845, precision: 0.7804, recall: 0.7887
 * Macro Average: f1: 0.7848, precision: 0.7769, recall: 0.7939

Epoch 3/4, accuracy: 0.8838
 * Micro Average: f1: 0.7990, precision: 0.7952, recall: 0.8028
 * Macro Average: f1: 0.7999, precision: 0.7954, recall: 0.8046

Epoch 4/4, accuracy: 0.8854
 * Micro Average: f1: 0.8016, precision: 0.7983, recall: 0.8049
 * Macro Average: f1: 0.8022, precision: 0.7966, recall: 0.8081

 time for training and evaluating:143.97989797592163 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7543
  * recall: 0.8288
  * f1-score: 0.7898
  * support: 10083.0000
 ORG:
  * precision: 0.7300
  * recall: 0.7171
  * f1-score: 0.7235
  * support: 14421.0000
 PER:
  * precision: 0.7547
  * recall: 0.8085
  * f1-score: 0.7806
  * support: 18894.0000
 micro avg:
  * precision: 0.7469
  * recall: 0.7828
  * f1-score: 0.7644
  * support: 43398.0000
 macro avg:
  * precision: 0.7463
  * recall: 0.7848
  * f1-score: 0.7646
  * support: 43398.0000
 weighted avg:
  * precision: 0.7464
  * recall: 0.7828
  * f1-score: 0.7638
  * support: 43398.0000
 accuracy:
  * 0.8612
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1009
 * Micro Average: f1: 0.0120, precision: 0.0330, recall: 0.0073
 * Macro Average: f1: 0.0142, precision: 0.0498, recall: 0.0095

Epoch 2/4, accuracy: 0.1050
 * Micro Average: f1: 0.0097, precision: 0.0291, recall: 0.0058
 * Macro Average: f1: 0.0113, precision: 0.0526, recall: 0.0070

Epoch 3/4, accuracy: 0.1358
 * Micro Average: f1: 0.0111, precision: 0.0299, recall: 0.0068
 * Macro Average: f1: 0.0122, precision: 0.0644, recall: 0.0073

Epoch 4/4, accuracy: 0.1684
 * Micro Average: f1: 0.0143, precision: 0.0342, recall: 0.0090
 * Macro Average: f1: 0.0140, precision: 0.0744, recall: 0.0088

 time for training and evaluating:57.34601855278015 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.1057
  * recall: 0.0168
  * f1-score: 0.0290
  * support: 10107.0000
 ORG:
  * precision: 0.0994
  * recall: 0.0022
  * f1-score: 0.0043
  * support: 14407.0000
 PER:
  * precision: 0.0181
  * recall: 0.0091
  * f1-score: 0.0121
  * support: 18858.0000
 micro avg:
  * precision: 0.0328
  * recall: 0.0086
  * f1-score: 0.0137
  * support: 43372.0000
 macro avg:
  * precision: 0.0744
  * recall: 0.0094
  * f1-score: 0.0152
  * support: 43372.0000
 weighted avg:
  * precision: 0.0655
  * recall: 0.0086
  * f1-score: 0.0135
  * support: 43372.0000
 accuracy:
  * 0.1731
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8560
 * Micro Average: f1: 0.7476, precision: 0.7490, recall: 0.7462
 * Macro Average: f1: 0.7467, precision: 0.7465, recall: 0.7480

Epoch 2/4, accuracy: 0.8768
 * Micro Average: f1: 0.7823, precision: 0.7860, recall: 0.7785
 * Macro Average: f1: 0.7834, precision: 0.7823, recall: 0.7861

Epoch 3/4, accuracy: 0.8827
 * Micro Average: f1: 0.7952, precision: 0.7942, recall: 0.7961
 * Macro Average: f1: 0.7965, precision: 0.7926, recall: 0.8009

Epoch 4/4, accuracy: 0.8850
 * Micro Average: f1: 0.7995, precision: 0.7947, recall: 0.8043
 * Macro Average: f1: 0.8007, precision: 0.7934, recall: 0.8085

 time for training and evaluating:144.1822407245636 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7567
  * recall: 0.8245
  * f1-score: 0.7892
  * support: 10097.0000
 ORG:
  * precision: 0.7157
  * recall: 0.7221
  * f1-score: 0.7189
  * support: 14408.0000
 PER:
  * precision: 0.7500
  * recall: 0.7930
  * f1-score: 0.7709
  * support: 18853.0000
 micro avg:
  * precision: 0.7407
  * recall: 0.7768
  * f1-score: 0.7583
  * support: 43358.0000
 macro avg:
  * precision: 0.7408
  * recall: 0.7799
  * f1-score: 0.7597
  * support: 43358.0000
 weighted avg:
  * precision: 0.7402
  * recall: 0.7768
  * f1-score: 0.7579
  * support: 43358.0000
 accuracy:
  * 0.8591
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1230
 * Micro Average: f1: 0.1911, precision: 0.1315, recall: 0.3496
 * Macro Average: f1: 0.1163, precision: 0.0952, recall: 0.2711

Epoch 2/4, accuracy: 0.2067
 * Micro Average: f1: 0.2039, precision: 0.1450, recall: 0.3437
 * Macro Average: f1: 0.1177, precision: 0.1098, recall: 0.2639

Epoch 3/4, accuracy: 0.3209
 * Micro Average: f1: 0.1885, precision: 0.1543, recall: 0.2422
 * Macro Average: f1: 0.0996, precision: 0.1152, recall: 0.1843

Epoch 4/4, accuracy: 0.3667
 * Micro Average: f1: 0.1725, precision: 0.1583, recall: 0.1896
 * Macro Average: f1: 0.0899, precision: 0.1169, recall: 0.1439

 time for training and evaluating:57.97754192352295 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10089.0000
 ORG:
  * precision: 0.1924
  * recall: 0.0579
  * f1-score: 0.0891
  * support: 14396.0000
 PER:
  * precision: 0.1428
  * recall: 0.4362
  * f1-score: 0.2152
  * support: 18854.0000
 micro avg:
  * precision: 0.1463
  * recall: 0.2090
  * f1-score: 0.1721
  * support: 43339.0000
 macro avg:
  * precision: 0.1117
  * recall: 0.1647
  * f1-score: 0.1014
  * support: 43339.0000
 weighted avg:
  * precision: 0.1260
  * recall: 0.2090
  * f1-score: 0.1232
  * support: 43339.0000
 accuracy:
  * 0.4003
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7591
 * Micro Average: f1: 0.5843, precision: 0.5645, recall: 0.6056
 * Macro Average: f1: 0.5836, precision: 0.5639, recall: 0.6073

Epoch 2/4, accuracy: 0.8258
 * Micro Average: f1: 0.6931, precision: 0.6898, recall: 0.6965
 * Macro Average: f1: 0.6922, precision: 0.6852, recall: 0.7022

Epoch 3/4, accuracy: 0.8417
 * Micro Average: f1: 0.7262, precision: 0.7225, recall: 0.7299
 * Macro Average: f1: 0.7268, precision: 0.7187, recall: 0.7370

Epoch 4/4, accuracy: 0.8443
 * Micro Average: f1: 0.7280, precision: 0.7268, recall: 0.7292
 * Macro Average: f1: 0.7289, precision: 0.7226, recall: 0.7381

 time for training and evaluating:144.21422290802002 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6579
  * recall: 0.8221
  * f1-score: 0.7309
  * support: 10109.0000
 ORG:
  * precision: 0.6976
  * recall: 0.6565
  * f1-score: 0.6765
  * support: 14406.0000
 PER:
  * precision: 0.7583
  * recall: 0.7243
  * f1-score: 0.7409
  * support: 18840.0000
 micro avg:
  * precision: 0.7110
  * recall: 0.7246
  * f1-score: 0.7177
  * support: 43355.0000
 macro avg:
  * precision: 0.7046
  * recall: 0.7343
  * f1-score: 0.7161
  * support: 43355.0000
 weighted avg:
  * precision: 0.7147
  * recall: 0.7246
  * f1-score: 0.7172
  * support: 43355.0000
 accuracy:
  * 0.8366
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4802
 * Micro Average: f1: 0.0003, precision: 0.0176, recall: 0.0001
 * Macro Average: f1: 0.0004, precision: 0.0061, recall: 0.0002

Epoch 2/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4824
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4821
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:57.193021059036255 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10092.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14390.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18835.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43317.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43317.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43317.0000
 accuracy:
  * 0.5433
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7553
 * Micro Average: f1: 0.5746, precision: 0.5470, recall: 0.6052
 * Macro Average: f1: 0.5711, precision: 0.5478, recall: 0.5976

Epoch 2/4, accuracy: 0.8236
 * Micro Average: f1: 0.6896, precision: 0.6883, recall: 0.6908
 * Macro Average: f1: 0.6881, precision: 0.6828, recall: 0.6968

Epoch 3/4, accuracy: 0.8399
 * Micro Average: f1: 0.7189, precision: 0.7235, recall: 0.7143
 * Macro Average: f1: 0.7187, precision: 0.7181, recall: 0.7225

Epoch 4/4, accuracy: 0.8429
 * Micro Average: f1: 0.7254, precision: 0.7273, recall: 0.7235
 * Macro Average: f1: 0.7253, precision: 0.7233, recall: 0.7303

 time for training and evaluating:144.34049940109253 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6541
  * recall: 0.8115
  * f1-score: 0.7244
  * support: 10087.0000
 ORG:
  * precision: 0.7094
  * recall: 0.6328
  * f1-score: 0.6689
  * support: 14399.0000
 PER:
  * precision: 0.7465
  * recall: 0.7273
  * f1-score: 0.7368
  * support: 18875.0000
 micro avg:
  * precision: 0.7092
  * recall: 0.7155
  * f1-score: 0.7123
  * support: 43361.0000
 macro avg:
  * precision: 0.7033
  * recall: 0.7239
  * f1-score: 0.7100
  * support: 43361.0000
 weighted avg:
  * precision: 0.7127
  * recall: 0.7155
  * f1-score: 0.7113
  * support: 43361.0000
 accuracy:
  * 0.8355
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4825
 * Micro Average: f1: 0.0087, precision: 0.2139, recall: 0.0045
 * Macro Average: f1: 0.0064, precision: 0.1821, recall: 0.0033

Epoch 2/4, accuracy: 0.4840
 * Micro Average: f1: 0.0002, precision: 0.3333, recall: 0.0001
 * Macro Average: f1: 0.0001, precision: 0.1111, recall: 0.0001

Epoch 3/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4825
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:57.418564796447754 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10099.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14406.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18854.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43359.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43359.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43359.0000
 accuracy:
  * 0.5431
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4834
 * Micro Average: f1: 0.0001, precision: 1.0000, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.3333, recall: 0.0000

Epoch 2/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:143.8624300956726 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10111.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14383.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18866.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43360.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43360.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43360.0000
 accuracy:
  * 0.5430
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.2885
 * Micro Average: f1: 0.1550, precision: 0.1340, recall: 0.1837
 * Macro Average: f1: 0.0690, precision: 0.1192, recall: 0.1377

Epoch 2/4, accuracy: 0.4764
 * Micro Average: f1: 0.0224, precision: 0.1458, recall: 0.0121
 * Macro Average: f1: 0.0152, precision: 0.0488, recall: 0.0090

Epoch 3/4, accuracy: 0.4826
 * Micro Average: f1: 0.0030, precision: 0.1546, recall: 0.0015
 * Macro Average: f1: 0.0022, precision: 0.0521, recall: 0.0011

Epoch 4/4, accuracy: 0.4828
 * Micro Average: f1: 0.0015, precision: 0.1744, recall: 0.0007
 * Macro Average: f1: 0.0011, precision: 0.0581, recall: 0.0006

 time for training and evaluating:57.63207221031189 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10097.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14384.0000
 PER:
  * precision: 0.1126
  * recall: 0.0099
  * f1-score: 0.0182
  * support: 18844.0000
 micro avg:
  * precision: 0.1126
  * recall: 0.0043
  * f1-score: 0.0083
  * support: 43325.0000
 macro avg:
  * precision: 0.0375
  * recall: 0.0033
  * f1-score: 0.0061
  * support: 43325.0000
 weighted avg:
  * precision: 0.0490
  * recall: 0.0043
  * f1-score: 0.0079
  * support: 43325.0000
 accuracy:
  * 0.5364
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4831
 * Micro Average: f1: 0.0001, precision: 1.0000, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.3333, recall: 0.0001

Epoch 2/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4827
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4839
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:144.0479381084442 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 10064.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 14390.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 18833.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43287.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43287.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 43287.0000
 accuracy:
  * 0.5437
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-it.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0719
 * Micro Average: f1: 0.0010, precision: 0.0407, recall: 0.0005
 * Macro Average: f1: 0.0008, precision: 0.1319, recall: 0.0004

Epoch 2/4, accuracy: 0.0732
 * Micro Average: f1: 0.0015, precision: 0.0430, recall: 0.0007
 * Macro Average: f1: 0.0011, precision: 0.0649, recall: 0.0006

Epoch 3/4, accuracy: 0.0790
 * Micro Average: f1: 0.0027, precision: 0.0285, recall: 0.0014
 * Macro Average: f1: 0.0023, precision: 0.0688, recall: 0.0012

Epoch 4/4, accuracy: 0.0848
 * Micro Average: f1: 0.0032, precision: 0.0224, recall: 0.0017
 * Macro Average: f1: 0.0028, precision: 0.0713, recall: 0.0015

 time for training and evaluating:57.67506694793701 for train language combination:train-en.tsv.gz and test language: dev-it.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0026
  * recall: 0.0007
  * f1-score: 0.0011
  * support: 10092.0000
 ORG:
  * precision: 0.0385
  * recall: 0.0001
  * f1-score: 0.0001
  * support: 14408.0000
 PER:
  * precision: 0.1269
  * recall: 0.0054
  * f1-score: 0.0104
  * support: 18854.0000
 micro avg:
  * precision: 0.0308
  * recall: 0.0025
  * f1-score: 0.0047
  * support: 43354.0000
 macro avg:
  * precision: 0.0560
  * recall: 0.0021
  * f1-score: 0.0039
  * support: 43354.0000
 weighted avg:
  * precision: 0.0685
  * recall: 0.0025
  * f1-score: 0.0048
  * support: 43354.0000
 accuracy:
  * 0.0624
________________________________________


Map:   0%|          | 0/514 [00:00<?, ? examples/s]Map: 100%|██████████| 514/514 [00:00<00:00, 6931.98 examples/s]
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8768
 * Micro Average: f1: 0.7884, precision: 0.7811, recall: 0.7959
 * Macro Average: f1: 0.7901, precision: 0.7847, recall: 0.7959

Epoch 2/4, accuracy: 0.8862
 * Micro Average: f1: 0.8051, precision: 0.7930, recall: 0.8177
 * Macro Average: f1: 0.8071, precision: 0.7956, recall: 0.8191

Epoch 3/4, accuracy: 0.8926
 * Micro Average: f1: 0.8133, precision: 0.8106, recall: 0.8161
 * Macro Average: f1: 0.8149, precision: 0.8110, recall: 0.8190

Epoch 4/4, accuracy: 0.8940
 * Micro Average: f1: 0.8167, precision: 0.8146, recall: 0.8189
 * Macro Average: f1: 0.8185, precision: 0.8137, recall: 0.8238

 time for training and evaluating:212.3133351802826 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6199
  * recall: 0.7256
  * f1-score: 0.6686
  * support: 962.0000
 ORG:
  * precision: 0.5859
  * recall: 0.6794
  * f1-score: 0.6292
  * support: 1335.0000
 PER:
  * precision: 0.6552
  * recall: 0.6556
  * f1-score: 0.6554
  * support: 1449.0000
 micro avg:
  * precision: 0.6195
  * recall: 0.6821
  * f1-score: 0.6493
  * support: 3746.0000
 macro avg:
  * precision: 0.6203
  * recall: 0.6869
  * f1-score: 0.6511
  * support: 3746.0000
 weighted avg:
  * precision: 0.6214
  * recall: 0.6821
  * f1-score: 0.6494
  * support: 3746.0000
 accuracy:
  * 0.7395
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.7483115196228 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 958.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1336.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1453.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3747.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3747.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3747.0000
 accuracy:
  * 0.4550
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8737
 * Micro Average: f1: 0.7816, precision: 0.7714, recall: 0.7920
 * Macro Average: f1: 0.7830, precision: 0.7707, recall: 0.7978

Epoch 2/4, accuracy: 0.8873
 * Micro Average: f1: 0.8067, precision: 0.8109, recall: 0.8025
 * Macro Average: f1: 0.8085, precision: 0.8084, recall: 0.8098

Epoch 3/4, accuracy: 0.8921
 * Micro Average: f1: 0.8155, precision: 0.8107, recall: 0.8204
 * Macro Average: f1: 0.8163, precision: 0.8116, recall: 0.8211

Epoch 4/4, accuracy: 0.8934
 * Micro Average: f1: 0.8168, precision: 0.8146, recall: 0.8189
 * Macro Average: f1: 0.8177, precision: 0.8133, recall: 0.8224

 time for training and evaluating:213.23858547210693 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6111
  * recall: 0.6977
  * f1-score: 0.6515
  * support: 966.0000
 ORG:
  * precision: 0.5797
  * recall: 0.6809
  * f1-score: 0.6262
  * support: 1335.0000
 PER:
  * precision: 0.6680
  * recall: 0.6763
  * f1-score: 0.6722
  * support: 1449.0000
 micro avg:
  * precision: 0.6194
  * recall: 0.6835
  * f1-score: 0.6498
  * support: 3750.0000
 macro avg:
  * precision: 0.6196
  * recall: 0.6850
  * f1-score: 0.6500
  * support: 3750.0000
 weighted avg:
  * precision: 0.6219
  * recall: 0.6835
  * f1-score: 0.6505
  * support: 3750.0000
 accuracy:
  * 0.7409
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4832
 * Micro Average: f1: 0.0022, precision: 0.2000, recall: 0.0011
 * Macro Average: f1: 0.0023, precision: 0.1093, recall: 0.0012

Epoch 2/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.715352058410645 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 962.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1332.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1457.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3751.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3751.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3751.0000
 accuracy:
  * 0.4552
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8320
 * Micro Average: f1: 0.7049, precision: 0.7105, recall: 0.6994
 * Macro Average: f1: 0.7041, precision: 0.7047, recall: 0.7079

Epoch 2/4, accuracy: 0.8539
 * Micro Average: f1: 0.7457, precision: 0.7441, recall: 0.7472
 * Macro Average: f1: 0.7447, precision: 0.7406, recall: 0.7526

Epoch 3/4, accuracy: 0.8633
 * Micro Average: f1: 0.7664, precision: 0.7586, recall: 0.7743
 * Macro Average: f1: 0.7670, precision: 0.7579, recall: 0.7771

Epoch 4/4, accuracy: 0.8680
 * Micro Average: f1: 0.7739, precision: 0.7705, recall: 0.7774
 * Macro Average: f1: 0.7746, precision: 0.7686, recall: 0.7815

 time for training and evaluating:212.42091488838196 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5714
  * recall: 0.7012
  * f1-score: 0.6297
  * support: 964.0000
 ORG:
  * precision: 0.5437
  * recall: 0.5787
  * f1-score: 0.5606
  * support: 1334.0000
 PER:
  * precision: 0.7118
  * recall: 0.6476
  * f1-score: 0.6782
  * support: 1453.0000
 micro avg:
  * precision: 0.6087
  * recall: 0.6369
  * f1-score: 0.6225
  * support: 3751.0000
 macro avg:
  * precision: 0.6090
  * recall: 0.6425
  * f1-score: 0.6229
  * support: 3751.0000
 weighted avg:
  * precision: 0.6159
  * recall: 0.6369
  * f1-score: 0.6239
  * support: 3751.0000
 accuracy:
  * 0.7290
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.95495057106018 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 958.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1339.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1449.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3746.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3746.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3746.0000
 accuracy:
  * 0.4562
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8313
 * Micro Average: f1: 0.7066, precision: 0.7020, recall: 0.7112
 * Macro Average: f1: 0.7064, precision: 0.6985, recall: 0.7152

Epoch 2/4, accuracy: 0.8535
 * Micro Average: f1: 0.7449, precision: 0.7480, recall: 0.7419
 * Macro Average: f1: 0.7452, precision: 0.7435, recall: 0.7504

Epoch 3/4, accuracy: 0.8622
 * Micro Average: f1: 0.7610, precision: 0.7581, recall: 0.7640
 * Macro Average: f1: 0.7613, precision: 0.7543, recall: 0.7694

Epoch 4/4, accuracy: 0.8664
 * Micro Average: f1: 0.7704, precision: 0.7696, recall: 0.7712
 * Macro Average: f1: 0.7712, precision: 0.7661, recall: 0.7775

 time for training and evaluating:212.75584197044373 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5414
  * recall: 0.6663
  * f1-score: 0.5974
  * support: 962.0000
 ORG:
  * precision: 0.5266
  * recall: 0.5945
  * f1-score: 0.5585
  * support: 1334.0000
 PER:
  * precision: 0.7181
  * recall: 0.6140
  * f1-score: 0.6620
  * support: 1448.0000
 micro avg:
  * precision: 0.5914
  * recall: 0.6205
  * f1-score: 0.6056
  * support: 3744.0000
 macro avg:
  * precision: 0.5953
  * recall: 0.6249
  * f1-score: 0.6059
  * support: 3744.0000
 weighted avg:
  * precision: 0.6044
  * recall: 0.6205
  * f1-score: 0.6085
  * support: 3744.0000
 accuracy:
  * 0.7155
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4497
 * Micro Average: f1: 0.0397, precision: 0.1042, recall: 0.0245
 * Macro Average: f1: 0.0262, precision: 0.0537, recall: 0.0189

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0001, precision: 0.2000, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0667, recall: 0.0000

Epoch 3/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.419002056121826 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 968.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1338.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1452.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3758.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3758.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3758.0000
 accuracy:
  * 0.4544
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4830
 * Micro Average: f1: 0.0002, precision: 0.2857, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.4000, recall: 0.0001

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:212.00126147270203 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 960.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1330.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1457.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3747.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3747.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3747.0000
 accuracy:
  * 0.4551
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1059
 * Micro Average: f1: 0.0002, precision: 0.0096, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.3590, recall: 0.0001

Epoch 2/4, accuracy: 0.1106
 * Micro Average: f1: 0.0015, precision: 0.0116, recall: 0.0008
 * Macro Average: f1: 0.0010, precision: 0.0039, recall: 0.0006

Epoch 3/4, accuracy: 0.2774
 * Micro Average: f1: 0.0477, precision: 0.0648, recall: 0.0377
 * Macro Average: f1: 0.0244, precision: 0.0216, recall: 0.0282

Epoch 4/4, accuracy: 0.4197
 * Micro Average: f1: 0.0462, precision: 0.1021, recall: 0.0298
 * Macro Average: f1: 0.0270, precision: 0.0340, recall: 0.0223

 time for training and evaluating:64.32524228096008 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 963.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1331.0000
 PER:
  * precision: 0.0739
  * recall: 0.0601
  * f1-score: 0.0663
  * support: 1448.0000
 micro avg:
  * precision: 0.0739
  * recall: 0.0232
  * f1-score: 0.0354
  * support: 3742.0000
 macro avg:
  * precision: 0.0246
  * recall: 0.0200
  * f1-score: 0.0221
  * support: 3742.0000
 weighted avg:
  * precision: 0.0286
  * recall: 0.0232
  * f1-score: 0.0256
  * support: 3742.0000
 accuracy:
  * 0.3851
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4847
 * Micro Average: f1: 0.0774, precision: 0.1551, recall: 0.0515
 * Macro Average: f1: 0.0466, precision: 0.0884, recall: 0.0392

Epoch 2/4, accuracy: 0.4867
 * Micro Average: f1: 0.0571, precision: 0.1791, recall: 0.0340
 * Macro Average: f1: 0.0365, precision: 0.1983, recall: 0.0257

Epoch 3/4, accuracy: 0.4851
 * Micro Average: f1: 0.0260, precision: 0.1867, recall: 0.0140
 * Macro Average: f1: 0.0181, precision: 0.2240, recall: 0.0105

Epoch 4/4, accuracy: 0.4842
 * Micro Average: f1: 0.0158, precision: 0.1962, recall: 0.0082
 * Macro Average: f1: 0.0115, precision: 0.2870, recall: 0.0063

 time for training and evaluating:212.20180106163025 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 964.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1329.0000
 PER:
  * precision: 0.1020
  * recall: 0.0069
  * f1-score: 0.0129
  * support: 1457.0000
 micro avg:
  * precision: 0.1010
  * recall: 0.0027
  * f1-score: 0.0052
  * support: 3750.0000
 macro avg:
  * precision: 0.0340
  * recall: 0.0023
  * f1-score: 0.0043
  * support: 3750.0000
 weighted avg:
  * precision: 0.0396
  * recall: 0.0027
  * f1-score: 0.0050
  * support: 3750.0000
 accuracy:
  * 0.4554
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0718
 * Micro Average: f1: 0.0001, precision: 0.0017, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0556, recall: 0.0000

Epoch 2/4, accuracy: 0.4503
 * Micro Average: f1: 0.0056, precision: 0.0280, recall: 0.0031
 * Macro Average: f1: 0.0061, precision: 0.0093, recall: 0.0045

Epoch 3/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.432502031326294 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 965.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1334.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1460.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3759.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3759.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3759.0000
 accuracy:
  * 0.4546
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8691
 * Micro Average: f1: 0.7724, precision: 0.7686, recall: 0.7762
 * Macro Average: f1: 0.7730, precision: 0.7689, recall: 0.7772

Epoch 2/4, accuracy: 0.8820
 * Micro Average: f1: 0.7964, precision: 0.7923, recall: 0.8006
 * Macro Average: f1: 0.7975, precision: 0.7931, recall: 0.8023

Epoch 3/4, accuracy: 0.8882
 * Micro Average: f1: 0.8063, precision: 0.8038, recall: 0.8087
 * Macro Average: f1: 0.8073, precision: 0.8036, recall: 0.8112

Epoch 4/4, accuracy: 0.8903
 * Micro Average: f1: 0.8083, precision: 0.8050, recall: 0.8117
 * Macro Average: f1: 0.8091, precision: 0.8034, recall: 0.8151

 time for training and evaluating:170.31825399398804 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6004
  * recall: 0.7066
  * f1-score: 0.6491
  * support: 961.0000
 ORG:
  * precision: 0.5642
  * recall: 0.6642
  * f1-score: 0.6101
  * support: 1337.0000
 PER:
  * precision: 0.6947
  * recall: 0.6632
  * f1-score: 0.6786
  * support: 1458.0000
 micro avg:
  * precision: 0.6185
  * recall: 0.6747
  * f1-score: 0.6454
  * support: 3756.0000
 macro avg:
  * precision: 0.6197
  * recall: 0.6780
  * f1-score: 0.6459
  * support: 3756.0000
 weighted avg:
  * precision: 0.6241
  * recall: 0.6747
  * f1-score: 0.6467
  * support: 3756.0000
 accuracy:
  * 0.7344
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0823
 * Micro Average: f1: 0.0795, precision: 0.0931, recall: 0.0694
 * Macro Average: f1: 0.0683, precision: 0.0867, recall: 0.0572

Epoch 2/4, accuracy: 0.1134
 * Micro Average: f1: 0.1472, precision: 0.1286, recall: 0.1721
 * Macro Average: f1: 0.1095, precision: 0.0936, recall: 0.1377

Epoch 3/4, accuracy: 0.3079
 * Micro Average: f1: 0.2043, precision: 0.1664, recall: 0.2646
 * Macro Average: f1: 0.1419, precision: 0.1185, recall: 0.2139

Epoch 4/4, accuracy: 0.3650
 * Micro Average: f1: 0.2207, precision: 0.1818, recall: 0.2807
 * Macro Average: f1: 0.1503, precision: 0.1289, recall: 0.2259

 time for training and evaluating:60.780330181121826 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0139
  * recall: 0.0042
  * f1-score: 0.0064
  * support: 962.0000
 ORG:
  * precision: 0.1359
  * recall: 0.1631
  * f1-score: 0.1482
  * support: 1337.0000
 PER:
  * precision: 0.1646
  * recall: 0.4945
  * f1-score: 0.2470
  * support: 1456.0000
 micro avg:
  * precision: 0.1504
  * recall: 0.2509
  * f1-score: 0.1880
  * support: 3755.0000
 macro avg:
  * precision: 0.1048
  * recall: 0.2206
  * f1-score: 0.1339
  * support: 3755.0000
 weighted avg:
  * precision: 0.1158
  * recall: 0.2509
  * f1-score: 0.1502
  * support: 3755.0000
 accuracy:
  * 0.2968
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8706
 * Micro Average: f1: 0.7768, precision: 0.7663, recall: 0.7877
 * Macro Average: f1: 0.7780, precision: 0.7686, recall: 0.7878

Epoch 2/4, accuracy: 0.8845
 * Micro Average: f1: 0.8005, precision: 0.8004, recall: 0.8006
 * Macro Average: f1: 0.8018, precision: 0.7990, recall: 0.8059

Epoch 3/4, accuracy: 0.8897
 * Micro Average: f1: 0.8087, precision: 0.8043, recall: 0.8132
 * Macro Average: f1: 0.8095, precision: 0.8035, recall: 0.8156

Epoch 4/4, accuracy: 0.8898
 * Micro Average: f1: 0.8088, precision: 0.8034, recall: 0.8143
 * Macro Average: f1: 0.8101, precision: 0.8030, recall: 0.8175

 time for training and evaluating:170.06520104408264 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6047
  * recall: 0.6972
  * f1-score: 0.6477
  * support: 961.0000
 ORG:
  * precision: 0.5655
  * recall: 0.6674
  * f1-score: 0.6122
  * support: 1326.0000
 PER:
  * precision: 0.6853
  * recall: 0.6623
  * f1-score: 0.6736
  * support: 1460.0000
 micro avg:
  * precision: 0.6175
  * recall: 0.6731
  * f1-score: 0.6441
  * support: 3747.0000
 macro avg:
  * precision: 0.6185
  * recall: 0.6756
  * f1-score: 0.6445
  * support: 3747.0000
 weighted avg:
  * precision: 0.6222
  * recall: 0.6731
  * f1-score: 0.6452
  * support: 3747.0000
 accuracy:
  * 0.7361
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4824
 * Micro Average: f1: 0.0155, precision: 0.1314, recall: 0.0082
 * Macro Average: f1: 0.0108, precision: 0.0440, recall: 0.0062

Epoch 2/4, accuracy: 0.4827
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:60.10198259353638 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 965.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1328.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1449.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3742.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3742.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3742.0000
 accuracy:
  * 0.4551
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7987
 * Micro Average: f1: 0.6476, precision: 0.6420, recall: 0.6532
 * Macro Average: f1: 0.6464, precision: 0.6356, recall: 0.6616

Epoch 2/4, accuracy: 0.8342
 * Micro Average: f1: 0.7104, precision: 0.7193, recall: 0.7018
 * Macro Average: f1: 0.7089, precision: 0.7145, recall: 0.7092

Epoch 3/4, accuracy: 0.8500
 * Micro Average: f1: 0.7389, precision: 0.7427, recall: 0.7352
 * Macro Average: f1: 0.7388, precision: 0.7384, recall: 0.7411

Epoch 4/4, accuracy: 0.8528
 * Micro Average: f1: 0.7434, precision: 0.7494, recall: 0.7375
 * Macro Average: f1: 0.7434, precision: 0.7449, recall: 0.7447

 time for training and evaluating:170.02538561820984 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5519
  * recall: 0.6684
  * f1-score: 0.6046
  * support: 962.0000
 ORG:
  * precision: 0.5459
  * recall: 0.5491
  * f1-score: 0.5475
  * support: 1333.0000
 PER:
  * precision: 0.7188
  * recall: 0.6259
  * f1-score: 0.6691
  * support: 1446.0000
 micro avg:
  * precision: 0.6056
  * recall: 0.6095
  * f1-score: 0.6075
  * support: 3741.0000
 macro avg:
  * precision: 0.6055
  * recall: 0.6145
  * f1-score: 0.6071
  * support: 3741.0000
 weighted avg:
  * precision: 0.6143
  * recall: 0.6095
  * f1-score: 0.6092
  * support: 3741.0000
 accuracy:
  * 0.7300
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:59.63071298599243 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 962.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1336.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1446.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3744.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3744.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3744.0000
 accuracy:
  * 0.4552
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7986
 * Micro Average: f1: 0.6508, precision: 0.6256, recall: 0.6780
 * Macro Average: f1: 0.6491, precision: 0.6220, recall: 0.6791

Epoch 2/4, accuracy: 0.8382
 * Micro Average: f1: 0.7207, precision: 0.7177, recall: 0.7237
 * Macro Average: f1: 0.7211, precision: 0.7141, recall: 0.7313

Epoch 3/4, accuracy: 0.8471
 * Micro Average: f1: 0.7353, precision: 0.7358, recall: 0.7348
 * Macro Average: f1: 0.7353, precision: 0.7312, recall: 0.7431

Epoch 4/4, accuracy: 0.8541
 * Micro Average: f1: 0.7470, precision: 0.7484, recall: 0.7456
 * Macro Average: f1: 0.7476, precision: 0.7442, recall: 0.7533

 time for training and evaluating:170.1376712322235 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5545
  * recall: 0.6722
  * f1-score: 0.6077
  * support: 961.0000
 ORG:
  * precision: 0.5381
  * recall: 0.5478
  * f1-score: 0.5429
  * support: 1329.0000
 PER:
  * precision: 0.7236
  * recall: 0.6193
  * f1-score: 0.6674
  * support: 1458.0000
 micro avg:
  * precision: 0.6046
  * recall: 0.6075
  * f1-score: 0.6061
  * support: 3748.0000
 macro avg:
  * precision: 0.6054
  * recall: 0.6131
  * f1-score: 0.6060
  * support: 3748.0000
 weighted avg:
  * precision: 0.6144
  * recall: 0.6075
  * f1-score: 0.6079
  * support: 3748.0000
 accuracy:
  * 0.7289
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4374
 * Micro Average: f1: 0.1032, precision: 0.1648, recall: 0.0751
 * Macro Average: f1: 0.0555, precision: 0.0549, recall: 0.0560

Epoch 2/4, accuracy: 0.4834
 * Micro Average: f1: 0.0033, precision: 0.2558, recall: 0.0017
 * Macro Average: f1: 0.0024, precision: 0.0853, recall: 0.0012

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0005, precision: 0.2941, recall: 0.0002
 * Macro Average: f1: 0.0004, precision: 0.0980, recall: 0.0002

Epoch 4/4, accuracy: 0.4827
 * Micro Average: f1: 0.0001, precision: 0.1667, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0556, recall: 0.0000

 time for training and evaluating:60.093395948410034 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 963.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1335.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1442.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3740.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3740.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3740.0000
 accuracy:
  * 0.4552
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4803
 * Micro Average: f1: 0.0090, precision: 0.0962, recall: 0.0047
 * Macro Average: f1: 0.0085, precision: 0.0321, recall: 0.0049

Epoch 2/4, accuracy: 0.4833
 * Micro Average: f1: 0.0003, precision: 0.0769, recall: 0.0001
 * Macro Average: f1: 0.0003, precision: 0.0256, recall: 0.0002

Epoch 3/4, accuracy: 0.4829
 * Micro Average: f1: 0.0002, precision: 0.1333, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.0444, recall: 0.0001

Epoch 4/4, accuracy: 0.4830
 * Micro Average: f1: 0.0001, precision: 0.1667, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0556, recall: 0.0001

 time for training and evaluating:169.54165816307068 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 960.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1335.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1451.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3746.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3746.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3746.0000
 accuracy:
  * 0.4557
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0681
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.0674
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.0676
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.0681
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:60.25221276283264 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 962.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1333.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1448.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3743.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3743.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3743.0000
 accuracy:
  * 0.0686
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:169.3314287662506 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 967.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1336.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1458.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3761.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3761.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3761.0000
 accuracy:
  * 0.4543
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0677
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.0678
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.0679
 * Micro Average: f1: 0.0002, precision: 0.0066, recall: 0.0001
 * Macro Average: f1: 0.0002, precision: 0.0567, recall: 0.0001

Epoch 4/4, accuracy: 0.0685
 * Micro Average: f1: 0.0004, precision: 0.0056, recall: 0.0002
 * Macro Average: f1: 0.0004, precision: 0.0681, recall: 0.0002

 time for training and evaluating:60.12687635421753 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 962.0000
 ORG:
  * precision: 0.0053
  * recall: 0.0007
  * f1-score: 0.0013
  * support: 1336.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1454.0000
 micro avg:
  * precision: 0.0053
  * recall: 0.0003
  * f1-score: 0.0005
  * support: 3752.0000
 macro avg:
  * precision: 0.0018
  * recall: 0.0002
  * f1-score: 0.0004
  * support: 3752.0000
 weighted avg:
  * precision: 0.0019
  * recall: 0.0003
  * f1-score: 0.0005
  * support: 3752.0000
 accuracy:
  * 0.0709
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8544
 * Micro Average: f1: 0.7466, precision: 0.7453, recall: 0.7479
 * Macro Average: f1: 0.7464, precision: 0.7393, recall: 0.7569

Epoch 2/4, accuracy: 0.8763
 * Micro Average: f1: 0.7839, precision: 0.7855, recall: 0.7823
 * Macro Average: f1: 0.7851, precision: 0.7821, recall: 0.7897

Epoch 3/4, accuracy: 0.8814
 * Micro Average: f1: 0.7938, precision: 0.7883, recall: 0.7994
 * Macro Average: f1: 0.7949, precision: 0.7875, recall: 0.8026

Epoch 4/4, accuracy: 0.8852
 * Micro Average: f1: 0.8006, precision: 0.7968, recall: 0.8043
 * Macro Average: f1: 0.8013, precision: 0.7953, recall: 0.8075

 time for training and evaluating:144.45141887664795 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5998
  * recall: 0.7080
  * f1-score: 0.6495
  * support: 959.0000
 ORG:
  * precision: 0.5690
  * recall: 0.6795
  * f1-score: 0.6193
  * support: 1329.0000
 PER:
  * precision: 0.7170
  * recall: 0.6516
  * f1-score: 0.6827
  * support: 1458.0000
 micro avg:
  * precision: 0.6261
  * recall: 0.6759
  * f1-score: 0.6501
  * support: 3746.0000
 macro avg:
  * precision: 0.6286
  * recall: 0.6797
  * f1-score: 0.6505
  * support: 3746.0000
 weighted avg:
  * precision: 0.6345
  * recall: 0.6759
  * f1-score: 0.6517
  * support: 3746.0000
 accuracy:
  * 0.7425
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0722
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.1304
 * Micro Average: f1: 0.0039, precision: 0.0111, recall: 0.0024
 * Macro Average: f1: 0.0036, precision: 0.0037, recall: 0.0035

Epoch 3/4, accuracy: 0.3510
 * Micro Average: f1: 0.0452, precision: 0.0646, recall: 0.0348
 * Macro Average: f1: 0.0301, precision: 0.0215, recall: 0.0501

Epoch 4/4, accuracy: 0.3978
 * Micro Average: f1: 0.0504, precision: 0.0805, recall: 0.0367
 * Macro Average: f1: 0.0356, precision: 0.0268, recall: 0.0530

 time for training and evaluating:57.537935733795166 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0817
  * recall: 0.1510
  * f1-score: 0.1060
  * support: 967.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1332.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1457.0000
 micro avg:
  * precision: 0.0817
  * recall: 0.0389
  * f1-score: 0.0527
  * support: 3756.0000
 macro avg:
  * precision: 0.0272
  * recall: 0.0503
  * f1-score: 0.0353
  * support: 3756.0000
 weighted avg:
  * precision: 0.0210
  * recall: 0.0389
  * f1-score: 0.0273
  * support: 3756.0000
 accuracy:
  * 0.3942
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8589
 * Micro Average: f1: 0.7560, precision: 0.7505, recall: 0.7616
 * Macro Average: f1: 0.7568, precision: 0.7474, recall: 0.7675

Epoch 2/4, accuracy: 0.8762
 * Micro Average: f1: 0.7849, precision: 0.7794, recall: 0.7904
 * Macro Average: f1: 0.7858, precision: 0.7776, recall: 0.7948

Epoch 3/4, accuracy: 0.8833
 * Micro Average: f1: 0.7972, precision: 0.7934, recall: 0.8009
 * Macro Average: f1: 0.7987, precision: 0.7915, recall: 0.8066

Epoch 4/4, accuracy: 0.8856
 * Micro Average: f1: 0.8024, precision: 0.7984, recall: 0.8065
 * Macro Average: f1: 0.8040, precision: 0.7974, recall: 0.8112

 time for training and evaluating:144.80310606956482 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6102
  * recall: 0.7225
  * f1-score: 0.6616
  * support: 962.0000
 ORG:
  * precision: 0.5758
  * recall: 0.6842
  * f1-score: 0.6253
  * support: 1333.0000
 PER:
  * precision: 0.7034
  * recall: 0.6634
  * f1-score: 0.6828
  * support: 1444.0000
 micro avg:
  * precision: 0.6279
  * recall: 0.6860
  * f1-score: 0.6557
  * support: 3739.0000
 macro avg:
  * precision: 0.6298
  * recall: 0.6900
  * f1-score: 0.6566
  * support: 3739.0000
 weighted avg:
  * precision: 0.6339
  * recall: 0.6860
  * f1-score: 0.6569
  * support: 3739.0000
 accuracy:
  * 0.7447
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0681
 * Micro Average: f1: 0.0030, precision: 0.0484, recall: 0.0015
 * Macro Average: f1: 0.0041, precision: 0.0754, recall: 0.0022

Epoch 2/4, accuracy: 0.0744
 * Micro Average: f1: 0.0038, precision: 0.0340, recall: 0.0020
 * Macro Average: f1: 0.0049, precision: 0.0705, recall: 0.0026

Epoch 3/4, accuracy: 0.2508
 * Micro Average: f1: 0.0295, precision: 0.0472, recall: 0.0215
 * Macro Average: f1: 0.0196, precision: 0.1002, recall: 0.0222

Epoch 4/4, accuracy: 0.3114
 * Micro Average: f1: 0.0387, precision: 0.0569, recall: 0.0293
 * Macro Average: f1: 0.0241, precision: 0.0933, recall: 0.0302

 time for training and evaluating:57.71084022521973 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0556
  * recall: 0.0010
  * f1-score: 0.0020
  * support: 961.0000
 ORG:
  * precision: 0.0821
  * recall: 0.1199
  * f1-score: 0.0975
  * support: 1335.0000
 PER:
  * precision: 0.2857
  * recall: 0.0014
  * f1-score: 0.0027
  * support: 1456.0000
 micro avg:
  * precision: 0.0826
  * recall: 0.0434
  * f1-score: 0.0569
  * support: 3752.0000
 macro avg:
  * precision: 0.1411
  * recall: 0.0408
  * f1-score: 0.0341
  * support: 3752.0000
 weighted avg:
  * precision: 0.1543
  * recall: 0.0434
  * f1-score: 0.0363
  * support: 3752.0000
 accuracy:
  * 0.2824
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7439
 * Micro Average: f1: 0.5657, precision: 0.5342, recall: 0.6012
 * Macro Average: f1: 0.5638, precision: 0.5353, recall: 0.5959

Epoch 2/4, accuracy: 0.8238
 * Micro Average: f1: 0.6909, precision: 0.6873, recall: 0.6945
 * Macro Average: f1: 0.6896, precision: 0.6811, recall: 0.7013

Epoch 3/4, accuracy: 0.8411
 * Micro Average: f1: 0.7210, precision: 0.7174, recall: 0.7246
 * Macro Average: f1: 0.7217, precision: 0.7131, recall: 0.7327

Epoch 4/4, accuracy: 0.8417
 * Micro Average: f1: 0.7233, precision: 0.7225, recall: 0.7241
 * Macro Average: f1: 0.7232, precision: 0.7178, recall: 0.7319

 time for training and evaluating:144.22545528411865 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5531
  * recall: 0.6687
  * f1-score: 0.6054
  * support: 966.0000
 ORG:
  * precision: 0.5519
  * recall: 0.5544
  * f1-score: 0.5531
  * support: 1333.0000
 PER:
  * precision: 0.7253
  * recall: 0.6265
  * f1-score: 0.6723
  * support: 1454.0000
 micro avg:
  * precision: 0.6102
  * recall: 0.6118
  * f1-score: 0.6110
  * support: 3753.0000
 macro avg:
  * precision: 0.6101
  * recall: 0.6166
  * f1-score: 0.6103
  * support: 3753.0000
 weighted avg:
  * precision: 0.6194
  * recall: 0.6118
  * f1-score: 0.6128
  * support: 3753.0000
 accuracy:
  * 0.7338
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4825
 * Micro Average: f1: 0.0007, precision: 0.0787, recall: 0.0003
 * Macro Average: f1: 0.0010, precision: 0.0265, recall: 0.0005

Epoch 2/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:57.21375226974487 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 964.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1329.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1458.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3751.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3751.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3751.0000
 accuracy:
  * 0.4545
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7375
 * Micro Average: f1: 0.5498, precision: 0.5285, recall: 0.5730
 * Macro Average: f1: 0.5491, precision: 0.5267, recall: 0.5737

Epoch 2/4, accuracy: 0.8131
 * Micro Average: f1: 0.6748, precision: 0.6643, recall: 0.6856
 * Macro Average: f1: 0.6742, precision: 0.6591, recall: 0.6923

Epoch 3/4, accuracy: 0.8334
 * Micro Average: f1: 0.7073, precision: 0.7070, recall: 0.7076
 * Macro Average: f1: 0.7068, precision: 0.7026, recall: 0.7133

Epoch 4/4, accuracy: 0.8374
 * Micro Average: f1: 0.7158, precision: 0.7135, recall: 0.7182
 * Macro Average: f1: 0.7156, precision: 0.7089, recall: 0.7249

 time for training and evaluating:143.95441222190857 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5547
  * recall: 0.6448
  * f1-score: 0.5963
  * support: 960.0000
 ORG:
  * precision: 0.5415
  * recall: 0.5561
  * f1-score: 0.5487
  * support: 1327.0000
 PER:
  * precision: 0.7122
  * recall: 0.6133
  * f1-score: 0.6591
  * support: 1461.0000
 micro avg:
  * precision: 0.6029
  * recall: 0.6011
  * f1-score: 0.6020
  * support: 3748.0000
 macro avg:
  * precision: 0.6028
  * recall: 0.6047
  * f1-score: 0.6014
  * support: 3748.0000
 weighted avg:
  * precision: 0.6114
  * recall: 0.6011
  * f1-score: 0.6039
  * support: 3748.0000
 accuracy:
  * 0.7295
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1056
 * Micro Average: f1: 0.0035, precision: 0.0112, recall: 0.0021
 * Macro Average: f1: 0.0038, precision: 0.0123, recall: 0.0022

Epoch 2/4, accuracy: 0.1408
 * Micro Average: f1: 0.0080, precision: 0.0166, recall: 0.0053
 * Macro Average: f1: 0.0063, precision: 0.0159, recall: 0.0044

Epoch 3/4, accuracy: 0.2421
 * Micro Average: f1: 0.0345, precision: 0.0491, recall: 0.0266
 * Macro Average: f1: 0.0195, precision: 0.0438, recall: 0.0202

Epoch 4/4, accuracy: 0.2787
 * Micro Average: f1: 0.0440, precision: 0.0616, recall: 0.0342
 * Macro Average: f1: 0.0239, precision: 0.0630, recall: 0.0258

 time for training and evaluating:57.40168738365173 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 961.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1331.0000
 PER:
  * precision: 0.0395
  * recall: 0.0552
  * f1-score: 0.0460
  * support: 1448.0000
 micro avg:
  * precision: 0.0390
  * recall: 0.0214
  * f1-score: 0.0276
  * support: 3740.0000
 macro avg:
  * precision: 0.0132
  * recall: 0.0184
  * f1-score: 0.0153
  * support: 3740.0000
 weighted avg:
  * precision: 0.0153
  * recall: 0.0214
  * f1-score: 0.0178
  * support: 3740.0000
 accuracy:
  * 0.2608
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.2996
 * Micro Average: f1: 0.1287, precision: 0.1095, recall: 0.1561
 * Macro Average: f1: 0.0914, precision: 0.0745, recall: 0.1473

Epoch 2/4, accuracy: 0.4489
 * Micro Average: f1: 0.1006, precision: 0.1387, recall: 0.0789
 * Macro Average: f1: 0.0780, precision: 0.0932, recall: 0.0731

Epoch 3/4, accuracy: 0.4669
 * Micro Average: f1: 0.0737, precision: 0.1441, recall: 0.0495
 * Macro Average: f1: 0.0599, precision: 0.0967, recall: 0.0453

Epoch 4/4, accuracy: 0.4730
 * Micro Average: f1: 0.0595, precision: 0.1499, recall: 0.0371
 * Macro Average: f1: 0.0495, precision: 0.1005, recall: 0.0341

 time for training and evaluating:143.56798434257507 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 963.0000
 ORG:
  * precision: 0.2037
  * recall: 0.0329
  * f1-score: 0.0566
  * support: 1338.0000
 PER:
  * precision: 0.0855
  * recall: 0.0180
  * f1-score: 0.0297
  * support: 1445.0000
 micro avg:
  * precision: 0.1346
  * recall: 0.0187
  * f1-score: 0.0328
  * support: 3746.0000
 macro avg:
  * precision: 0.0964
  * recall: 0.0170
  * f1-score: 0.0288
  * support: 3746.0000
 weighted avg:
  * precision: 0.1058
  * recall: 0.0187
  * f1-score: 0.0317
  * support: 3746.0000
 accuracy:
  * 0.4480
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0741
 * Micro Average: f1: 0.1046, precision: 0.0792, recall: 0.1537
 * Macro Average: f1: 0.0453, precision: 0.0264, recall: 0.1584

Epoch 2/4, accuracy: 0.0769
 * Micro Average: f1: 0.1188, precision: 0.0868, recall: 0.1883
 * Macro Average: f1: 0.0504, precision: 0.0289, recall: 0.1942

Epoch 3/4, accuracy: 0.0805
 * Micro Average: f1: 0.1249, precision: 0.0900, recall: 0.2043
 * Macro Average: f1: 0.0525, precision: 0.0300, recall: 0.2110

Epoch 4/4, accuracy: 0.0844
 * Micro Average: f1: 0.1269, precision: 0.0910, recall: 0.2093
 * Macro Average: f1: 0.0532, precision: 0.0303, recall: 0.2159

 time for training and evaluating:57.785953521728516 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 960.0000
 ORG:
  * precision: 0.1013
  * recall: 0.6784
  * f1-score: 0.1763
  * support: 1334.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1450.0000
 micro avg:
  * precision: 0.1013
  * recall: 0.2417
  * f1-score: 0.1428
  * support: 3744.0000
 macro avg:
  * precision: 0.0338
  * recall: 0.2261
  * f1-score: 0.0588
  * support: 3744.0000
 weighted avg:
  * precision: 0.0361
  * recall: 0.2417
  * f1-score: 0.0628
  * support: 3744.0000
 accuracy:
  * 0.0963
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4824
 * Micro Average: f1: 0.0001, precision: 1.0000, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.3333, recall: 0.0001

Epoch 2/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4824
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4842
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:143.46673464775085 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 963.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1322.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1450.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3735.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3735.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 3735.0000
 accuracy:
  * 0.4557
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-sw.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0722
 * Micro Average: f1: 0.0078, precision: 0.0578, recall: 0.0042
 * Macro Average: f1: 0.0078, precision: 0.0393, recall: 0.0043

Epoch 2/4, accuracy: 0.0723
 * Micro Average: f1: 0.0082, precision: 0.0547, recall: 0.0044
 * Macro Average: f1: 0.0081, precision: 0.0384, recall: 0.0045

Epoch 3/4, accuracy: 0.0781
 * Micro Average: f1: 0.0095, precision: 0.0474, recall: 0.0053
 * Macro Average: f1: 0.0099, precision: 0.0635, recall: 0.0056

Epoch 4/4, accuracy: 0.0874
 * Micro Average: f1: 0.0089, precision: 0.0336, recall: 0.0051
 * Macro Average: f1: 0.0096, precision: 0.0602, recall: 0.0057

 time for training and evaluating:57.42445254325867 for train language combination:train-en.tsv.gz and test language: dev-sw.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0102
  * recall: 0.0041
  * f1-score: 0.0059
  * support: 966.0000
 ORG:
  * precision: 0.1575
  * recall: 0.0150
  * f1-score: 0.0274
  * support: 1333.0000
 PER:
  * precision: 0.6667
  * recall: 0.0014
  * f1-score: 0.0027
  * support: 1459.0000
 micro avg:
  * precision: 0.0496
  * recall: 0.0069
  * f1-score: 0.0121
  * support: 3758.0000
 macro avg:
  * precision: 0.2781
  * recall: 0.0068
  * f1-score: 0.0120
  * support: 3758.0000
 weighted avg:
  * precision: 0.3173
  * recall: 0.0069
  * f1-score: 0.0123
  * support: 3758.0000
 accuracy:
  * 0.1024
________________________________________


Map:   0%|          | 0/999 [00:00<?, ? examples/s]Map: 100%|██████████| 999/999 [00:00<00:00, 6775.23 examples/s]Map: 100%|██████████| 999/999 [00:00<00:00, 6711.70 examples/s]
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /fp/projects01/ec30/models/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.


====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8769
 * Micro Average: f1: 0.7858, precision: 0.7815, recall: 0.7902
 * Macro Average: f1: 0.7884, precision: 0.7802, recall: 0.7982

Epoch 2/4, accuracy: 0.8875
 * Micro Average: f1: 0.8067, precision: 0.7993, recall: 0.8143
 * Macro Average: f1: 0.8090, precision: 0.7997, recall: 0.8188

Epoch 3/4, accuracy: 0.8926
 * Micro Average: f1: 0.8154, precision: 0.8101, recall: 0.8208
 * Macro Average: f1: 0.8174, precision: 0.8104, recall: 0.8247

Epoch 4/4, accuracy: 0.8952
 * Micro Average: f1: 0.8197, precision: 0.8165, recall: 0.8229
 * Macro Average: f1: 0.8222, precision: 0.8166, recall: 0.8283

 time for training and evaluating:211.19939303398132 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6936
  * recall: 0.8078
  * f1-score: 0.7464
  * support: 796.0000
 ORG:
  * precision: 0.6884
  * recall: 0.7806
  * f1-score: 0.7316
  * support: 2083.0000
 PER:
  * precision: 0.7570
  * recall: 0.8098
  * f1-score: 0.7825
  * support: 2224.0000
 micro avg:
  * precision: 0.7181
  * recall: 0.7976
  * f1-score: 0.7557
  * support: 5103.0000
 macro avg:
  * precision: 0.7130
  * recall: 0.7994
  * f1-score: 0.7535
  * support: 5103.0000
 weighted avg:
  * precision: 0.7191
  * recall: 0.7976
  * f1-score: 0.7561
  * support: 5103.0000
 accuracy:
  * 0.8833
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4863
 * Micro Average: f1: 0.0162, precision: 0.1131, recall: 0.0087
 * Macro Average: f1: 0.0111, precision: 0.0377, recall: 0.0065

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:61.74916100502014 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 790.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2097.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2219.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5106.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5106.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5106.0000
 accuracy:
  * 0.6652
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8754
 * Micro Average: f1: 0.7842, precision: 0.7842, recall: 0.7843
 * Macro Average: f1: 0.7846, precision: 0.7818, recall: 0.7886

Epoch 2/4, accuracy: 0.8851
 * Micro Average: f1: 0.8000, precision: 0.7998, recall: 0.8003
 * Macro Average: f1: 0.8003, precision: 0.7965, recall: 0.8047

Epoch 3/4, accuracy: 0.8937
 * Micro Average: f1: 0.8144, precision: 0.8106, recall: 0.8183
 * Macro Average: f1: 0.8157, precision: 0.8102, recall: 0.8217

Epoch 4/4, accuracy: 0.8956
 * Micro Average: f1: 0.8191, precision: 0.8155, recall: 0.8228
 * Macro Average: f1: 0.8199, precision: 0.8139, recall: 0.8263

 time for training and evaluating:212.80726957321167 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7164
  * recall: 0.8060
  * f1-score: 0.7585
  * support: 799.0000
 ORG:
  * precision: 0.6874
  * recall: 0.8018
  * f1-score: 0.7402
  * support: 2084.0000
 PER:
  * precision: 0.7831
  * recall: 0.8319
  * f1-score: 0.8068
  * support: 2201.0000
 micro avg:
  * precision: 0.7315
  * recall: 0.8155
  * f1-score: 0.7712
  * support: 5084.0000
 macro avg:
  * precision: 0.7290
  * recall: 0.8132
  * f1-score: 0.7685
  * support: 5084.0000
 weighted avg:
  * precision: 0.7334
  * recall: 0.8155
  * f1-score: 0.7719
  * support: 5084.0000
 accuracy:
  * 0.8874
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.96875882148743 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 788.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2087.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2219.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5094.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5094.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5094.0000
 accuracy:
  * 0.6660
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8291
 * Micro Average: f1: 0.7039, precision: 0.7037, recall: 0.7041
 * Macro Average: f1: 0.7027, precision: 0.6979, recall: 0.7133

Epoch 2/4, accuracy: 0.8535
 * Micro Average: f1: 0.7474, precision: 0.7489, recall: 0.7458
 * Macro Average: f1: 0.7474, precision: 0.7449, recall: 0.7528

Epoch 3/4, accuracy: 0.8630
 * Micro Average: f1: 0.7649, precision: 0.7630, recall: 0.7668
 * Macro Average: f1: 0.7657, precision: 0.7602, recall: 0.7723

Epoch 4/4, accuracy: 0.8666
 * Micro Average: f1: 0.7705, precision: 0.7684, recall: 0.7726
 * Macro Average: f1: 0.7714, precision: 0.7655, recall: 0.7783

 time for training and evaluating:213.47424292564392 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6251
  * recall: 0.8094
  * f1-score: 0.7054
  * support: 787.0000
 ORG:
  * precision: 0.6559
  * recall: 0.7551
  * f1-score: 0.7020
  * support: 2078.0000
 PER:
  * precision: 0.7603
  * recall: 0.7896
  * f1-score: 0.7746
  * support: 2205.0000
 micro avg:
  * precision: 0.6923
  * recall: 0.7785
  * f1-score: 0.7329
  * support: 5070.0000
 macro avg:
  * precision: 0.6804
  * recall: 0.7847
  * f1-score: 0.7274
  * support: 5070.0000
 weighted avg:
  * precision: 0.6965
  * recall: 0.7785
  * f1-score: 0.7341
  * support: 5070.0000
 accuracy:
  * 0.8669
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1297
 * Micro Average: f1: 0.1979, precision: 0.1361, recall: 0.3626
 * Macro Average: f1: 0.0777, precision: 0.0454, recall: 0.2709

Epoch 2/4, accuracy: 0.4029
 * Micro Average: f1: 0.1760, precision: 0.1762, recall: 0.1758
 * Macro Average: f1: 0.0812, precision: 0.0587, recall: 0.1314

Epoch 3/4, accuracy: 0.4771
 * Micro Average: f1: 0.0473, precision: 0.2440, recall: 0.0262
 * Macro Average: f1: 0.0315, precision: 0.0813, recall: 0.0195

Epoch 4/4, accuracy: 0.4841
 * Micro Average: f1: 0.0239, precision: 0.3444, recall: 0.0124
 * Macro Average: f1: 0.0172, precision: 0.1148, recall: 0.0093

 time for training and evaluating:63.86872363090515 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 795.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2094.0000
 PER:
  * precision: 0.0765
  * recall: 0.0708
  * f1-score: 0.0735
  * support: 2219.0000
 micro avg:
  * precision: 0.0765
  * recall: 0.0307
  * f1-score: 0.0439
  * support: 5108.0000
 macro avg:
  * precision: 0.0255
  * recall: 0.0236
  * f1-score: 0.0245
  * support: 5108.0000
 weighted avg:
  * precision: 0.0332
  * recall: 0.0307
  * f1-score: 0.0319
  * support: 5108.0000
 accuracy:
  * 0.5928
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8272
 * Micro Average: f1: 0.6945, precision: 0.6903, recall: 0.6987
 * Macro Average: f1: 0.6930, precision: 0.6842, recall: 0.7052

Epoch 2/4, accuracy: 0.8530
 * Micro Average: f1: 0.7460, precision: 0.7487, recall: 0.7434
 * Macro Average: f1: 0.7471, precision: 0.7448, recall: 0.7511

Epoch 3/4, accuracy: 0.8599
 * Micro Average: f1: 0.7585, precision: 0.7537, recall: 0.7633
 * Macro Average: f1: 0.7596, precision: 0.7516, recall: 0.7690

Epoch 4/4, accuracy: 0.8631
 * Micro Average: f1: 0.7639, precision: 0.7642, recall: 0.7636
 * Macro Average: f1: 0.7647, precision: 0.7615, recall: 0.7695

 time for training and evaluating:213.47570538520813 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6392
  * recall: 0.7960
  * f1-score: 0.7090
  * support: 799.0000
 ORG:
  * precision: 0.6677
  * recall: 0.7464
  * f1-score: 0.7048
  * support: 2070.0000
 PER:
  * precision: 0.7542
  * recall: 0.7936
  * f1-score: 0.7734
  * support: 2200.0000
 micro avg:
  * precision: 0.6983
  * recall: 0.7747
  * f1-score: 0.7345
  * support: 5069.0000
 macro avg:
  * precision: 0.6870
  * recall: 0.7787
  * f1-score: 0.7291
  * support: 5069.0000
 weighted avg:
  * precision: 0.7007
  * recall: 0.7747
  * f1-score: 0.7353
  * support: 5069.0000
 accuracy:
  * 0.8707
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.777233362197876 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 798.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2089.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2207.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5094.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5094.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5094.0000
 accuracy:
  * 0.6662
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4825
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:213.14127135276794 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 792.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2084.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2219.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5095.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5095.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5095.0000
 accuracy:
  * 0.6661
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4611
 * Micro Average: f1: 0.0082, precision: 0.0488, recall: 0.0045
 * Macro Average: f1: 0.0072, precision: 0.0542, recall: 0.0045

Epoch 2/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:63.07782816886902 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 791.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2092.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2221.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5104.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5104.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5104.0000
 accuracy:
  * 0.6660
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4837
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4888
 * Micro Average: f1: 0.0376, precision: 0.1813, recall: 0.0210
 * Macro Average: f1: 0.0335, precision: 0.1174, recall: 0.0197

Epoch 4/4, accuracy: 0.5265
 * Micro Average: f1: 0.1651, precision: 0.2072, recall: 0.1372
 * Macro Average: f1: 0.1221, precision: 0.1304, recall: 0.1322

 time for training and evaluating:213.52585101127625 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 796.0000
 ORG:
  * precision: 0.2161
  * recall: 0.2525
  * f1-score: 0.2329
  * support: 2095.0000
 PER:
  * precision: 0.1576
  * recall: 0.0949
  * f1-score: 0.1184
  * support: 2224.0000
 micro avg:
  * precision: 0.1954
  * recall: 0.1447
  * f1-score: 0.1663
  * support: 5115.0000
 macro avg:
  * precision: 0.1246
  * recall: 0.1158
  * f1-score: 0.1171
  * support: 5115.0000
 weighted avg:
  * precision: 0.1570
  * recall: 0.1447
  * f1-score: 0.1469
  * support: 5115.0000
 accuracy:
  * 0.6415
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 16
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4827
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4825
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:64.31387543678284 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 787.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2087.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2219.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5093.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5093.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5093.0000
 accuracy:
  * 0.6665
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8712
 * Micro Average: f1: 0.7764, precision: 0.7675, recall: 0.7855
 * Macro Average: f1: 0.7768, precision: 0.7662, recall: 0.7881

Epoch 2/4, accuracy: 0.8809
 * Micro Average: f1: 0.7955, precision: 0.7898, recall: 0.8013
 * Macro Average: f1: 0.7963, precision: 0.7905, recall: 0.8023

Epoch 3/4, accuracy: 0.8884
 * Micro Average: f1: 0.8078, precision: 0.8025, recall: 0.8132
 * Macro Average: f1: 0.8093, precision: 0.8018, recall: 0.8170

Epoch 4/4, accuracy: 0.8881
 * Micro Average: f1: 0.8075, precision: 0.8027, recall: 0.8122
 * Macro Average: f1: 0.8087, precision: 0.8021, recall: 0.8155

 time for training and evaluating:171.05701875686646 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7167
  * recall: 0.7872
  * f1-score: 0.7503
  * support: 794.0000
 ORG:
  * precision: 0.6815
  * recall: 0.7914
  * f1-score: 0.7324
  * support: 2085.0000
 PER:
  * precision: 0.7477
  * recall: 0.8375
  * f1-score: 0.7900
  * support: 2215.0000
 micro avg:
  * precision: 0.7153
  * recall: 0.8108
  * f1-score: 0.7600
  * support: 5094.0000
 macro avg:
  * precision: 0.7153
  * recall: 0.8053
  * f1-score: 0.7576
  * support: 5094.0000
 weighted avg:
  * precision: 0.7158
  * recall: 0.8108
  * f1-score: 0.7602
  * support: 5094.0000
 accuracy:
  * 0.8813
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4371
 * Micro Average: f1: 0.1607, precision: 0.1852, recall: 0.1420
 * Macro Average: f1: 0.0781, precision: 0.0617, recall: 0.1062

Epoch 2/4, accuracy: 0.4830
 * Micro Average: f1: 0.0009, precision: 0.6923, recall: 0.0004
 * Macro Average: f1: 0.0007, precision: 0.2308, recall: 0.0003

Epoch 3/4, accuracy: 0.4824
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4837
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:60.101256370544434 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 793.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2090.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2204.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5087.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5087.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5087.0000
 accuracy:
  * 0.6667
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8710
 * Micro Average: f1: 0.7764, precision: 0.7772, recall: 0.7757
 * Macro Average: f1: 0.7770, precision: 0.7737, recall: 0.7813

Epoch 2/4, accuracy: 0.8835
 * Micro Average: f1: 0.7983, precision: 0.7937, recall: 0.8030
 * Macro Average: f1: 0.8001, precision: 0.7934, recall: 0.8080

Epoch 3/4, accuracy: 0.8891
 * Micro Average: f1: 0.8094, precision: 0.7995, recall: 0.8196
 * Macro Average: f1: 0.8110, precision: 0.8016, recall: 0.8206

Epoch 4/4, accuracy: 0.8906
 * Micro Average: f1: 0.8103, precision: 0.8067, recall: 0.8139
 * Macro Average: f1: 0.8122, precision: 0.8059, recall: 0.8188

 time for training and evaluating:170.95535850524902 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7115
  * recall: 0.8199
  * f1-score: 0.7618
  * support: 794.0000
 ORG:
  * precision: 0.6873
  * recall: 0.7774
  * f1-score: 0.7296
  * support: 2084.0000
 PER:
  * precision: 0.7564
  * recall: 0.8259
  * f1-score: 0.7896
  * support: 2211.0000
 micro avg:
  * precision: 0.7205
  * recall: 0.8051
  * f1-score: 0.7605
  * support: 5089.0000
 macro avg:
  * precision: 0.7184
  * recall: 0.8077
  * f1-score: 0.7603
  * support: 5089.0000
 weighted avg:
  * precision: 0.7211
  * recall: 0.8051
  * f1-score: 0.7607
  * support: 5089.0000
 accuracy:
  * 0.8807
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0797
 * Micro Average: f1: 0.1413, precision: 0.0972, recall: 0.2585
 * Macro Average: f1: 0.1020, precision: 0.1172, recall: 0.2938

Epoch 2/4, accuracy: 0.3395
 * Micro Average: f1: 0.1692, precision: 0.1367, recall: 0.2218
 * Macro Average: f1: 0.1284, precision: 0.2280, recall: 0.2488

Epoch 3/4, accuracy: 0.4765
 * Micro Average: f1: 0.0820, precision: 0.1659, recall: 0.0545
 * Macro Average: f1: 0.0767, precision: 0.2080, recall: 0.0614

Epoch 4/4, accuracy: 0.4835
 * Micro Average: f1: 0.0491, precision: 0.1900, recall: 0.0282
 * Macro Average: f1: 0.0492, precision: 0.2137, recall: 0.0315

 time for training and evaluating:60.184051275253296 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0226
  * recall: 0.0690
  * f1-score: 0.0341
  * support: 797.0000
 ORG:
  * precision: 0.1029
  * recall: 0.0886
  * f1-score: 0.0952
  * support: 2089.0000
 PER:
  * precision: 0.0714
  * recall: 0.0005
  * f1-score: 0.0009
  * support: 2217.0000
 micro avg:
  * precision: 0.0568
  * recall: 0.0472
  * f1-score: 0.0516
  * support: 5103.0000
 macro avg:
  * precision: 0.0657
  * recall: 0.0527
  * f1-score: 0.0434
  * support: 5103.0000
 weighted avg:
  * precision: 0.0767
  * recall: 0.0472
  * f1-score: 0.0447
  * support: 5103.0000
 accuracy:
  * 0.5385
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8002
 * Micro Average: f1: 0.6503, precision: 0.6388, recall: 0.6623
 * Macro Average: f1: 0.6482, precision: 0.6352, recall: 0.6642

Epoch 2/4, accuracy: 0.8393
 * Micro Average: f1: 0.7206, precision: 0.7188, recall: 0.7224
 * Macro Average: f1: 0.7217, precision: 0.7166, recall: 0.7285

Epoch 3/4, accuracy: 0.8517
 * Micro Average: f1: 0.7425, precision: 0.7424, recall: 0.7425
 * Macro Average: f1: 0.7432, precision: 0.7386, recall: 0.7499

Epoch 4/4, accuracy: 0.8528
 * Micro Average: f1: 0.7442, precision: 0.7436, recall: 0.7447
 * Macro Average: f1: 0.7450, precision: 0.7403, recall: 0.7516

 time for training and evaluating:171.0393693447113 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5955
  * recall: 0.7942
  * f1-score: 0.6806
  * support: 797.0000
 ORG:
  * precision: 0.6600
  * recall: 0.7464
  * f1-score: 0.7006
  * support: 2086.0000
 PER:
  * precision: 0.7303
  * recall: 0.7549
  * f1-score: 0.7424
  * support: 2199.0000
 micro avg:
  * precision: 0.6760
  * recall: 0.7576
  * f1-score: 0.7145
  * support: 5082.0000
 macro avg:
  * precision: 0.6619
  * recall: 0.7652
  * f1-score: 0.7079
  * support: 5082.0000
 weighted avg:
  * precision: 0.6803
  * recall: 0.7576
  * f1-score: 0.7155
  * support: 5082.0000
 accuracy:
  * 0.8624
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0736
 * Micro Average: f1: 0.0437, precision: 0.0697, recall: 0.0319
 * Macro Average: f1: 0.0323, precision: 0.1604, recall: 0.0257

Epoch 2/4, accuracy: 0.3082
 * Micro Average: f1: 0.0648, precision: 0.0817, recall: 0.0537
 * Macro Average: f1: 0.0538, precision: 0.3992, recall: 0.0544

Epoch 3/4, accuracy: 0.3983
 * Micro Average: f1: 0.0194, precision: 0.0477, recall: 0.0122
 * Macro Average: f1: 0.0175, precision: 0.0607, recall: 0.0135

Epoch 4/4, accuracy: 0.4297
 * Micro Average: f1: 0.0112, precision: 0.0400, recall: 0.0065
 * Macro Average: f1: 0.0106, precision: 0.0633, recall: 0.0074

 time for training and evaluating:60.65490007400513 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0065
  * recall: 0.0202
  * f1-score: 0.0098
  * support: 791.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2078.0000
 PER:
  * precision: 0.0682
  * recall: 0.0539
  * f1-score: 0.0602
  * support: 2209.0000
 micro avg:
  * precision: 0.0321
  * recall: 0.0266
  * f1-score: 0.0291
  * support: 5078.0000
 macro avg:
  * precision: 0.0249
  * recall: 0.0247
  * f1-score: 0.0233
  * support: 5078.0000
 weighted avg:
  * precision: 0.0307
  * recall: 0.0266
  * f1-score: 0.0277
  * support: 5078.0000
 accuracy:
  * 0.4765
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8088
 * Micro Average: f1: 0.6657, precision: 0.6475, recall: 0.6850
 * Macro Average: f1: 0.6633, precision: 0.6410, recall: 0.6894

Epoch 2/4, accuracy: 0.8428
 * Micro Average: f1: 0.7293, precision: 0.7244, recall: 0.7343
 * Macro Average: f1: 0.7297, precision: 0.7212, recall: 0.7400

Epoch 3/4, accuracy: 0.8521
 * Micro Average: f1: 0.7453, precision: 0.7460, recall: 0.7446
 * Macro Average: f1: 0.7461, precision: 0.7418, recall: 0.7529

Epoch 4/4, accuracy: 0.8554
 * Micro Average: f1: 0.7512, precision: 0.7513, recall: 0.7510
 * Macro Average: f1: 0.7518, precision: 0.7477, recall: 0.7580

 time for training and evaluating:171.23184990882874 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5933
  * recall: 0.8260
  * f1-score: 0.6906
  * support: 793.0000
 ORG:
  * precision: 0.6438
  * recall: 0.7555
  * f1-score: 0.6952
  * support: 2086.0000
 PER:
  * precision: 0.7439
  * recall: 0.7697
  * f1-score: 0.7566
  * support: 2219.0000
 micro avg:
  * precision: 0.6736
  * recall: 0.7727
  * f1-score: 0.7197
  * support: 5098.0000
 macro avg:
  * precision: 0.6603
  * recall: 0.7837
  * f1-score: 0.7141
  * support: 5098.0000
 weighted avg:
  * precision: 0.6795
  * recall: 0.7727
  * f1-score: 0.7212
  * support: 5098.0000
 accuracy:
  * 0.8577
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4829
 * Micro Average: f1: 0.0004, precision: 0.0625, recall: 0.0002
 * Macro Average: f1: 0.0005, precision: 0.3645, recall: 0.0002

Epoch 2/4, accuracy: 0.4836
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4828
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4838
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:60.238115072250366 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 792.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2097.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2223.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5112.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5112.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5112.0000
 accuracy:
  * 0.6658
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4829
 * Micro Average: f1: 0.0001, precision: 0.1000, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0370, recall: 0.0001

Epoch 2/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4824
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4831
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:170.65192365646362 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 785.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2093.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2201.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5079.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5079.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5079.0000
 accuracy:
  * 0.6666
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0599
 * Micro Average: f1: 0.0997, precision: 0.0690, recall: 0.1796
 * Macro Average: f1: 0.0431, precision: 0.0510, recall: 0.2592

Epoch 2/4, accuracy: 0.3105
 * Micro Average: f1: 0.0372, precision: 0.0422, recall: 0.0333
 * Macro Average: f1: 0.0231, precision: 0.0321, recall: 0.0473

Epoch 3/4, accuracy: 0.4441
 * Micro Average: f1: 0.0049, precision: 0.0193, recall: 0.0028
 * Macro Average: f1: 0.0050, precision: 0.0345, recall: 0.0039

Epoch 4/4, accuracy: 0.4639
 * Micro Average: f1: 0.0026, precision: 0.0206, recall: 0.0014
 * Macro Average: f1: 0.0031, precision: 0.0305, recall: 0.0020

 time for training and evaluating:60.46813941001892 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0013
  * recall: 0.0013
  * f1-score: 0.0013
  * support: 796.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2095.0000
 PER:
  * precision: 0.0312
  * recall: 0.0005
  * f1-score: 0.0009
  * support: 2215.0000
 micro avg:
  * precision: 0.0025
  * recall: 0.0004
  * f1-score: 0.0007
  * support: 5106.0000
 macro avg:
  * precision: 0.0108
  * recall: 0.0006
  * f1-score: 0.0007
  * support: 5106.0000
 weighted avg:
  * precision: 0.0138
  * recall: 0.0004
  * f1-score: 0.0006
  * support: 5106.0000
 accuracy:
  * 0.6299
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.4821
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4830
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4839
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:170.23294854164124 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 795.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2089.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2195.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5079.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5079.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 5079.0000
 accuracy:
  * 0.6668
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 32
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.0605
 * Micro Average: f1: 0.1057, precision: 0.0729, recall: 0.1918
 * Macro Average: f1: 0.0590, precision: 0.0577, recall: 0.2684

Epoch 2/4, accuracy: 0.0753
 * Micro Average: f1: 0.1075, precision: 0.0754, recall: 0.1874
 * Macro Average: f1: 0.0656, precision: 0.0606, recall: 0.2568

Epoch 3/4, accuracy: 0.2783
 * Micro Average: f1: 0.0776, precision: 0.0716, recall: 0.0847
 * Macro Average: f1: 0.0529, precision: 0.0627, recall: 0.1127

Epoch 4/4, accuracy: 0.3708
 * Micro Average: f1: 0.0538, precision: 0.0698, recall: 0.0438
 * Macro Average: f1: 0.0410, precision: 0.0624, recall: 0.0571

 time for training and evaluating:60.43154549598694 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0416
  * recall: 0.1355
  * f1-score: 0.0636
  * support: 797.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2089.0000
 PER:
  * precision: 0.0636
  * recall: 0.0254
  * f1-score: 0.0363
  * support: 2208.0000
 micro avg:
  * precision: 0.0471
  * recall: 0.0322
  * f1-score: 0.0383
  * support: 5094.0000
 macro avg:
  * precision: 0.0351
  * recall: 0.0536
  * f1-score: 0.0333
  * support: 5094.0000
 weighted avg:
  * precision: 0.0341
  * recall: 0.0322
  * f1-score: 0.0257
  * support: 5094.0000
 accuracy:
  * 0.5468
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8621
 * Micro Average: f1: 0.7604, precision: 0.7603, recall: 0.7604
 * Macro Average: f1: 0.7611, precision: 0.7566, recall: 0.7671

Epoch 2/4, accuracy: 0.8740
 * Micro Average: f1: 0.7840, precision: 0.7702, recall: 0.7983
 * Macro Average: f1: 0.7856, precision: 0.7727, recall: 0.7989

Epoch 3/4, accuracy: 0.8807
 * Micro Average: f1: 0.7938, precision: 0.7946, recall: 0.7929
 * Macro Average: f1: 0.7954, precision: 0.7916, recall: 0.8004

Epoch 4/4, accuracy: 0.8846
 * Micro Average: f1: 0.8017, precision: 0.7990, recall: 0.8045
 * Macro Average: f1: 0.8027, precision: 0.7968, recall: 0.8092

 time for training and evaluating:144.4198670387268 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.6759
  * recall: 0.8175
  * f1-score: 0.7400
  * support: 778.0000
 ORG:
  * precision: 0.6745
  * recall: 0.7725
  * f1-score: 0.7202
  * support: 2009.0000
 PER:
  * precision: 0.7422
  * recall: 0.8081
  * f1-score: 0.7738
  * support: 2131.0000
 micro avg:
  * precision: 0.7030
  * recall: 0.7950
  * f1-score: 0.7462
  * support: 4918.0000
 macro avg:
  * precision: 0.6975
  * recall: 0.7994
  * f1-score: 0.7446
  * support: 4918.0000
 weighted avg:
  * precision: 0.7041
  * recall: 0.7950
  * f1-score: 0.7465
  * support: 4918.0000
 accuracy:
  * 0.8756
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.2020
 * Micro Average: f1: 0.1186, precision: 0.0882, recall: 0.1811
 * Macro Average: f1: 0.1048, precision: 0.2477, recall: 0.2317

Epoch 2/4, accuracy: 0.4674
 * Micro Average: f1: 0.0292, precision: 0.1036, recall: 0.0170
 * Macro Average: f1: 0.0315, precision: 0.0929, recall: 0.0205

Epoch 3/4, accuracy: 0.4819
 * Micro Average: f1: 0.0039, precision: 0.1444, recall: 0.0020
 * Macro Average: f1: 0.0043, precision: 0.0919, recall: 0.0022

Epoch 4/4, accuracy: 0.4826
 * Micro Average: f1: 0.0025, precision: 0.1799, recall: 0.0012
 * Macro Average: f1: 0.0026, precision: 0.1036, recall: 0.0013

 time for training and evaluating:57.932732820510864 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0052
  * recall: 0.0077
  * f1-score: 0.0062
  * support: 778.0000
 ORG:
  * precision: 0.1136
  * recall: 0.0049
  * f1-score: 0.0094
  * support: 2029.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2139.0000
 micro avg:
  * precision: 0.0129
  * recall: 0.0032
  * f1-score: 0.0052
  * support: 4946.0000
 macro avg:
  * precision: 0.0396
  * recall: 0.0042
  * f1-score: 0.0052
  * support: 4946.0000
 weighted avg:
  * precision: 0.0474
  * recall: 0.0032
  * f1-score: 0.0049
  * support: 4946.0000
 accuracy:
  * 0.6143
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.8576
 * Micro Average: f1: 0.7515, precision: 0.7493, recall: 0.7536
 * Macro Average: f1: 0.7513, precision: 0.7445, recall: 0.7598

Epoch 2/4, accuracy: 0.8779
 * Micro Average: f1: 0.7870, precision: 0.7882, recall: 0.7858
 * Macro Average: f1: 0.7885, precision: 0.7854, recall: 0.7926

Epoch 3/4, accuracy: 0.8821
 * Micro Average: f1: 0.7974, precision: 0.7888, recall: 0.8062
 * Macro Average: f1: 0.7987, precision: 0.7884, recall: 0.8097

Epoch 4/4, accuracy: 0.8836
 * Micro Average: f1: 0.7986, precision: 0.7951, recall: 0.8021
 * Macro Average: f1: 0.7999, precision: 0.7943, recall: 0.8058

 time for training and evaluating:144.8305721282959 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.7041
  * recall: 0.8124
  * f1-score: 0.7544
  * support: 741.0000
 ORG:
  * precision: 0.6632
  * recall: 0.7868
  * f1-score: 0.7197
  * support: 2012.0000
 PER:
  * precision: 0.7610
  * recall: 0.7988
  * f1-score: 0.7794
  * support: 2152.0000
 micro avg:
  * precision: 0.7097
  * recall: 0.7959
  * f1-score: 0.7503
  * support: 4905.0000
 macro avg:
  * precision: 0.7094
  * recall: 0.7993
  * f1-score: 0.7512
  * support: 4905.0000
 weighted avg:
  * precision: 0.7123
  * recall: 0.7959
  * f1-score: 0.7511
  * support: 4905.0000
 accuracy:
  * 0.8767
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.1
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4835
 * Micro Average: f1: 0.0001, precision: 0.5000, recall: 0.0001
 * Macro Average: f1: 0.0001, precision: 0.1667, recall: 0.0001

Epoch 2/4, accuracy: 0.4834
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4835
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4833
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:57.642621755599976 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 749.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2035.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2154.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 4938.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 4938.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 4938.0000
 accuracy:
  * 0.6669
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7519
 * Micro Average: f1: 0.5716, precision: 0.5440, recall: 0.6020
 * Macro Average: f1: 0.5689, precision: 0.5410, recall: 0.5998

Epoch 2/4, accuracy: 0.8228
 * Micro Average: f1: 0.6928, precision: 0.6863, recall: 0.6994
 * Macro Average: f1: 0.6924, precision: 0.6822, recall: 0.7050

Epoch 3/4, accuracy: 0.8385
 * Micro Average: f1: 0.7209, precision: 0.7170, recall: 0.7249
 * Macro Average: f1: 0.7209, precision: 0.7133, recall: 0.7306

Epoch 4/4, accuracy: 0.8403
 * Micro Average: f1: 0.7212, precision: 0.7215, recall: 0.7210
 * Macro Average: f1: 0.7209, precision: 0.7177, recall: 0.7274

 time for training and evaluating:144.53585195541382 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5372
  * recall: 0.7883
  * f1-score: 0.6389
  * support: 770.0000
 ORG:
  * precision: 0.6510
  * recall: 0.7180
  * f1-score: 0.6829
  * support: 2032.0000
 PER:
  * precision: 0.7011
  * recall: 0.7656
  * f1-score: 0.7319
  * support: 2120.0000
 micro avg:
  * precision: 0.6488
  * recall: 0.7495
  * f1-score: 0.6955
  * support: 4922.0000
 macro avg:
  * precision: 0.6298
  * recall: 0.7573
  * f1-score: 0.6846
  * support: 4922.0000
 weighted avg:
  * precision: 0.6548
  * recall: 0.7495
  * f1-score: 0.6971
  * support: 4922.0000
 accuracy:
  * 0.8512
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1300
 * Micro Average: f1: 0.1987, precision: 0.1368, recall: 0.3635
 * Macro Average: f1: 0.0781, precision: 0.0456, recall: 0.2713

Epoch 2/4, accuracy: 0.1296
 * Micro Average: f1: 0.1983, precision: 0.1364, recall: 0.3633
 * Macro Average: f1: 0.0779, precision: 0.0455, recall: 0.2713

Epoch 3/4, accuracy: 0.1295
 * Micro Average: f1: 0.1982, precision: 0.1363, recall: 0.3630
 * Macro Average: f1: 0.0778, precision: 0.0454, recall: 0.2709

Epoch 4/4, accuracy: 0.1295
 * Micro Average: f1: 0.1980, precision: 0.1363, recall: 0.3622
 * Macro Average: f1: 0.0778, precision: 0.0454, recall: 0.2709

 time for training and evaluating:58.88597297668457 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 772.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2037.0000
 PER:
  * precision: 0.0948
  * recall: 0.8669
  * f1-score: 0.1709
  * support: 2134.0000
 micro avg:
  * precision: 0.0948
  * recall: 0.3743
  * f1-score: 0.1513
  * support: 4943.0000
 macro avg:
  * precision: 0.0316
  * recall: 0.2890
  * f1-score: 0.0570
  * support: 4943.0000
 weighted avg:
  * precision: 0.0409
  * recall: 0.3743
  * f1-score: 0.0738
  * support: 4943.0000
 accuracy:
  * 0.0899
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.7453
 * Micro Average: f1: 0.5612, precision: 0.5338, recall: 0.5916
 * Macro Average: f1: 0.5586, precision: 0.5368, recall: 0.5866

Epoch 2/4, accuracy: 0.8180
 * Micro Average: f1: 0.6838, precision: 0.6737, recall: 0.6942
 * Macro Average: f1: 0.6822, precision: 0.6704, recall: 0.6964

Epoch 3/4, accuracy: 0.8352
 * Micro Average: f1: 0.7142, precision: 0.7102, recall: 0.7183
 * Macro Average: f1: 0.7137, precision: 0.7058, recall: 0.7241

Epoch 4/4, accuracy: 0.8392
 * Micro Average: f1: 0.7210, precision: 0.7175, recall: 0.7246
 * Macro Average: f1: 0.7202, precision: 0.7141, recall: 0.7289

 time for training and evaluating:144.44792795181274 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.5636
  * recall: 0.7979
  * f1-score: 0.6606
  * support: 772.0000
 ORG:
  * precision: 0.6273
  * recall: 0.7092
  * f1-score: 0.6657
  * support: 2012.0000
 PER:
  * precision: 0.7001
  * recall: 0.7519
  * f1-score: 0.7251
  * support: 2152.0000
 micro avg:
  * precision: 0.6447
  * recall: 0.7417
  * f1-score: 0.6898
  * support: 4936.0000
 macro avg:
  * precision: 0.6303
  * recall: 0.7530
  * f1-score: 0.6838
  * support: 4936.0000
 weighted avg:
  * precision: 0.6491
  * recall: 0.7417
  * f1-score: 0.6908
  * support: 4936.0000
 accuracy:
  * 0.8471
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.3
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1059
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 2/4, accuracy: 0.1061
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.1252
 * Micro Average: f1: 0.0020, precision: 0.0116, recall: 0.0011
 * Macro Average: f1: 0.0014, precision: 0.0039, recall: 0.0008

Epoch 4/4, accuracy: 0.1513
 * Micro Average: f1: 0.0059, precision: 0.0181, recall: 0.0035
 * Macro Average: f1: 0.0037, precision: 0.0060, recall: 0.0026

 time for training and evaluating:58.125609159469604 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 767.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2012.0000
 PER:
  * precision: 0.0118
  * recall: 0.0056
  * f1-score: 0.0076
  * support: 2156.0000
 micro avg:
  * precision: 0.0118
  * recall: 0.0024
  * f1-score: 0.0040
  * support: 4935.0000
 macro avg:
  * precision: 0.0039
  * recall: 0.0019
  * f1-score: 0.0025
  * support: 4935.0000
 weighted avg:
  * precision: 0.0052
  * recall: 0.0024
  * f1-score: 0.0033
  * support: 4935.0000
 accuracy:
  * 0.0826
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4834
 * Micro Average: f1: 0.0001, precision: 1.0000, recall: 0.0001
 * Macro Average: f1: 0.0001, precision: 0.3333, recall: 0.0000

Epoch 2/4, accuracy: 0.4829
 * Micro Average: f1: 0.0007, precision: 0.3684, recall: 0.0003
 * Macro Average: f1: 0.0005, precision: 0.1228, recall: 0.0003

Epoch 3/4, accuracy: 0.4834
 * Micro Average: f1: 0.0006, precision: 0.5000, recall: 0.0003
 * Macro Average: f1: 0.0004, precision: 0.1667, recall: 0.0002

Epoch 4/4, accuracy: 0.4836
 * Micro Average: f1: 0.0006, precision: 0.2308, recall: 0.0003
 * Macro Average: f1: 0.0004, precision: 0.0769, recall: 0.0002

 time for training and evaluating:144.00912952423096 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 777.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 1974.0000
 PER:
  * precision: 0.4000
  * recall: 0.0019
  * f1-score: 0.0037
  * support: 2124.0000
 micro avg:
  * precision: 0.4000
  * recall: 0.0008
  * f1-score: 0.0016
  * support: 4875.0000
 macro avg:
  * precision: 0.1333
  * recall: 0.0006
  * f1-score: 0.0012
  * support: 4875.0000
 weighted avg:
  * precision: 0.1743
  * recall: 0.0008
  * f1-score: 0.0016
  * support: 4875.0000
 accuracy:
  * 0.6689
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: GELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1072
 * Micro Average: f1: 0.0007, precision: 0.0034, recall: 0.0004
 * Macro Average: f1: 0.0006, precision: 0.0011, recall: 0.0004

Epoch 2/4, accuracy: 0.2328
 * Micro Average: f1: 0.0300, precision: 0.0482, recall: 0.0218
 * Macro Average: f1: 0.0187, precision: 0.0161, recall: 0.0225

Epoch 3/4, accuracy: 0.3379
 * Micro Average: f1: 0.0541, precision: 0.0772, recall: 0.0416
 * Macro Average: f1: 0.0322, precision: 0.0257, recall: 0.0429

Epoch 4/4, accuracy: 0.3668
 * Micro Average: f1: 0.0517, precision: 0.0798, recall: 0.0382
 * Macro Average: f1: 0.0318, precision: 0.1933, recall: 0.0394

 time for training and evaluating:58.14944243431091 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 756.0000
 ORG:
  * precision: 0.0698
  * recall: 0.1264
  * f1-score: 0.0900
  * support: 2025.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2141.0000
 micro avg:
  * precision: 0.0698
  * recall: 0.0520
  * f1-score: 0.0596
  * support: 4922.0000
 macro avg:
  * precision: 0.0233
  * recall: 0.0421
  * f1-score: 0.0300
  * support: 4922.0000
 weighted avg:
  * precision: 0.0287
  * recall: 0.0520
  * f1-score: 0.0370
  * support: 4922.0000
 accuracy:
  * 0.4782
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: False
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.4830
 * Micro Average: f1: 0.0010, precision: 0.2273, recall: 0.0005
 * Macro Average: f1: 0.0010, precision: 0.1843, recall: 0.0005

Epoch 2/4, accuracy: 0.4829
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 3/4, accuracy: 0.4832
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

Epoch 4/4, accuracy: 0.4826
 * Micro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000
 * Macro Average: f1: 0.0000, precision: 0.0000, recall: 0.0000

 time for training and evaluating:144.30825686454773 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 779.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2000.0000
 PER:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2119.0000
 micro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 4898.0000
 macro avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 4898.0000
 weighted avg:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 4898.0000
 accuracy:
  * 0.6681
________________________________________




====================================================================================================
Training model: xlm-roberta-base
 * 4 epochs
 * learning rate is 2e-05
 * batch size is 64
 * frozen weights: True
 * device is on cuda * warmup steps: 50
 * activation: RELU
 * languages: dev-af.tsv.gz
----------------------------------------------------------------------------------------------------
 * dropout: 0.5
----------------------------------------------------------------------------------------------------

Epoch 1/4, accuracy: 0.1053
 * Micro Average: f1: 0.0001, precision: 0.0098, recall: 0.0001
 * Macro Average: f1: 0.0001, precision: 0.0033, recall: 0.0000

Epoch 2/4, accuracy: 0.1059
 * Micro Average: f1: 0.0001, precision: 0.0108, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0036, recall: 0.0000

Epoch 3/4, accuracy: 0.1061
 * Micro Average: f1: 0.0001, precision: 0.0109, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0036, recall: 0.0000

Epoch 4/4, accuracy: 0.1060
 * Micro Average: f1: 0.0001, precision: 0.0108, recall: 0.0000
 * Macro Average: f1: 0.0001, precision: 0.0036, recall: 0.0000

 time for training and evaluating:57.80190920829773 for train language combination:train-en.tsv.gz and test language: dev-af.tsv.gz
Classification Report on test set:

________________________________________
 LOC:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 751.0000
 ORG:
  * precision: 0.0000
  * recall: 0.0000
  * f1-score: 0.0000
  * support: 2005.0000
 PER:
  * precision: 0.0097
  * recall: 0.0014
  * f1-score: 0.0024
  * support: 2154.0000
 micro avg:
  * precision: 0.0097
  * recall: 0.0006
  * f1-score: 0.0011
  * support: 4910.0000
 macro avg:
  * precision: 0.0032
  * recall: 0.0005
  * f1-score: 0.0008
  * support: 4910.0000
 weighted avg:
  * precision: 0.0043
  * recall: 0.0006
  * f1-score: 0.0011
  * support: 4910.0000
 accuracy:
  * 0.0497
________________________________________



Task and CPU usage stats:
JobID           JobName  AllocCPUS   NTasks     MinCPU MinCPUTask     AveCPU    Elapsed ExitCode 
------------ ---------- ---------- -------- ---------- ---------- ---------- ---------- -------- 
463266           in5550          8                                             06:25:04      0:0 
463266.batch      batch          8        1   06:24:20          0   06:24:20   06:25:04      0:0 
463266.exte+     extern          8        1   00:00:00          0   00:00:00   06:25:04      0:0 

Memory usage stats:
JobID            MaxRSS MaxRSSTask     AveRSS MaxPages   MaxPagesTask   AvePages 
------------ ---------- ---------- ---------- -------- -------------- ---------- 
463266                                                                           
463266.batch   3543508K          0   3543508K        0              0          0 
463266.exte+          0          0          0        0              0          0 

Disk usage stats:
JobID         MaxDiskRead MaxDiskReadTask    AveDiskRead MaxDiskWrite MaxDiskWriteTask   AveDiskWrite 
------------ ------------ --------------- -------------- ------------ ---------------- -------------- 
463266                                                                                                
463266.batch   199873.89M               0     199873.89M        1.12M                0          1.12M 
463266.exte+        0.01M               0          0.01M        0.00M                0          0.00M 

Job 463266 completed at Thu Mar 14 11:01:11 CET 2024
