{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ea6dbc-24c0-4683-ad49-0f7304e29468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "# set TOKENIZERS_PARALLELISM so that it doesn't annoy us\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description='Train a model on the SNLI dataset')\n",
    "    parser.add_argument('--model', type=str, default='/fp/homes01/u01/ec-rasyed/2024/labs/06/mand2/bert-base-multilingual-cased', help='The model to use')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='The batch size')\n",
    "    parser.add_argument('--epochs', type=int, default=2, help='The number of epochs to train')\n",
    "    parser.add_argument('--lr', type=float, default=1e-4, help='The learning rate')\n",
    "    parser.add_argument('--seed', type=int, default=42, help='The random seed')\n",
    "    parser.add_argument('--warmup_steps', type=int, default=50, help='The number of warmup steps')\n",
    "    parser.add_argument('--gradient_clipping', type=float, default=10.0, help='The gradient clipping value')\n",
    "    return parser.parse_args([])\n",
    "\n",
    "args = parse_arguments()\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    args.model,\n",
    "    cache_dir=\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3775d9ef-af17-4563-b72b-55145025a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from operator import itemgetter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import itertools\n",
    "from itertools import chain\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class datacollector:\n",
    "    def __init__(self, name_of_file):\n",
    "        self.name_of_file = name_of_file\n",
    "\n",
    "    def __call__(self,train:bool):\n",
    "        if not isinstance(train, bool):\n",
    "            raise TypeError(\"train parameter must be a boolean\")\n",
    "            \n",
    "        current_directory = os.getcwd()\n",
    "        paths_to_print = self.import_func([self.name_of_file], current_directory)\n",
    "        print(paths_to_print)\n",
    "        doc = self.read_file_to_df(paths_to_print)[0]\n",
    "\n",
    "        train_text_col = doc.iloc[:, 0].to_string(index=False)\n",
    "        train_text = ' '.join(train_text_col.split())\n",
    "\n",
    "        sent_tokenizing = sent_tokenize(train_text)\n",
    "\n",
    "        train_lab_col = doc.iloc[:, 1].to_string(index=False)\n",
    "        train_labels = ' '.join(train_lab_col.split())\n",
    "\n",
    "        train_text_list = train_text_col.split()\n",
    "        train_label_list = train_lab_col.split()\n",
    "        text_sent,label_sent=self.tokenize_text_and_labels(train_text_list, train_label_list)\n",
    " \n",
    "        self.all_labels = list(itertools.chain.from_iterable(label_sent))\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.fit(self.all_labels)\n",
    "        \n",
    "        numerical_NER = [list(label_encoder.transform(sublist_list)) for sublist_list in label_sent]\n",
    "       \n",
    "\n",
    "        numeric_flatt_unique=list(np.unique(np.array(list(chain.from_iterable(numerical_NER)))))\n",
    "        all_labels_flatt_unique=list(np.unique(np.array(self.all_labels)))\n",
    " \n",
    "        data = {\"tokens\": text_sent, \"ner_tags\": numerical_NER}\n",
    "        # Create a dataset from the Pandas DataFrame\n",
    "        data = Dataset.from_dict(data)\n",
    "\n",
    "        tokenized_data = data.map(self.tokenize_and_adjust_labels, batched=True)\n",
    "        if train==True:\n",
    "             \n",
    "            text_sent_train,text_sent_val,train_label,val_label=train_test_split(text_sent, label_sent,test_size=0.2)\n",
    "\n",
    "            train_numerical_NER=self.numeric_target(train_label)\n",
    "            val_numerical_NER=self.numeric_target(val_label)\n",
    "           \n",
    "            data_train=data = {\"tokens\": text_sent_train, \"ner_tags\": train_numerical_NER[0]}\n",
    "            data_train = Dataset.from_dict(data_train)\n",
    "            data_val = {\"tokens\": text_sent_val, \"ner_tags\": val_numerical_NER[0]}\n",
    "            data_val = Dataset.from_dict(data_val)\n",
    "            tokenized_train_data=data_train.map(self.tokenize_and_adjust_labels, batched=True)\n",
    "            tokenized_eval_data=data_val.map(self.tokenize_and_adjust_labels, batched=True)\n",
    "            return tokenized_train_data,tokenized_eval_data,train_numerical_NER[1],val_numerical_NER[1]\n",
    "        return tokenized_data,all_labels_flatt_unique\n",
    "    \n",
    "    def numeric_target(self,labels):\n",
    "        all_labels = list(itertools.chain.from_iterable(labels))\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.fit(all_labels)\n",
    "        \n",
    "        numerical_NER = [list(label_encoder.transform(sublist_list)) for sublist_list in labels]\n",
    "       \n",
    "\n",
    "        numeric_flatt_unique=list(np.unique(np.array(list(chain.from_iterable(numerical_NER)))))\n",
    "        all_labels_flatt_unique=list(np.unique(np.array(all_labels)))\n",
    "        return numerical_NER,all_labels_flatt_unique\n",
    "    \n",
    "    def find_substring_index(self, substring_list, string_list):\n",
    "        indexes = []\n",
    "        for substring in substring_list:\n",
    "            try:\n",
    "                index = next(i for i, string in enumerate(string_list) if substring in string)\n",
    "                indexes.append(index)\n",
    "            except StopIteration:\n",
    "                indexes.append(-1)\n",
    "        return indexes\n",
    "\n",
    "    def import_func(self, sub_string_list, current_dir):\n",
    "        dir_path = current_dir\n",
    "\n",
    "        # Construct the base path for the data directory\n",
    "        dir_path = os.path.join(dir_path, \"data\")\n",
    "\n",
    "        files = os.listdir(dir_path)\n",
    "\n",
    "        list_paths = [os.path.join(dir_path, files[i]) for i in range(len(files))]\n",
    "        match_on = self.find_substring_index(sub_string_list, list_paths)\n",
    "\n",
    "        path_get = itemgetter(*match_on)\n",
    "        get_paths = path_get(list_paths)\n",
    "        return get_paths\n",
    "\n",
    "    def read_file_to_df(self, path_in_list):\n",
    "        if not path_in_list:\n",
    "            return []\n",
    "        \n",
    "        df_list = []\n",
    "        path_in_list=[path_in_list]\n",
    "        for path_in in path_in_list:\n",
    "            \n",
    "            with open(path_in, \"rb\") as f:\n",
    "                \n",
    "                df = pd.read_csv(f.name, sep=\"\\t\", header=0)\n",
    "                df_list.append(df)\n",
    "            \n",
    "        return df_list\n",
    "\n",
    "    def tokenize_text_and_labels(self,text_list, labels_list):\n",
    "        \"\"\"\n",
    "        Tokenize the input text into sentences and preserve the one-to-one correspondence\n",
    "        between tokens and labels.\n",
    "    \n",
    "        Args:\n",
    "        - text (str): The input text to tokenize.\n",
    "        - labels (str): The corresponding labels for each word in the text.\n",
    "    \n",
    "        Returns:\n",
    "        - tokenized_texts (list): The tokenized sentences.\n",
    "        - tokenized_labels (list): The corresponding labels for each token.\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "        # Initialize lists to store tokenized text and labels\n",
    "        tokenize_nested_text=[]\n",
    "        tokenize_nested_label=[]\n",
    "        tokenized_texts = []\n",
    "        tokenized_labels = [] \n",
    "        # Keep track of the current index in the tokenized text\n",
    "        current_index = 0\n",
    "        len_text_list=len(text_list)\n",
    "        count_for=0\n",
    "        # Iterate through sentences\n",
    "        for i,word in enumerate(text_list):\n",
    "            count_for+=1\n",
    "            \n",
    "                \n",
    "            \n",
    "            if current_index<=10:\n",
    "                \n",
    "                tokenized_texts.append(word)\n",
    "                \n",
    "                if (\",\" in word or \".\" in word) and len(word)==1:\n",
    "                   \n",
    "                # Append the corresponding label to the tokenized labels\n",
    "                   tokenized_labels.append(\"O\")\n",
    "                   current_index=current_index \n",
    "                else:\n",
    "                    tokenized_labels.append(labels_list[i])\n",
    "                    current_index+=1\n",
    "                \n",
    "            if current_index>10:\n",
    "                current_index=0\n",
    "                tokenized_texts = []\n",
    "                tokenized_labels = [] \n",
    "            \n",
    "            if current_index==10:\n",
    "                tokenize_nested_text.append(tokenized_texts)\n",
    "                tokenize_nested_label.append(tokenized_labels)\n",
    "            \n",
    "            if count_for==len_text_list:\n",
    "               break\n",
    "           \n",
    "            \n",
    "        return tokenize_nested_text, tokenize_nested_label\n",
    "\n",
    "    def tokenize_and_adjust_labels(self,samples_per_split):\n",
    "      tokenized_samples = tokenizer.batch_encode_plus(samples_per_split[\"tokens\"],return_tensors='pt', padding=True, truncation=True ,is_split_into_words=True)\n",
    "     \n",
    "      adjusted_labels = []\n",
    "      print(len(tokenized_samples[\"input_ids\"]))\n",
    "      for k in range(0, len(tokenized_samples[\"input_ids\"])):\n",
    "        prev_wid = -1\n",
    "        word_ids_list = tokenized_samples.word_ids(batch_index=k)\n",
    "        existing_label_ids = samples_per_split[\"ner_tags\"][k]\n",
    "      \n",
    "          \n",
    "        j = -1\n",
    "        adjusted_label_ids = []\n",
    "       \n",
    "        for wid in word_ids_list:\n",
    "          if(wid is None):\n",
    "            adjusted_label_ids.append(-100)\n",
    "          elif(wid!=prev_wid):\n",
    "            j = j + 1\n",
    "            adjusted_label_ids.append(existing_label_ids[j])\n",
    "            prev_wid = wid\n",
    "          else:\n",
    "            label_name = self.all_labels[existing_label_ids[j]]\n",
    "            adjusted_label_ids.append(existing_label_ids[j])\n",
    "            \n",
    "        adjusted_labels.append(adjusted_label_ids)\n",
    "      tokenized_samples[\"labels\"] = adjusted_labels\n",
    "      return tokenized_samples\n",
    "\n",
    "\n",
    "#data_collector = datacollector(\"train-en.tsv.gz\")\n",
    "\n",
    "\n",
    "#train_set=data_collector(train=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53eac6e6-f3b8-4e8e-a887-86a32fbf2f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class util_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label_vocab=None):\n",
    "\n",
    "\n",
    "        self.data=data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class CollateFunctor:\n",
    "    def __init__(self, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        input_ids = []\n",
    "        token_type_ids = []\n",
    "        attention_mask = []\n",
    "        labels = []\n",
    "        \n",
    "        # Iterate over each sample in the batch\n",
    "        for sample in batch:\n",
    "            # Pad or truncate input_ids, token_type_ids, attention_mask\n",
    "            input_ids.append(torch.tensor(sample[\"input_ids\"]))\n",
    "            token_type_ids.append(torch.tensor(sample[\"token_type_ids\"]))\n",
    "            attention_mask.append(torch.tensor(sample[\"attention_mask\"]))\n",
    "            # Add padding to labels\n",
    "           \n",
    "            labels.append(torch.tensor(sample[\"labels\"] +  (len( input_ids)-len(sample[\"labels\"]))*[-100] ))\n",
    "        \n",
    "        # Pad sequences to ensure uniform length\n",
    "        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        token_type_ids = pad_sequence(token_type_ids, batch_first=True, padding_value=0,)\n",
    "        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "        labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "        labels=torch.stack([term.squeeze(0) for term in labels])\n",
    "        inputs = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        #print(inputs)\n",
    "        #print(self.tokenizer.pad_token_id)\n",
    "        #inputs['labels'] = torch.tensor(labels)\n",
    "         \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e20d53-dee6-4552-8933-73f71527e068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fp/homes01/u01/ec-rasyed/2024/labs/06/mand2/assignment2/IN5550-mandatory-2/data/train-en.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2646aa4281184d0a8f9a5153619ae934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "518\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c576a09cfd44366aefb4a9141f867b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae49a814fcca45a9b74a218fbf6cfbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "904\n",
      "/fp/homes01/u01/ec-rasyed/2024/labs/06/mand2/assignment2/IN5550-mandatory-2/data/dev-en.tsv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d794dbbc761432f9a5e339a69c01332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "334\n",
      "input_ids:\ttorch.Size([32, 48])\ttorch.int64\n",
      "token_type_ids:\ttorch.Size([32, 48])\ttorch.int64\n",
      "attention_mask:\ttorch.Size([32, 48])\ttorch.int64\n",
      "labels:\ttorch.Size([32, 48])\ttorch.int64\n",
      "Input subwords: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 22:30:11.242194: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-06 22:30:11.242255: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-06 22:30:11.243287: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-06 22:30:11.249740: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-06 22:30:15.045010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`[CLS]` `Sf` `##ânt` `##u` `Gheorghe` `[UNK]` `B` `##ă` `##ile` `Tu` `##ș` `##nad` `[UNK]` `Mi` `##er` `##cure` `##a` `-` `Ci` `##uc` `[UNK]` `Top` `##li` `##ța` `IS` `##U` `JG` `##P` `[SEP]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` `[PAD]` "
     ]
    }
   ],
   "source": [
    "#train_set = util_Dataset(train_set)\n",
    "\n",
    "data_collector_train_val = datacollector(\"train-en.tsv.gz\")\n",
    "train_set,val_set,label_unique_train,label_unique_val=data_collector_train_val(train=True)\n",
    "train_set = util_Dataset(train_set)\n",
    "val_set = util_Dataset(val_set)\n",
    "\n",
    "data_collector_test = datacollector(\"dev-en.tsv.gz\")\n",
    "test_set,label_unique_test=data_collector_test(train=False)\n",
    "test_set = util_Dataset(test_set)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "train_set, batch_size=args.batch_size, shuffle=True, drop_last=True,\n",
    "collate_fn=CollateFunctor(tokenizer, 40)\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "val_set, batch_size=args.batch_size, shuffle=True, drop_last=True,\n",
    "collate_fn=CollateFunctor(tokenizer, 40)\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "test_set, batch_size=args.batch_size, shuffle=True, drop_last=True,\n",
    "collate_fn=CollateFunctor(tokenizer, 40)\n",
    ")\n",
    "# Peek at the first batch\n",
    "for batch in train_loader:\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key}:\\t{value.shape}\\t{value.dtype}\")\n",
    "    break\t\n",
    "\n",
    "\n",
    "print(\"Input subwords: \", end=\"\")\n",
    "for subword_id in batch['input_ids'][0]:\n",
    "    print('`' + tokenizer.decode(subword_id.item()) + '`', end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065afb32-11ac-4b4d-8ed0-992803b48b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fp/projects01/ec30/software/easybuild/software/nlpl-pytorch/2.1.2-foss-2022b-cuda-12.0.0-Python-3.10.8/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at /fp/homes01/u01/ec-rasyed/2024/labs/06/mand2/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import  TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    args.model,\n",
    "    cache_dir=\"./cache\",\n",
    "    trust_remote_code=True,\n",
    "    num_labels=7\n",
    ")\n",
    "item_list=[]\n",
    "def train_epoch(model, train_loader, optimizer, lr_scheduler, device):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        #batch = batch.to(device)\n",
    "        #.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #print(batch[\"labels\"])\n",
    "        # forward pass\n",
    "        model_out = model(**batch)\n",
    "        #print(model_out.logits)\n",
    "        \n",
    "        \n",
    "        loss = model_out.loss\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        lr_scheduler.step()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        item_list.append(loss.item())\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_metrics(model,data,all_labels_flatt_unique):\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "    total_correct, total_samples = 0, 0\n",
    "    for batch in tqdm(data):\n",
    "        #batch = batch.to(device)\n",
    "        #.to(device)\n",
    "        outputs = model(**batch)\n",
    "        predictions=outputs.logits\n",
    "        labels=batch[\"labels\"]\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        filtered_predictions = []\n",
    "        filtered_labels = []\n",
    "        for pred_seq, label_seq in zip(predictions, labels):\n",
    "            pred_seq_filtered = []\n",
    "            label_seq_filtered = []\n",
    "            for pred, label in zip(pred_seq, label_seq):\n",
    "                if label != -100:\n",
    "                    pred_seq_filtered.append(pred)\n",
    "                    label_seq_filtered.append(label)\n",
    "            filtered_predictions.append(pred_seq_filtered)\n",
    "            filtered_labels.append(label_seq_filtered)\n",
    "\n",
    "           \n",
    "        for pred_seq, label_seq in zip(filtered_predictions, filtered_labels):\n",
    "            pred_labels = [all_labels_flatt_unique[pred] for pred in pred_seq]\n",
    "            true_labels = [all_labels_flatt_unique[label] for label in label_seq]\n",
    "            all_predictions.append(pred_labels)\n",
    "            all_labels.append(true_labels)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(all_labels, all_predictions,output_dict=True)\n",
    "    #print(all_labels[1:100])\n",
    "   # print(all_predictions[1:100])\n",
    "    return report\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58af8bc-30c5-4278-bf53-86348d5034ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at /fp/homes01/u01/ec-rasyed/2024/labs/06/mand2/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import  TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    args.model,\n",
    "    cache_dir=\"./cache\",\n",
    "    trust_remote_code=True,\n",
    "    num_labels=7\n",
    ").to(device)\n",
    "loss_list=[]\n",
    "def train_epoch(model, train_loader, optimizer, lr_scheduler, device):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        #batch = batch.to(device)\n",
    "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "        #inputs=batch\n",
    "        #.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #print(batch[\"labels\"])\n",
    "        # forward pass\n",
    "        \n",
    "        model_out = model(**inputs)\n",
    "        #print(model_out.logits)\n",
    "        \n",
    "        \n",
    "        loss = model_out.loss\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        lr_scheduler.step()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "        loss_list.append(loss.item())\n",
    " \n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_metrics(model,data,all_labels_flatt_unique):\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "    total_correct, total_samples = 0, 0\n",
    "    for batch in tqdm(data):\n",
    "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "        #.to(device)\n",
    "        #inputs=batch\n",
    "        outputs = model(**inputs)\n",
    "        predictions=outputs.logits.to(\"cpu\")\n",
    "        #predictions=predictions.detach()\n",
    "\n",
    "        labels=batch[\"labels\"]\n",
    "        #print(labels)\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "        #print(predictions)\n",
    "     \n",
    "        filtered_predictions = []\n",
    "        filtered_labels = []\n",
    "        for pred_seq, label_seq in zip(predictions, labels):\n",
    "            pred_seq_filtered = []\n",
    "            label_seq_filtered = []\n",
    "            for pred, label in zip(pred_seq, label_seq):\n",
    "                if label != -100:\n",
    "                    pred_seq_filtered.append(pred)\n",
    "                    label_seq_filtered.append(label)\n",
    "            filtered_predictions.append(pred_seq_filtered)\n",
    "            filtered_labels.append(label_seq_filtered)\n",
    "\n",
    "           \n",
    "        for pred_seq, label_seq in zip(filtered_predictions, filtered_labels):\n",
    "            pred_labels = [all_labels_flatt_unique[pred] for pred in pred_seq]\n",
    "            true_labels = [all_labels_flatt_unique[label] for label in label_seq]\n",
    "            all_predictions.append(pred_labels)\n",
    "            all_labels.append(true_labels)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(all_labels, all_predictions,output_dict=True)\n",
    "    #print(all_labels[1:100])\n",
    "   # print(all_predictions[1:100])\n",
    "    return report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31155b4-8d51-414f-a4c1-8e828b7ed0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 362/362 [00:28<00:00, 12.88it/s, loss=0.347, lr=5.37e-5]\n",
      "100%|██████████| 90/90 [00:03<00:00, 29.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC': {'precision': 0.8031014078759436, 'recall': 0.8665785997357992, 'f1-score': 0.8336333792227046, 'support': 4542}, 'ORG': {'precision': 0.675097862089732, 'recall': 0.6142465753424657, 'f1-score': 0.6432362645244584, 'support': 3650}, 'PER': {'precision': 0.8140262993112085, 'recall': 0.8248730964467005, 'f1-score': 0.8194138039710054, 'support': 3152}, 'micro avg': {'precision': 0.7689208128941836, 'recall': 0.7738011283497884, 'f1-score': 0.771353251318102, 'support': 11344}, 'macro avg': {'precision': 0.7640751897589614, 'recall': 0.7685660905083219, 'f1-score': 0.765427815906056, 'support': 11344}, 'weighted avg': {'precision': 0.764951047834008, 'recall': 0.7738011283497884, 'f1-score': 0.7684209700335336, 'support': 11344}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 362/362 [00:27<00:00, 13.03it/s, loss=0.404, lr=0]       \n",
      "100%|██████████| 90/90 [00:03<00:00, 29.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC': {'precision': 0.8380266779589244, 'recall': 0.873923603444469, 'f1-score': 0.8555987894509295, 'support': 4529}, 'ORG': {'precision': 0.7057268722466961, 'recall': 0.6639955788891959, 'f1-score': 0.6842255125284737, 'support': 3619}, 'PER': {'precision': 0.8124072425051945, 'recall': 0.8683375634517766, 'f1-score': 0.8394418034043858, 'support': 3152}, 'micro avg': {'precision': 0.7913368704879534, 'recall': 0.8051327433628318, 'f1-score': 0.7981751984910296, 'support': 11300}, 'macro avg': {'precision': 0.7853869309036049, 'recall': 0.8020855819284805, 'f1-score': 0.7930887017945963, 'support': 11300}, 'weighted avg': {'precision': 0.7885093808418704, 'recall': 0.8051327433628318, 'f1-score': 0.7962070452738433, 'support': 11300}}\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=args.lr\n",
    ")\n",
    "lr_scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=len(train_loader) * args.epochs\n",
    ")\n",
    "\n",
    "f1_micro_avg=[]\n",
    "f1_macro_avg=[]\n",
    "f1_weighted_avg=[]\n",
    "for epoch in range(args.epochs):\n",
    "    train_epoch(model, train_loader, optimizer, lr_scheduler, device)\n",
    "    eval_metric_val=compute_metrics(model,val_loader,label_unique_val)\n",
    "    f1_micro_avg.append(eval_metric_val[\"micro avg\"]['f1-score'])\n",
    "    f1_macro_avg.append(eval_metric_val[\"macro avg\"]['f1-score'])\n",
    "    f1_weighted_avg.append(eval_metric_val[\"weighted avg\"]['f1-score'])\n",
    "    print(eval_metric_val)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391a54ec-26c5-4cc8-a08d-71ffe6da3e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:09<00:00, 25.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC': {'precision': 0.8262187628021302, 'recall': 0.860629854058206, 'f1-score': 0.8430733216286264, 'support': 11717}, 'ORG': {'precision': 0.6806869961444094, 'recall': 0.6267885960193652, 'f1-score': 0.6526268623277697, 'support': 9295}, 'PER': {'precision': 0.8050065876152833, 'recall': 0.8535687071374143, 'f1-score': 0.8285767120754485, 'support': 7874}, 'micro avg': {'precision': 0.777350324597259, 'recall': 0.7834591151422835, 'f1-score': 0.7803927653925068, 'support': 28886}, 'macro avg': {'precision': 0.7706374488539409, 'recall': 0.7803290524049951, 'f1-score': 0.7747589653439482, 'support': 28886}, 'weighted avg': {'precision': 0.7736070326039461, 'recall': 0.7834591151422835, 'f1-score': 0.7778394317572982, 'support': 28886}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_metric_test=compute_metrics(model,test_loader,label_unique_test)\n",
    "print(eval_metric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8a40a046-6a64-48cd-bd52-6d9afbade143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfee955b-08df-4790-8f61-7cd71ee1fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 362/362 [00:13<00:00, 26.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC': {'precision': 0.9021499737808075, 'recall': 0.9384170621284024, 'f1-score': 0.9199262091276101, 'support': 18333}, 'ORG': {'precision': 0.8527209904981284, 'recall': 0.7965839553493377, 'f1-score': 0.8236971108716059, 'support': 14871}, 'PER': {'precision': 0.8963386727688787, 'recall': 0.9343988549618321, 'f1-score': 0.9149731371174958, 'support': 12576}, 'micro avg': {'precision': 0.8855921166869248, 'recall': 0.8912407164700743, 'f1-score': 0.8884074380525193, 'support': 45780}, 'macro avg': {'precision': 0.8837365456826048, 'recall': 0.8897999574798575, 'f1-score': 0.886198819038904, 'support': 45780}, 'weighted avg': {'precision': 0.8844972579240417, 'recall': 0.8912407164700743, 'f1-score': 0.8873068829204404, 'support': 45780}}\n"
     ]
    }
   ],
   "source": [
    "eval_metric_train=compute_metrics(model,train_loader,label_unique_test)\n",
    "print(eval_metric_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02842317-d86b-42b6-9066-0c0d0d4d360c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14f0b6a3f1f0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(range(0,len(f1_micro_avg)),f1_micro_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "944b61fa-f11e-4f42-b79c-79996fb1b86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " 'PER': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " 'micro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2},\n",
       " 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2},\n",
       " 'weighted avg': {'precision': 1.0,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 1.0,\n",
       "  'support': 2}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test classification_report function\n",
    "\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "# Example nested lists of predictions and true labels\n",
    "all_predictions = [['O', 'B-PER', 'I-PER', 'O'], ['B-LOC', 'I-LOC', 'O']]\n",
    "all_labels = [['O', 'B-PER', 'I-PER', 'O'], ['B-LOC', 'I-LOC', 'O']]\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(all_labels, all_predictions,output_dict=True)\n",
    "\n",
    "# Print the report\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
